# Claude Session Export

## Session Information

- **Session ID**: `agent-0bdcc13c`
- **Export Mode**: Full Conversation
- **Total Messages**: 18 (8 user, 10 assistant)
- **First Message**: 11/30/2025, 3:48:05 PM
- **Last Message**: 11/30/2025, 3:48:47 PM
- **Project Path**: `/home/chris/dev/projects/codex/brain_explore`

---

## Conversation

### Assistant
> 11/30/2025, 3:48:05 PM

[
  {
    "type": "text",
    "text": "I'll search for each of these cognitive and metacognitive assessments to find the actual instruments and official sources."
  }
]

---

### Assistant
> 11/30/2025, 3:48:06 PM

[
  {
    "type": "tool_use",
    "id": "toolu_018BSgSapxx1wWnB5hxPho6r",
    "name": "mcp__tavily__tavily-search",
    "input": {
      "query": "Metacognitive Awareness Inventory MAI Schraw Dennison PDF instrument",
      "max_results": 10,
      "include_raw_content": true
    }
  }
]

---

### Assistant
> 11/30/2025, 3:48:06 PM

[
  {
    "type": "tool_use",
    "id": "toolu_01FTvntJ3UwXYWV2sW3yShNB",
    "name": "mcp__tavily__tavily-search",
    "input": {
      "query": "BRIEF-A Behavior Rating Inventory Executive Function Adult assessment PDF",
      "max_results": 10,
      "include_raw_content": true
    }
  }
]

---

### Assistant
> 11/30/2025, 3:48:07 PM

[
  {
    "type": "tool_use",
    "id": "toolu_019e6XZmJH4NHxagprwyZY2T",
    "name": "mcp__tavily__tavily-search",
    "input": {
      "query": "Learning and Study Strategies Inventory LASSI assessment instrument PDF",
      "max_results": 10,
      "include_raw_content": true
    }
  }
]

---

### Assistant
> 11/30/2025, 3:48:08 PM

[
  {
    "type": "tool_use",
    "id": "toolu_01T9GBDo7SpdF7XzAaJCy2Zz",
    "name": "mcp__tavily__tavily-search",
    "input": {
      "query": "Motivated Strategies for Learning Questionnaire MSLQ PDF free download",
      "max_results": 10,
      "include_raw_content": true
    }
  }
]

---

### Assistant
> 11/30/2025, 3:48:09 PM

[
  {
    "type": "tool_use",
    "id": "toolu_01BPoRj46rjw7y9No2yqPqxw",
    "name": "mcp__tavily__tavily-search",
    "input": {
      "query": "REFLECT Rubric metacognition assessment tool PDF",
      "max_results": 10,
      "include_raw_content": true
    }
  }
]

---

### Assistant
> 11/30/2025, 3:48:09 PM

[
  {
    "type": "tool_use",
    "id": "toolu_018Lt3pzcpeZmiwwNpyjg8AM",
    "name": "mcp__tavily__tavily-search",
    "input": {
      "query": "DIEP Model reflection framework assessment tool",
      "max_results": 10,
      "include_raw_content": true
    }
  }
]

---

### Assistant
> 11/30/2025, 3:48:10 PM

[
  {
    "type": "tool_use",
    "id": "toolu_01Mow8EbFLv4wVnpz72Ru1Q8",
    "name": "mcp__tavily__tavily-search",
    "input": {
      "query": "Herrmann Brain Dominance Instrument HBDI sample assessment PDF",
      "max_results": 10,
      "include_raw_content": true
    }
  }
]

---

### Assistant
> 11/30/2025, 3:48:11 PM

[
  {
    "type": "tool_use",
    "id": "toolu_01SgXF3fFjNBKjJ4STcpFSDK",
    "name": "mcp__tavily__tavily-search",
    "input": {
      "query": "Thinking Environment Assessment Nancy Kline tool instrument",
      "max_results": 10,
      "include_raw_content": true
    }
  }
]

---

### User
> 11/30/2025, 3:48:14 PM

[
  {
    "tool_use_id": "toolu_018BSgSapxx1wWnB5hxPho6r",
    "type": "tool_result",
    "content": [
      {
        "type": "text",
        "text": "Detailed Results:\n\nTitle: Metacognitive Awareness in Adults | PDF - Scribd\nURL: https://www.scribd.com/document/831666976/Instrument-MAI\nContent: The Metacognitive Awareness Inventory (MAI), created by Schraw and Dennison in 1994, is a reliable tool for assessing metacognitive awareness in adults,\nRaw Content: ![Scribd](data:image/svg+xml;base64,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)\n\n# Metacognitive Awareness in Adults\n\nMetacognitive Awareness in Adults\n\n## Uploaded by\n\nAI-enhanced title and description\n\n# Metacognitive Awareness in Adults\n\nThe Metacognitive Awareness Inventory (MAI), created by Schraw and Dennison in 1994, is a reliable tool for assessing metacognitive awareness in adults, with a high internal consistency indicated by a Cronbach's Alpha of 0.867. The inventory consists of 52 true/false items that evaluate two main components: knowledge about cognition and regulation of cognition, each containing several subcomponents. The MAI helps in understanding individuals' cognitive processes and their management strategies.\n\n# Metacognitive Awareness in Adults\n\nMetacognitive Awareness in Adults\n\n## Uploaded by\n\nAI-enhanced title and description\n\n## Share this document\n\n![]()\n\n## Footer menu\n\nAbout\n\nSupport\n\nLegal\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nAbout\n\nLegal\n\nSupport\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nTitle: [PDF] METACOGNITIVE AWARENESS INVENTORY' (MAI ... - FCA UNJu\nURL: https://fca.unju.edu.ar/media/revista_articulo/Revista_Cientifica_Vol16_2_Trabajo_Rivera_Funes.pdf\nContent: Este instrumento (MAI) fue creado por Schraw y Denninson en 1994 para identificar habilidades metacognitivas en los sujetos y consta de 52 ítems distribuidos en\n\nTitle: [PDF] Validation of the Shortened Version of the Metacognitive Awareness ...\nURL: https://digibuo.uniovi.es/dspace/bitstream/handle/10651/67623/4766.pdf?sequence=1&isAllowed=y\nContent: Some examples are the Meta- cognitive Awareness Inventory (MAI) (Schraw & Dennison, 1994), the Motivated Strategies for Learning Questionnaire (MSLQ).\n\nTitle: Validación y Examen de la Estructura Factorial del Metacognitive ...\nURL: https://www.researchgate.net/publication/352572837_Validacion_y_Examen_de_la_Estructura_Factorial_del_Metacognitive_Awareness_Inventory_MAI_en_Espanol_con_una_Muestra_Colombiana_de_Estudiantes_Universitarios\nContent: PDF | Objetivo: El Metacognitive Awareness Inventory (MAI) fue desarrollado originalmente en inglés por Schraw & Dennison en 1994 para medir\n\nTitle: [PDF] Assessing Metacognitive Awareness - Gregory ScHRAW ... - Sci-Hub\nURL: https://2024.sci-hub.st/2344/c886ab48676010ae16918a549d83609f/schraw1994.pdf\nContent: The materials consisted of a 52-item self-report instrument (henceforth referred to as the Metacognitive Awareness Inventory, or MAI) developed for the purposes\n\nTitle: [PDF] Metacognitive Awareness Inventory (MAI) Scoring Guide\nURL: https://studentsuccess.uiowa.edu/sites/studentsuccess.uiowa.edu/files/imports/Vecera.pdf\nContent: Directions - For each True on the MAI give yourself 1 point on the following charts. For each False, give yourself 0 points in the. Score column.\n\nTitle: [PDF] Inventario de Conciencia Metacognitiva para Docentes (MAIT)\nURL: https://www.redalyc.org/pdf/2931/293122852016.pdf\nContent: The results of this three-phase study support the validity and reliability of scores on the inventory modified by the researcher who based it on the Metacognitive Awareness In-ventory (MAI). While modifying Metacognitive Awareness Inventory for Teachers (MAIT), the researcher based it on the Metacognitive Awareness Inventory developed by Schraw and Dennison (1994). The results of this three-phase study support the validity and reliability of scores on the inventory modified by the researcher who based it on the Metacognitive Awareness In-ventory (MAI) developed by Schraw and Dennison (1994). The results from empirical research combined with the student teach-ers‟ teaching metacognitive awareness revealed that the inventory modified was validated at the end of the statistical process.\nRaw Content: Electronic Journal of Research in Educational Psychology E-ISSN: 1696-2095 jfuente@ual.es Universidad de Almería España Balcikanli, Cem Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, vol. 9, núm. 3, diciembre, 2011, pp. 1309-1331 Universidad de Almería Almeria, España Disponible en: http://www.redalyc.org/articulo.oa?id=293122852016 Cómo citar el artículo Número completo Más información del artículo Página de la revista en redalyc.org Sistema de Información Científica Red de Revistas Científicas de América Latina, el Caribe, España y Portugal Proyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1309 - Inventario de Conciencia Metacognitiva para Docentes (MAIT) Cem Balcikanli English Language Teaching Department, Gazi University, Ankara Turquía Correspondencia: Dr. Cem Balcikanli, Gazi Universitesi, Gazi Egitim Fakultesi, Yabancı Diller Egitimi Bolu-mu, Ingiliz Dili Egitimi ABD, Teknikokullar/Besevler Ankara, Turkey. E-mail: balcikanli@gazi.edu.tr © Education & Psychology I+D+i and Editorial EOS (España) Balcikanli, Cem - 1310 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 Resumen Introducción. En las publicaciones científicas se han producido un gran número de intentos de conceptualizar la construcción de la metacognición en los últimos tres decenios. El concep-to en sí ha aumentado su popularidad en casi todas las disciplinas que van desde la comunica-ción a la enfermería. Esta populariadad se ha materializado con una gran cantidad de inventa-rios metacognitivo desarrollado. Sin embargo, no existe un inventario específicamente dise-ñado, exclusivamente para los profesores, que conozcamos por la literatura. En este punto, este estudio tiene por objeto elaborar un inventario de la conciencia metacognitiva para los profesores, a partir del inventario desarrollado para la conciencia metacognitiva de los adul-tos. Método. El estudio consta de tres fases con el fin de hacer el inventario fiable y válido para ser utilizado en el contexto de la investigación educativa. Cada fase consistió en diferentes pasos, es decir, construcción de elementos, retroalimentación externa, análisis de SPSS, y pilotaje del inventariocon un número de estudiantes de pedagogía. Resultados. Los resultados de este estudio, en tres fases, dan apoyo a la validez y fiabilidad de las puntuaciones en el inventario modificado por el investigador que se basa en el Inventa-rioa de conciencia metacognitiva (MAI). Discusión y Conclusiones. La versión modificada del MAI, titulado MAIT, es un un inventa-rio válido y fiable para medir la conciencia metacognitiva de los docentes. Por lo tanto, este i-ventario puede ser utilizado como una herramienta para medir la conciencia metacognitiva docente, en el área de la investigación educativa. Palabras clave: Metacognición, conciencia metacognitiva, profesorado, validez, fiabilidad. Recibido: 18/05/11 Aceptación inicial: 05/06/11 Aceptación final: 05/11/11 Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1311 - Metacognitive Awareness Inventory for Teachers (MAIT) Abstract Introduction. In research literature there have been a great number of attempts to conceptual-ize the construct of metacognition over the last three decades. The concept itself has increased its popularity in almost all disciplines ranging from communication to nursing. This populari-ty has been materialized with a lot of metacognitive inventories developed in time. However, there is no inventory specifically designed solely for teachers, of which we know in the litera-ture. At this point, this study aims at modifying Metacognitive Awareness Inventory for Teachers by making use of the inventory developed for metacognitive awareness of adults. Method. Consisting of three phases carried out, this study was conducted so as to make the inventory reliable and valid to be used in educational research paradigm. Each phase con-sisted of steps, namely items construction, external feedback, SPSS analyses, and inventory piloting with a number of student teachers. Results. The results of this three-phase study support the validity and reliability of scores on the inventory modified by the researcher who based it on the Metacognitive Awareness In-ventory (MAI). Discussion and Conclusion. The modified version of MAI, entitled MAIT, seemed to make a valid and reliable inventory to measure teachers‟ metacognitive awareness. Thus, this inven-tory would be utilized as a tool to measure teachers‟ metacognitive awareness in educational research area. Keywords: Metacognition, Metacognitive Awareness, Teacher, Validity, Realibility. Received: 05/18/11 Initial acceptance: 06/05/10 Final acceptance: 11/05/11 Balcikanli, Cem - 1312 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 Introduction In research literature there have been a great number of attempts to conceptualize the construct of metacognition over the last three decades (Baker & Brown, 1984; Flavell, 1976, 1979; Garrison, 1997; Hacker, Dunlosky, & Graesser, 1998; Paris & Winograd, 1990; Schraw, 1998; Schraw & Dennison, 1994). The literature is replete with definitions of meta-cognition up to date (Brown, 1985; Flavell, 1976, 1979; Garrison, 1997; Hacker, Dunlosky, & Graesser, 1998; Paris & Winograd, 1990; Schraw & Dennison, 1994). However, there is no general consensus of the most agreed-upon definition of metacognition as yet (Hacker, 1998). It was Flavell (1970) who first coined the term and defined it as “our awareness of the learn-ing process”. Flavell, later, (1976, p. 232) described metacognition as “one‟s knowledge con-cerning one‟s own cognitive processes and products or anything related to them, e.g. the learning-relevant properties of information or data”. Hacker‟s definition of metacogniton, though, has proved remarkably robust and remains the most widely cited definition in the field. Hacker (1998, p. 11) believed that “metacognition includes both knowledge of one‟s knowledge, processes, cognitive and affective states, and the ability to consciously and deli-berately monitor and regulate one‟s knowledge, process, and cognitive and affective states”. Since then, the relevant literature has tended to focus on two aspects of metacognition: a) me-tacognition knowledge b) metacognitive regulation. Indicating the assumption that metacogni-tion plays a key role in different disciplines such as oral communication, reading comprehen-sion, and writing comprehension, Flavell (1979) offered four classes of phenomena, which, he believes, that have very close ties with the monitoring of a wide variety of cognitive enter-prises. Metacognitive knowledge, metacognitive experiences, goals (or tasks) and actions (or strategies). Metacognitive knowledge is “the stored world knowledge that has to do with people as cognitive creatures and with their diverse cognitive tasks, goals, actions and expe-riences” (Flavell, 1979, p. 906). That is to say, metacognitive knowledge consists of know-ledge or beliefs that drive cognitive enterprises to emerge in the process of factors or variables (Flavell, 1979, 1987). Within this perspective, metacognitive knowledge includes three major categories: a) person b) task c) strategy. In Flavell‟s (1979, p. 907) remarks, “the person cate-gory encompasses everything that you could come to believe about the nature of yourself and other people as cognitive enterprises”. In other words, a learner confronted with a particular learning situation needs to know his/her existing situation in terms of how much information s/he has related to that particular learning. Another category is task which “concerns the in-formation available to you during a cognitive enterprise” (Flavell, 1979, p. 907). A learner Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1313 - needs to understand what variations enable what cognitive enterprises in achieving the task. The last category is “strategy”. There is a great deal of knowledge that could be acquired con-cerning “what strategies are likely to be effective in achieving subgoals and goals in what sorts of cognitive undertakings” (Flavell, 1979, p. 907). It basically refers to what kind strate-gies each learner needs to undertake when s/he is confronted with a particular learning situa-tion/problem to deal with. Metacognitive experiences, on the other hand, are “any conscious cognitive or affective experiences that accompany and pertain to any intellectual enterprise” (Flavell, 1979, p. 906). In a broader context, they can be best described as “items of metacog-nitive knowledge that have entered consciousness” (Flavell, 1979, p. 908). Related to what metacognitive experiences propose with regard to cognitive goals or tasks, metacognitive knowledge, and cognitive actions or strategies, Flavell (1979) pinpointed three important im-plications for this. First, metacognitive experiences have the power of influencing metacogni-tive knowledge along with a variety of actions including adding, deleting or revising. Second, they can guide learners to recreate new goals and revise them on the basis of old ones. Third, metacognitive experiences can arouse strategies that may be employed in the face of cognitive or metacognitive goals. Congruent with Flavell‟s insights about metacognition (1979), Paris and Winograd (1990) proposed two aspects of metacognition, namely cognitive self-appraisal and self-management of cognition. While the former is described as “personal reflections about one‟s own knowledge states and abilities” (Paris & Winograd, 1990, p. 17), the latter can be consi-dered to be “metacognition in action, i.e. how metacognition helps to orchestrate cognitive aspects of problem solving” (Paris & Winograd, 1990, p. 18). As is easily recognized in these two aspects of metacognition, they both refer to thinking processes and the particular actions and insights when one is confronted with one‟s cognitive enterprises. Corroborating with Fla-vell (1979)‟s framework, Schraw and Moshman (1995) believed that metacognition can be broken into two parts. Drawing the studies conducted by Brown (1987), Baker (2001) and Paris and Winograd (1990) who distinguished knowledge of cognition from regulation of cognition, Schraw and Moshman (1995) proposed a distinction between metacognitive know-ledge and metacognitive regulation. What Paris and Winograd (1990) call “self-appraisal” can be best associated with Schraw‟s concept of “knowledge of cognition”, while self-management is very identical to Schraw‟s concept of regulation (Schraw, 2001). Schraw and Moshman‟s distinction between metacognitive knowledge and metacognitive regulation seems to have received a lot of approval from academicians and has been widely used in Balcikanli, Cem - 1314 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 many research studies. Other than two key figures in the field of metacognition, there are, however, different levels of metacognitive processing. Kluwe (1982, cited in Hacker, Dun-losky, & Graesser, 1998), differentiated between executive monitoring processes, which are directed at the acquisition of information about the person‟s thinking processes, and executive regulation processes that are directed at the regulation of the course of one‟s own thinking. In this context, the first provides a ground for identifying the task, checking current progress of that task, evaluating that progress, and guessing what the result is likely to occur. The second, on the other hand, is concerned with certain decisions on employing his or her resources for the given task, determining the order of steps to be taken to complete the task, and pacing on the completion of task. When it comes the question of how metacognition relates to learning, Flavell (1987, p. 27) emphasized that “metacognition is congruent with the learners‟ need and desire to com-municate, explain and justify thinking to organisms as well as to himself”. In a similar vein, a wide range of researchers agree to provide learners with the best environment to develop me-tacognitive knowledge and skills since learning is internalized through interaction and com-munities (Flavell, 1987; Paris & Winograd, 1990; Schraw, 2001; Schraw & Moshman, 1995). One of the studies that explore the relationship between metacognition and learning gains is that Jones et al. (1987, cited in Sinclair, 1999) who found that metacognitive awareness was related to success in language learning in the sense that successful learners were aware of the processes about their own learning processes and of the appropriate strategies to manage their own learning effectively. Young and Fry (2008), based on their research study where they investigated to reveal the relationship between metacognitive awareness and academic achievement in college students, found out that there are correlations between the MAI (Me-tacognitive Awareness Inventory) and cumulative GPA (Grade Point Average). These results provide support for the validity of the MAI as it relates to academic measures. On the other hand, Stevens (2009) investigated availability of a method for the development of metacogni-tive self-knowledge and also a means for discovering what academic experiences students perceive as influential in their development as learners. In a qualitative research design, the researcher concluded that metacognitive self-knowledge can be developed through the use of a guided reflection activity and that the guided reflection activity used in the study identified and illuminated academic experiences that students perceive as salient for their learning. There is little evidence that metacognition is related to academic success despite the fact that there are popular ideas in the literature. Coffey (2009), for example, examined whether writ-Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1315 - ing instruction in a mathematics classroom increased metacognition. Students who are sup-ported in using metacognition can increase their understanding in the classroom. Utilizing a pre-test-post-test control group, the researcher asked the participants to complete a mathemat-ics problem solving assessment, which was analyzed with a rubric for accuracy and a survey concerning how they used metacognitive skills for the problem solving activity. She con-cluded that there was a relationship between metacognition and writing. Lee (2009) examined the relationships between metacognition, self-regulation and students‟ critical thinking skills and disposition in online Socratic Seminars for ninth grade World Geography and Culture students. Based on the findings of the study, she argued that self-regulation had significant relationships with students‟ critical thinking disposition, but not with students‟ critical think-ing skills for both the experimental and the control group. Using semi-structured interviews with four students from a community college to investigate the use of e-portfolios as a tool for reflection/metacognition, Zellers and Mudrey (2007) put forward that there are two broader dimensions of the use of e-portfolios. The benefits are as follows. 1) Potential for raising stu-dent metacognition. 2) Potential for raising student achievement. Another benefit, instructor implementation, also consists of five important components. The components are clarity of purpose, coaching students in the reflective process, providing feedback throughout the process, addressing technological issues, and evaluating whether a course is well suited for a portfolio. The researchers concluded that electronic portfolios can be an effective tool for in-creasing student metacognition on condition that the way instructors implement it is very meaningful to the effectiveness itself. In a similar research study, Meyer, Abrami, Wade, As-lan and Deault (2010) conducted a research study in three Canadian provinces with 32 teach-ers and 388 students to answer the research question “Can an electronic portfolio have a posi-tive impact on the literacy practices and self-regulated learning skills of students?”. Using a non-equivalent pretest/ post-test design, the researchers found out that grade 4–6 students in the experimental group compared to the students in the control group showed significant im-provements in their writing skills on a standardized literacy measure. Metacognitive Awareness: Definitions and Trends If it is the aim of education to let learners take charge of their own learning, then they need to be able to plan, monitor and evaluate their learning. In order to do so, they need to be metacognitively aware. Q‟Malley, Chamot, Stewner-Marizanares, Kupper, and Russo (1985, Balcikanli, Cem - 1316 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 p. 24) summarized it: “Students without metacognitive approaches are essentially learners without direction and ability to review their progress, accomplishments and future learning directions”. Oxford (1990) also pointed out that metacognitive strategies are essential for suc-cessful language learning. Strategies like organizing, setting goals and objectives, considering the purpose, and planning for a language task help learners arrange and plan for their lan-guage learning in an efficient way. The students without metacognitive strategies will never become autonomous learners because they don‟t know how to arrange, regulate, and evaluate their learning activities. However, there is no explored relationship between metacognitive awareness and learning gains in the relevant literature. Only a few studies simply indicate that metacognitive awareness is an important element in learning and crucial to the development of effective learning (Wenden, 1991, 1999; Wilkins, 1997). Even though there are popular ideas available everywhere without specific research studies which support this view, metacognitive aware-ness plays a pivotal role in the effectiveness of learning process, which, however, needs to be researched. Simply described as being aware of one‟s own knowledge, processes, cognitive and affective states as well as of regulation of those states (Flavell, 1976, 1979) metacognitive awareness consists of three parts: thinking of what one knows (metacognitive knowledge), thinking of what one is currently doing (metacognitive skill) and thinking of what one‟s cur-rent cognitive or affective state is (metacognitive experience) (Hacker, Dunlosky, & Graesser, 1998). What is important is that all this knowledge, the beliefs and perceptions are much re-lated to development of autonomy in that they are required to make informed decisions about one‟s own learning/teaching. Researchers (Brown, 1987; Schraw, 2001; Schraw & Moshman, 1995) elaborated on the distinction between metacognitive knowledge and metacognitive reg-ulation. Efklides (2001, p. 299) described metacognitive knowledge as “knowledge we re-trieve from memory and regards what the person knows or believes about him/herself and the tasks, goals, actions or strategies as well as the experiences s/he has had in relation to them”. Flavell‟s overall definition of metacognition seems to be very close to this one as there are overlapping features that view metacognition in relation to tasks, goals, actions, or strategies. However, the role of memory is missing in the former one. Metacognitive knowledge (or knowledge of cognition) contains three kinds of know-ledge: declarative knowledge, procedural knowledge, and conditional knowledge (Brown, 1987; Jacobs & Paris, 1987, Schraw, 2001; Schraw & Moshman, 1995). In brief, declarative Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1317 - knowledge refers to “knowing about things”, procedural knowledge refers to “knowing how to do things”, and finally conditional knowledge is “knowing the why and when aspects of cognition\" (Schraw & Moshman, 1995, p. 352). More specifically, declarative knowledge includes individuals‟ conceptions, and also their beliefs of task structures, their cognitive goals, and their own personal abilities (Schraw, 1998; Schraw & Moshman, 1995; Schraw, Crippen, & Hartley, 2006). Presley, Borkowski, & Schneider (1987) recognized the impor-tance of declarative knowledge in learning, particularly in relation to metamory in light of the results of their research study. Procedural knowledge, on the other hand, refers to “knowledge about the execution of procedural skills” (Schraw & Moshman, 1995, p. 353). In a broader sense, much of this knowledge is reflected through strategies that lead individuals to resolve the problems if there is any. Presley, Borkowski, and Schneider (1987) affirmed that individ-uals with a higher degree of procedural knowledge tend to possess a larger repertoire of strat-egies, and to sequence strategies effectively. Procedural knowledge basically includes infor-mation about how individuals perform cognitive tasks (Jacobs & Paris, 1987; Paris & Paris, 2001; Pintrich, 2002; Schraw, 1998; Schraw, Crippen, & Hartley, 2006). Conditional know-ledge refers to “knowing when and why to apply various cognitive actions (Schraw & Mosh-man, 1995, p. 353). Young and Fry (2008) particularly refer to the knowledge we have about the conditions under which we can implement various cognitive strategies. This statement is very similar to Schraw and Moshman‟s in that conditional knowledge ultimately concerns selected various strategies depending upon the condition in which learning is internalized. On the other hand, Reynolds (1992), based on his research study, claimed that conditional know-ledge is important because it helps students selectively allocate their resources and use strate-gies more effectively. To put it more clearly, conditional knowledge includes the understand-ing of both the value and the limitations of the procedural knowledge and knowing when, how, and why procedures should be used (Jacobs & Paris, 1987; Pintrich, 2002; Schraw, 1998; Schraw, Crippen, & Hartley, 2006). As for metacognitive regulation (or regulation of cognition), it refers to “metacognitive activities that help control one‟s thinking or learning” (Schraw & Moshman, 1995, p. 354). In contrast to metacognitive knowledge, metacognitive regulation is more related to a set of actions and events so as to facilitate learning than a set of knowledge that shapes how those actions emerge. Schraw (2001) accentuated that metacogni-tive regulation involves performance in a number of ways, including better use of intentional resources, better use of existing strategies, and a greater awareness of comprehension break-downs. Balcikanli, Cem - 1318 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 As Schraw and Moshman (1995) pointed out, there are several regulatory skills that have been mostly referred in research literature. Pertaining to metacognitive regulation, three regulatory skills namely planning, monitoring, and evaluating (Kluwe, 1987; Jacobs & Paris, 1987) occupy an important role in regulating students‟ skills concerning their own learning processes. Planning involves “the selection of appropriate strategies and the allocation of re-sources that affect one‟s learning performance” (Schraw & Moshman, 1995, p. 354). The skills that might be attributable to planning are setting goals, selecting appropriate strategies, and scheduling time and strategies. Miller (1985) suggested, based on the findings of his re-search, that individuals‟ planning skills contain making prediction before reading, strategy sequencing, and allocating time or attention selective before beginning a task. Monitoring, on the other hand, involves “one‟s on-line awareness of comprehension and task performance” (Schraw & Moshman, 1995, p. 355). This skill can be best conceptualized through the process of performing a specific task and how well it is controlled at regular intervals to check if the learning happens or not. The statement “I ask myself if I am sure or not to be sure if I have really learned” can be a specific example of monitoring skills. Delclos and Harrington (1991) maintained that monitoring skills can be developed through practice and training. Finally, evaluating refers to “appraising the products and regulatory processes of one‟s learning” (Schraw & Moshman, 1995, p. 355). That is to say, evaluating involves taking a deep look at the outcome and determining if the learning matches our learning goals and if the regulation processes utilized were effective (Schraw & Moshman, 1995). Evaluating skills may also in-clude re-evaluating one‟s goals and conclusion upon the completion of a task. Schraw and Dennison (1994) reported that these components are highly correlated with each other and they serve the same purpose. In other words, they complement one and other. Along similar lines, metacognition fosters students‟ awareness of their own learning and thinking processes and helps them regulate their cognition with the processes of planning, monitoring and eva-luating. More specifically, metacognition has an essential role in problem solving, reading, writing, and memory (Flavell, 1987). Jimenez, Puente, Alvarado and Arrebillaga (2009) in-vestigated how 684 students from 8 to 13 (Argentina and Spain) perceived themselves as readers. Using ESCOLA Reading Awareness Inventory, the study concluded that younger students seemed to have a lower level of reading awareness than the older ones. As certain studies indicate (Hacker, Dunlosky, & Graesser, 1998; Wenden, 1999; Wil-kins, 1997), metacognition is a crucial skill to have since it makes students independent think-ers who control their thinking processes. Using metacognition, learners can have the control Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1319 - over what and how they learn, which can trigger the development of independent learning. What is important is that learners who display more metacognitive skills tend to set clear ob-jectives in the learning process, to define the content, to make a schedule in line with this con-tent, and to select the cognitive and metacognitive strategies. The bottom line is that metacog-nitive awareness is an important element in learning and crucial to the development of (learn-er) autonomy (Wenden, 1991, 1999; Wilkins, 1997). Metacognitive awareness, in this regard, seems to be some of the key elements needed in developing autonomy. Cao and Nietfeld (2007) examined college students‟ awareness of difficulties in learning class content and se-lection of study strategies to address the perceived challenges. Employing both qualitative and quantitative procedures to analyse the data, the researchers concluded that students‟ aware-ness of different kinds of difficulties in learning the class content did not lead to adjustment of study strategies. This is not actualized in an autonomous learning process, though. Metacognition Inventories Since it was first utilized in the 1970s, the concept of metacognition has become quite fashionable in cognitive psychology. There have been several attempts to develop metacogni-tive inventories worldwide thus far. It was Myers and Paris (1978), who first created a meta-cognitive inventory. Corroborating with the categories, namely person, task, and strategy de-veloped by Flavell and Welman (1977), Myers and Paris produced a structured interview format by allowing older readers to respond freely to the open-ended questions. Later, Paris and Jacobs (1984) modified the instrument of Myers and Paris (1978). Employing 15 open-ended questions containing three categories, namely planning, evaluating and regulating, they developed an inventory for any reading situation. Miholic (1994) used the Paris and Jacobs (1984) questionnaire as a starting point to develop an inventory to measure metacognitive activities of young students. This inventory included 10 questions concerning the difficulties learners might face while reading. As opposed to the two previous ones, this instrument fo-cused more on difficulties encountered in terms of whether readers show metacognition in the process of reading. A frequently employed in the research literature, Metacognitive Aware-ness Inventory was developed to measure adults‟ metacognitive awareness. This 52-item in-ventory is a long, comprehensive scale assessing various facets of metacognition, including metacognitive knowledge and regulation (Schraw & Dennison, 1994). Items are classified into eight subcomponents under two broader categories, knowledge of cognition and regula-tion of cognition. Each component has different subcomponents. To clarify, knowledge of cognition includes at least three different kinds of knowledge: declarative, procedural, and Balcikanli, Cem - 1320 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 conditional knowledge (Brown, 1987; Jacobs & Paris, 1987; Schraw & Moshman, 1995). Regulation of cognition, on the other hand, refers to a set of activities that help students con-trol their learning. This component has also subcomponents: planning, information manage-ment strategies, comprehension monitoring, debugging strategies, and evaluation. Although a number of regulatory skills have been described in the literature, three skills stand out in all accounts: planning, monitoring, and evaluation (Jacobs & Paris, 1987). The State Metacogni-tion Inventory was developed by Q‟Neil and Abedi (1996). With the four subscales of meta-cognition, namely planning, self-checking, cognitive strategy, and awareness, the entire in-ventory was validated with a group of 219 community college students along with a 20-item math test. Yıldız, Akpınar, Tatar and Ergin (2009) developed a new instrument entitled “Me-tacognition Scale (MS)” by reviewing previous studies (O‟Neil & Abedi, 1996; Schraw & Dennison, 1994; Sperling, Howard, Miller, & Murphy, 2002). The scale includes eight scales, namely declarative knowledge, procedural knowledge and conditional knowledge, planning, self-control, cognitive strategies, self-assessment and self-monitoring. The results indicate that the MS is appropriate for researchers or teachers whose aim is to measure his/her stu-dents‟ metacognitive awareness and metacognitive abilities. Chen, Gualberto, and Tameta (2009) developed a new self-report instrument, called the Metacognitive Reading Awareness Inventory, to assess college students‟ reading awareness in reading academic or school-related materials. Consisting of five components, namely Phonemic Awareness, Phonics, Reading Fluency, Vocabulary Development, and Reading Comprehension, the inventory produced satisfactory results. The researchers believed that this instrument could be employed to meas-ure metacognitive awareness and skills of elementary level students. Above the inventories were mostly based on reading skills. As easily seen thus far, the concept of metacognition has gained its popularity in educational psychology since it was first coined by Flavell in the 1970s. This popularity was recognized with a lot of metacognitive inventories developed in time. However, there is no inventory specifically designed solely for teachers, of which we know in the literature. Objective This study aimed at modifying Metacognitive Awareness Inventory for Teachers by making use of the inventory developed for metacognitive awareness of adults (Schraw and Dennison, 1994). It is highly believed that knowing what teachers know about their own teaching should be a starting point for a change in teacher development. This inventory is considered to help teachers realize their metacognitive levels of teaching. Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1321 - Method Participants The sample was made up of three groups consisting of 323, 226 and 125 student teachers of ELT (English Language Teaching) Program. In the first group, 271 male and 52 male students were the subjects of the study, in the second group, 165 female and 61 male participants. In the last group, 82 female and 43 male student teachers constituted the subjects of the study. All of these participants were senior students of ELT Program, Gazi University (Turkey). Instrument and procedure: Metacognitive Awareness Inventory for Teachers (MAIT) By taking the various dimensions of metacognition into account, the researcher made small changes on the inventory to make it more appropriate for teaching situations. While modifying Metacognitive Awareness Inventory for Teachers (MAIT), the researcher based it on the Metacognitive Awareness Inventory developed by Schraw and Dennison (1994). More specifically, there were three main phases conducted during the development of the MAIT in 2009-2010. Phase 1 This section is concerned with three phases to conduct the validity analysis of the MAIT. Subsequent to a wide range of literature review and expert opinions, it was decided that 42 items would be employed to modify the inventory. Out of 52 items, only 42 items were taken from the inventory. Teaching aspects were added to the items. To illustrate, the item “I ask myself periodically if I am meeting my goals” was changed into “I ask myself periodically if I meet my teaching goals while I am teaching”. Similar changes were made in the items to make them more suitable for teaching contexts. A rigorous study was conducted to compose the 42 items that represent the components. Dörnyei (2003, p. 52) believed that in the questionnaire construction process “some external feedback is indispensable when we have prepared an initial item pool”. At this point, the 42 items were sent to five experts (3 Turkish, 2 British) of metacognition to get external feedback for the content of the inventory as well as the wording issues. Dörnyei (2003, p. 52) alleged that “questions that have been used frequently before must have been through extensive piloting”. As an integral part of the Balcikanli, Cem - 1322 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 questionnaire construction, field-testing is used to “pilot the questionnaire at various stages of its development on a sample of people who are similar to the target sample for which the in-strument has been designed” (Dörnyei, 2007, p. 112). Metacognitive Awareness Inventory for Teachers was piloted with 323 ELT student teachers in the first place. The data gathered through the inventory were processed through a statistical software program, SPSS 15, for the factor analysis. Factor analysis is “designed to see whether each item measured the subscale it was supposed to measure to look at construct validity” (Muijs, 2004, p. 70) and is particularly suited to reduce the number of variables to a few values that still contain most of the informa-tion found in the original variables (Hatch & Lazaraton, 1991). There are several ways to conduct factor analysis and the choice of method depends on many things (Field, 2005). The most important of this is the factor extraction on SPSS. Kaiser (1974, cited in Field, 2005) recommends accepting values greater than 0.5 as acceptable (values below this should lead you to either collect more data or rethink which variables to include). SPSS lists “eigenvalues associated with each linear component before extraction, after extraction and after rotation” (Field, 2005, p.7). Phase 2 As a result of the first factor analysis, 6 items were removed from the inventory be-cause their factor levels were not as high as required as Kasier (1974, cited in Field, 2005) mentioned. Later, the five experts were asked to get their further suggestions on the 36 items. On the basis of the suggestions made, the 36 items were administered to 226 student teachers. However, 12 items that did not work as a result of the second factor analysis were removed. Phase 3 As a consequence of a meticulous study, those items were removed from the invento-ry. As a final step, the remaining 24 items were modified and administered to 125 student teachers. The inventory produced the expected results. Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1323 - Table 1. The Ultimate Factor Analysis of the Metacognitive Awareness Inventory for Teachers Variance Total: % 60,411 Factor-1: % 7,946 Factor-2: % 13,911 Factor-3: % 27,439 Factor-4: % 6,499 Factor-5: % 4,616 Factor-6: % 5, 456 Statements Common Factor Variance Factor I Factor II Factor III Factor IV Factor V Factor VI Factor I- Declarative Knowledge 1- I am aware of the strengths and weak-nesses in my teaching. .573 .741 7- I know what skills are most important in order to be a good teacher. .662 .699 13- I have control over how well I teach. .501 .651 19- I know what I am expected to teach. .577 .582 Factor II- Procedural Knowledge 2- I try to use teaching techniques that worked in the past. .701 .781 8- I have a specific reason for choosing each teaching technique I use in class. .570 .751 14. I am aware of what teaching techniques I use while I am teaching. .578 .683 20. I use helpful teaching techniques auto-matically. .541 .591 Factor III- Conditional Knowledge 3- I use my strengths to compensate for my weaknesses in my teaching. .722 .802 9- I can motivate myself to teach when I really need to teach. .667 .741 15- I use different teaching techniques depending on the situation. .679 .662 21- I know when each teaching technique I use will be most effective. .540 .581 Factor IV- Planning 4- I pace myself while I am teaching in order to have enough time. .644 .752 10- I set my specific teaching goals before I start teaching. .548 .682 16- I ask myself questions about the teach-ing materials I am going to use. .522 .631 22- I organize my time to best accomplish my teaching goals. .568 .601 Factor V- Monitoring 5- I ask myself periodically if I meet my teaching goals while I am teaching. .711 .821 11- I find myself assessing how useful my teaching techniques are while I am teaching. .758 .732 17- I check regularly to what extent my students comprehend the topic while I am teaching. .754 .741 23- I ask myself questions about how well I am doing while I am teaching. .670 .681 Factor VI- Evaluating 6- I ask myself how well I have accom-plished my teaching goals once I am fi-nished. .570 .581 12- I ask myself if I could have used differ-ent techniques after each teaching expe-rience. .508 .561 18- After teaching a point. I ask myself if I‟d teach it more effectively next time. .491 .521 24- I ask myself if I have considered all possible techniques after teaching a point. .502 . 509 Balcikanli, Cem - 1324 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 Data analysis SPSS 15 statistical software program was used to process the data gathered from the participants during the study. For validity consideration, KMO (Kaiser-Meyer-Olkin Measure of Sampling Adequacy) was employed so as to identify the validity of the inventory (0,794) and the value for Barlett TKest was identified as significant (2513,474). As for the realibility issue of the inventory, Cronbach's Alpha was utilized to find out whether the inventory in the context of research was reliable or not. Results Validity KMO (Kaiser-Meyer-Olkin Measure of Sampling Adequacy) was employed so as to identify the validity of the inventory (0,794) and the value for Barlett TKest was identified as significant (2513,474). This calculation proved to be appropriate for the factor analysis. The number of the factors was identified as 6, as indicated above. Factor I includes items 1, 7, 13, 19, Factor II 2, 8, 14, 20, Factor III 3, 9, 15, 21, Factor IV 4, 10, 16, 22, Factor V 5, 11, 17, 23, and Factor VI includes items 6, 12,18, 24. The ultimate factor analysis result is given in Table 1 (See the appendix for the inventory). Reliability After an inventory is constructed, it is mandatory that a reliability analysis be carried out. Reliability is the fact that a scale should consistently reflect the construct it is measuring (Field, 2005). In SPSS, Cronbach's Alpha was utilized to find out whether the inventory in the context of research was reliable or not. The detailed analysis for reliability issue is given in Table 2. When we examine the reliability data for the inventory, the values vary from 0, 79 to 0, 85, which indicates that the inventory was observed to display high alpha scores. The in-ventory modified in this doctoral dissertation was 5-point Likert-type response format, and the degree of agreement was from „strongly disagree‟ (1) to „strongly agree‟ (5). Scoring is provided as follows. “Strongly Disagree” (1) refers to 1, “Disagree” (2), “Neutral” (3), Agree (4), Strongly Agree (5). Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1325 - Table 2. The Reliability Analysis of the MAIT Factors Cronbach Alpha Factor I- Declarative Knowledge 0, 85 Factor II- Procedural Knowledge 0, 82 Factor III- Conditional Knowledge 0, 84 Factor IV- Planning 0, 81 Factor V- Monitoring 0, 80 Factor VI- Evaluating 0, 79 Discussion and Conclusion The motivation of this study came from a need to measure language teachers‟ meta-cognitive awareness. In the relevant literature, it is possible to encounter several inventories associated with metacognitive awareness. Not a single one designed for teachers‟ metacogni-tive awareness, however, is available that we are aware of. Since the construct of metacogni-tion was first coined by Flavell (1970), the inventories have mostly focused on learning as-pects rather than teaching ones. The inventories, though, took metacognitive knowledge and regulation as the starting point because metacognitive awareness consists of these two aspects in the literature. In a similar fashion, this study set out to develop an instrument to measure teachers‟ metacognitive awareness of teaching by taking metacognitive knowledge and regu-lation into account. More specifically, subdimensions of both metacognitive knowledge and regulation were used in the development of the inventory namely conditional, procedural and declarative knowledge for metacognitive knowledge, planning, monitoring and evaluating for metacognitive regulation. The results of this three-phase study support the validity and reliability of scores on the inventory modified by the researcher who based it on the Metacognitive Awareness In-ventory (MAI) developed by Schraw and Dennison (1994). While modifying the MAIT (Me-tacognitive Awareness Inventory for Teachers), the researcher focused on the two compo-nents that constitute metacognitive awareness in the literature. The widespread focus on the presence of two components served as a starting point in the process of the modification of the MAIT. As mentioned above, there were three phases carried out during the study. In the first phase, identification of 42 items that represent the very essence of two components of Balcikanli, Cem - 1326 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 metacognitive awareness was done. Following this, teaching aspects to the inventory were added with a rigorous examination of each item added. Next step was to receive external feedback about the inventory in progress. To do so, five experts (3 Turkish and 2 British) on metacognition were advised to make comments on the items composed. As a final step of the first phase, these 42 items were administered to 323 pre-service English teachers in the Gazi University, Turkey. As a result of the explanatory factor analysis, it was revealed that 6 items did not work as anticipated. As Kaiser (1974, cited in Field, 2005) mentioned, to accept val-ues, their values should be at least 0.5 or above. In the second phase, 6 items which did not work in the first factor analysis in SPSS 15 were removed from the inventory. After this process, 36 items were modified again and sent to the experts to get some further suggestions from them. In light of the feedback provided, 36 items were given to 226 student teachers to validate the inventory. There were still some items that did not produce satisfactory results for the second factor analysis in SPSS. The 12 items whose factor levels were considered to be lower than anticipated were removed from the inventory. In the third phase, the remaining 24 items were sent to five experts to make sure if content validity was covered. Subsequent to experts‟ opinions, 24 items that represent 6 dimensions, consisting of 4 items each, were vali-dated with 125 student teachers. The data collected this way were processed through SPSS statistical programme. The results from empirical research combined with the student teach-ers‟ teaching metacognitive awareness revealed that the inventory modified was validated at the end of the statistical process. After the inventory was validated, the 24 items were processed through SPSS once again for reliability issue this time. As expected, Cronbach's Alpha results indicated that the inventory was found to have a high reliability to be used in educational sciences. In conclusion, this study revealed that the modified version of MAI, entitled, MAIT possesses good reliability and validity estimates. It, thus, can be used as a diagnostic and re-search tool to measure metacognitive awareness of teachers. The instrument added to our knowledge of the nature of the metacognitive awareness in that two of the main components of the instrument reflected both developmental and psychosocial. The two components are attention deficit and hyperactivity. Thus, this inventory would be utilized as a tool to measure teachers‟ metacognitive awareness in educational research area. Further re-search is needed in the future to validate the structure of the instrument with larger and varied samples. Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1327 - References Baker, L., & Brown, A.L. (1984). Metacognitive skills and reading. In P. D. Pearson (Ed.), Handbook of reading research (pp. 353–394). New York: Longman. Brown, A.L. (1985). Metacognition: The development of selective attention strategies for learning from texts. In H. Singer & R. B. Ruddell (Eds.), Theoretical models and processes of reading (pp. 501–526). Newark, DE: International Reading Association. Cao, L., & Nietfeld, J.L. (2007). College students‟ metacognitive awareness of difficulties in learning the class content does not automatically lead to adjustment of study strategies. Australian Journal of Educational and Developmental Psychology, 7, 31-46. Chen, M. H., Gualberto, P.J., & Tameta, C.L. (2009). The Development of Metacognitive Reading Awareness Inventory. TESOL Journal, 1, 43-57. Coffey, H. (2009). The relationship between metacognition and writing in sixth grade mathematics. Unpublished Doctoral Dissertation, Walden University, Walden. Delclos, V.R., & Harrington, C. (1991). Effects of strategy monitoring and proactive instruction on children‟s problem-solving performance. Journal of Educational Psychology, 83(1), 35–42. Dörnyei, Z. (2003). Questionnaires in second language research: Construction, administration, and processing. New Jersey: Lawrence Erlbaum Associates, Publishers. Efklides, A. (2001). Metacognitive experiences in problem solving: Metacognition, motivation, and self-regulation. In A. Efklides, J. Kuhl, & R. M. Sorrentino (Eds.), Trends and prospects in motivation research (pp. 297–323). Dordrecht, The Netherlands: Kluwer. Field, A. P. (2005). Discovering statistics using SPSS. London: Sage Flavell, J.H. (1970). Developmental studies of mediated memory. In H. W. Reese & L. Lipsitt (Eds.), Advances in child development and behavior New York: Academic Press. Flavell, J.H. (1976). Metacognitive aspects of problem solving. In L. B. Resnick (Ed.), The Nature of intelligence (pp. 231–236). Hillsdale, NJ: Erlbaum. Flavell, J.H. (1979). Metacognition and cognitive monitoring: a new area of cognitive- Balcikanli, Cem - 1328 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 developmental inquiry. American Psychologist, 34(10), 906-917. Flavell, J.H. (1987). Speculations about the nature and development of metacognition. In F. Weinert & R. Kluwe, (Eds.), Metacognition, motivation, and understanding (pp. 21–29). Hillsdale, NJ: Erlbaum. Flavell, J.H. & Wellman, H.M. (1977). Metamemory. In R.V. Kail & J.W. Hagen (Eds.), Perspectives on the development of memory and cognition. Hillsdale, NJ: Erlbaum. Jimenez, V., Puente, A., Alvarado, J. M., & Arrebillage, L. (2009). Measuring metacognitive strategies using reading awareness scale ESCOLA. Electronic Journal of Research in Educational Psychology, 7(2), 779-804. Garrison, J. (1997). Dewey and Eros: Wisdom and desire in the art of teaching. New York: Teachers College Press. Hacker, D.J., Dunlosky, J., & Graesser, A.C. (Eds.), (1998). Metacognition in educational theory and practice Mahwah, NJ: Lawrence Erlbaum Associates, Publishers. Hatch, E., & Lazaraton, A. (1991). The research manual: Design and statistics for applied linguistics. Boston, MA: Newbury House. Kluwe, R.H. (1987). Executing decisions and regulation of problem solving behavior. In F.E. Weinert & R.H. Kluwe (Eds.), Metacognition, motivation and understanding (pp. 31- 64). Hillsdale: Earlbaum Associates Lee, S. (2009). Examining the relationships between metacognition, self- regulation and critical thinking in online socratic seminars for high school social studies students. Unpublished Master‟s Thesis, University of Texas, Texas Meyer, E., Abrami, P.C., Wade, C.A., Aslan, O., & Deault, L. (2010). Improving literacy and metacognition with electronic portfolios: Teaching and Learning with Epearl. Computers & Education, 55(1), 84–91. Miholic, V. (1994). An inventory to pique students‟ metacognitive awareness of reading strategies”. Journal of Reading, 38 (1), 2 – 4. Muijs, D. (2004). Doing quantitative research in education with SPSS. California: Sage Publications. Myers, M. & Paris, S.G. (1978). Children‟s metacognitive knowledge about reading. Journal of Educational Psychology, 70, 680–690. Oxford, R.L. (1990). Language learning strategies: What every teacher should know. Rowley, Mass: Newbury House. Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1329 - Paris, S.G., & Winograd, P.N. (1990). How metacognition can promote academic learning and instruction. In B. Jones & L. Idol (Eds.), Dimensions of thinking and cognitive instruction (pp. 15–51). Hillsdale, NJ: Lawrence. Erlbaum Associates Paris S.; & Jacobs, J. (1984) The benefits of informed instruction for children‟s reading awareness and comprehension skills. Child Development, 55,2083–2093. Presley, M., Borkowski, J. G., & Schneider, W. (1987). Cognitive strategies: Good strategy users coordinate metacognition and knowledge. In R. Vasta, & G. Whilehurst (Eds.), Annals of Child Development (pp. 80-129). Greenwich, CT: JAI Press. Pintrich, P.R. (2002). The role of metacognitive knowledge in learning, teaching & assessing. Theory Into Practice, 41(4), 220-227. Q‟Malley, J. M., Chamot, A.U., Stewner-Marizanares, G., Kupper, L., & Russo, R.P. (1985). Learning strategies used by beginning and intermediate ESL students. Language Learning, 35(1), 21-46. O‟Neil, H. F., & Abedi, J. (1996). Reliability and Validity of a State Metacognitive Inventory: Potential for Alternative Assessment. Journal of Educational Research, 89 (4), 234-245. Reynolds, R.E. (1992). Selective attention and prose learning: Theoretical and empirical research. Educational Psychology Review, 4(4), 345–391. Schraw, G. (1998). Promoting general metacognitive awareness. Instructional Science, 26(1 2), 113–125. Schraw, G., & Moshman, D. (1995). Metacognitive theories. Educational Psychology Review, 7, 351-373. Schraw, G. (2001). Promoting general metacognitive awareness, H.J. Hartman (Eds.), Metacognition learning and ınstruction (pp. 3-16). USA: Kluwer Academic Publisher. Schraw, G., & Dennison, R.S. (1994). Assessing metacognitive awareness. Contemporary Educational Psychology, 19(4), 460–475. Schraw, G., Crippen, K.J., & Hartley, K. (2006). Promoting self-regulation in science education: Metacognition as part of a broader perspective on learning. Research in Science Education, 36(1-2), 111-139. Sinclair, B. (1999). Wrestling with a jelly: The evaluation of learner autonomy. In B. Morrison (Ed.), Experiments and evaluation in self-access language learning (pp. 95-109). Hong Kong: Hasald. Balcikanli, Cem - 1330 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 Sperling, R. A., Howard, B. C., Miller, L. A., & Murphy, C. (2002). Measures of children‟s knowledge and regulation of cognition. Contemporary Educationa Psychology, 27, 51-79. Stevens, K.W. (2009). Metacognition: Developing self-knowledge through guided reflection. Unpublished Doctoral Dissertation, University of Massachusetts, Massachusetts. Yıldız, E., Akpınar, E., Tatar, N., & Ergin, Ö. (2009). Exploratory and Confirmatory Factor Analysis of the Metacognition Scale for Primary School Students. Kuram ve Uygulamada Eğitim Bilimleri, 9 (3), 1591-1604. Young, A., & Fry, J.D. (2008). Metacognitive awareness and academic achievement in college students. Journal of the Scholarship of Teaching and Learning, 8(2), 1-10. Wenden, A. (1991). Learner strategies for learner autonomy. London: Prentice Hall International. Wenden, A. (1999). Special issue on metacognitive knowledge and beliefs in language learning. System, 27(4), 435-441. Wilkins, L.S. (1997). Fostering independence with metacognition. In L. Dickinson (Ed), Autonomy 2000: The development of learning independence in language learning, Bangkok: King Mongkut‟s Institute of Technology Thonburi. Zellers, M., & Mudrey, R.R. (2007). Electronic portfolios and metacognition: A phenomenological examination of the implementation of e-portfolios from the instructors‟ perspective. International Journal of Instructional Media, 34(4), 419–430. Inventario de Conciencia Metacognitiva para Docentes (MAIT) Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 - 1331 - APPENDIX __________________________________________________________________________ Metacognitive Awareness Inventory for Teachers (MAIT) The MAIT is a list of 24 statements. There are no right or wrong answers in this list of state-ments. It is simply a matter of what is true for you. Read every statement carefully and choose the one that best describes you. Thank you very much for your participation. 1= Strongly Disagree 2= Disagree 3= Neutral 4= Agree 5= Strongly Agree 1. I am aware of the strengths and weaknesses in my teaching. 1 2 3 4 5 2. I try to use teaching techniques that worked in the past. 1 2 3 4 5 3. I use my strengths to compensate for my weaknesses in my teaching. 1 2 3 4 5 4. I pace myself while I am teaching in order to have enough time. 1 2 3 4 5 5. I ask myself periodically if I meet my teaching goals while I am teaching. 1 2 3 4 5 6. I ask myself how well I have accomplished my teaching goals once I am fin-ished. 1 2 3 4 5 7. I know what skills are most important in order to be a good teacher. 1 2 3 4 5 8. I have a specific reason for choosing each teaching technique I use in class. 1 2 3 4 5 9. I can motivate myself to teach when I really need to teach. 1 2 3 4 5 10. I set my specific teaching goals before I start teaching. 1 2 3 4 5 11. I find myself assessing how useful my teaching techniques are while I am teaching. 1 2 3 4 5 12. I ask myself if I could have used different techniques after each teaching experience. 1 2 3 4 5 13. I have control over how well I teach. 1 2 3 4 5 14. I am aware of what teaching techniques I use while I am teaching. 1 2 3 4 5 15. I use different teaching techniques depending on the situation. 1 2 3 4 5 16. I ask myself questions about the teaching materials I am going to use. 1 2 3 4 5 17. I check regularly to what extent my students comprehend the topic while I am teaching. 1 2 3 4 5 18. After teaching a point, I ask myself if I‟d teach it more effectively next time. 1 2 3 4 5 19. I know what I am expected to teach. 1 2 3 4 5 20. I use helpful teaching techniques automatically. 1 2 3 4 5 21. I know when each teaching technique I use will be most effective. 1 2 3 4 5 22. I organize my time to best accomplish my teaching goals. 1 2 3 4 5 23. I ask myself questions about how well I am doing while I am teaching. 1 2 3 4 5 24. I ask myself if I have considered all possible techniques after teaching a point. 1 2 3 4 5 Balcikanli, Cem - 1332 - Electronic Journal of Research in Educational Psychology, 9(3), 1309-1332. ISSN: 1696-2095. 2011, no. 25 [Page intentionnally left blank]\n\nTitle: [PDF] Metacognitive Awareness Inventory\nURL: https://www.rcsj.edu/Tutoring-site/Gloucester-site/Documents/Metacognitive%20Awareness%20Inventory.pdf\nContent: A student practicing metacognition would ask him/herself “How am I thinking?” or “Where am I in the learning process? Students who are metacognitively aware demonstrate self-knowledge: They know what strategies and conditions work best for them while they are learning. I know what kind of information is most important to learn. I find myself using helpful learning strategies automatically. I ask myself if I learned as much as I could have once I finish a task. I know what kind of information is most important to learn. I find myself using helpful learning strategies automatically. Total /7 Total /7 Information Management Strategies Score 9. I ask myself if I learned as much as I could have once I finish a task.\nRaw Content: Academic Support Center * ASC 603 * 856-681-6250 * rcsj.edu/tutoring/gloucester Metacognitive Awareness Inventory What is Metacognition? The simplest definition of metacognition is “thinking about thinking.” This refers to the “self-regulation” that effective learners exhibit, meaning they are aware of their learning process and can measure how efficiently they are learning as they study. Essentially, metacognition involves two simultaneous levels of thought: the first level is the student’s thinking/learning about the specific subject content and the second level is the student’s thinking about his/her learning. A student practicing metacognition would ask him/herself “How am I thinking?” or “Where am I in the learning process? Am I learning/understanding this topic? How could I learn more effectively?” These two levels are: knowledge and regulation. Students who are metacognitively aware demonstrate self-knowledge: They know what strategies and conditions work best for them while they are learning. Declarative, procedural, and conditional knowledge are essential for developing conceptual knowledge (content knowledge). Regulation refers to students’ knowledge about the implementation of strategies and the ability to monitor the effectiveness of their strategies. When students regulate, they are continually developing and monitoring their learning strategies based on their evolving self-knowledge. Complete the Metacognitive Awareness Inventory to assess your metacognitive processes. The Inventory Check True or False for each statement below. After you complete the inventory, use the scoring guide. Contact an Academic Coach at the Academic Support Center at (856) 681-6250 to discuss your results and strategies to increase your metacognitive awareness. True False 1. I ask myself periodically if I am meeting my goals. 2. I consider several alternatives to a problem before I answer. 3. I try to use strategies that have worked in the past. 4. I pace myself while learning in order to have enough time. 5. I understand my intellectual strengths and weaknesses. Academic Support Center * ASC 603 * 856-681-6250 * rcsj.edu/tutoring/gloucester 6. I think about what I really need to learn before I begin a task. 7. I know how well I did once I finish a test. 8. I set specific goals before I begin a task. 9. I slow down when I encounter important information. 10. I know what kind of information is most important to learn. 11. I ask myself if I have considered all options when solving a problem. 12. I am good at organizing information. 13. I consciously focus my attention on important information. 14. I have a specific purpose for each strategy I use. 15. I learn best when I know something about the topic. 16. I know what the teacher expects me to learn. 17. I am good at remembering information. 18. I use different learning strategies depending on the situation. 19. I ask myself if there was an easier way to do things after I finish a task. 20. I have control over how well I learn. 21. I periodically review to help me understand important relationships. 22. I ask myself questions about the material before I begin. 23. I think of several ways to solve a problem and choose the best one. 24. I summarize what I’ve learned after I finish. 25. I ask others for help when I don’t understand something. 26. I can motivate myself to learn when I need to. 27. I am aware of what strategies I use when I study. 28. I find myself analyzing the usefulness of strategies while I study. 29. I use my intellectual strengths to compensate for my weaknesses. 30. I focus on the meaning and significance of new information. 31. I create my own examples to make information more meaningful. 32. I am a good judge of how well I understand something. 33. I find myself using helpful learning strategies automatically. 34. I find myself pausing regularly to check my comprehension. 35. I know when each strategy I use will be most effective. 36. I ask myself how well I accomplish my goals once I’m finished. 37. I draw pictures or diagrams to help me understand while learning. 38. I ask myself if I have considered all options after I solve a problem. 39. I try to translate new information into my own words. 40. I change strategies when I fail to understand. 41. I use the organizational structure of the text to help me learn. 42. I read instructions carefully before I begin a task. 43. I ask myself if what I’m reading is related to what I already know. 44. I reevaluate my assumptions when I get confused. 45. I organize my time to best accomplish my goals. Academic Support Center * ASC 603 * 856-681-6250 * rcsj.edu/tutoring/gloucester 46. I learn more when I am interested in the topic. 47. I try to break studying down into smaller steps. 48. I focus on overall meaning rather than specifics. 49. I ask myself questions about how well I am doing while I am learning something new. 50. I ask myself if I learned as much as I could have once I finish a task. 51. I stop and go back over new information that is not clear. 52. I stop and reread when I get confused. Schraw, G. & Dennison, R.S. (1994). Assessing metacognitive awareness. Contemporary Educational Psychology, 19, 460-475. Metacognitive Awareness Inventory Scoring Guide Directions: Score every “true” answer as 1 point each. Score every “false” answer as 0 points each. Add up the total in each column and place it over the points possible. For example, if I have 5 true answers and 3 false answers in one chart. The total score for that chart would be 5/8. Knowledge about Cognition Declarative Knowledge Score 5. I understand my intellectual strengths and weaknesses. 10. I know what kind of information is most important to learn. 12. I am good at organizing information. 16. I know what the teacher expects me to learn. 17. I am good at remembering information. 20. I have control over how well I learn. 32. I am a good judge of how well I understand something. 46. I learn more when I am interested in the topic. Total /8 Procedural Knowledge Score Conditional Knowledge Score 3. I try to use strategies that have worked in the past. 15. I learn best when I know something about the topic. 14. I have a specific purpose for each strategy I use. 18. I use different learning strategies depending on the situation. 27. I am aware of what strategies I use when I study. 26. I can motivate myself to learn when I need to. Academic Support Center * ASC 603 * 856-681-6250 * rcsj.edu/tutoring/gloucester 33. I find myself using helpful learning strategies automatically. 29. I use my intellectual strengths to compensate for my weaknesses. 35. I know when each strategy I use will be most effective. Total /4 Total /5 Regulation of Cognition Planning Score Comprehension Monitoring Score 4. I pace myself while learning in order to have enough time. 1. I ask myself periodically if I am meeting my goals. 6. I think about what I really need to learn before I begin a task. 2. I consider several alternatives to a problem before I answer. 8. I set specific goals before I begin a task. 11. I ask myself if I have considered all options when solving a problem. 22. I ask myself questions about the material before I begin. 21. I periodically review to help me understand important relationships. 23. I think of several ways to solve a problem and choose the best one. 28. I find myself analyzing the usefulness of strategies while I study. 42. I read instructions carefully before I begin a task. 34. I find myself pausing regularly to check my comprehension. 45. I organize my time to best accomplish my goals. 49. I ask myself questions about how well I am doing while learning something new. Total /7 Total /7 Information Management Strategies Score 9. I slow down when I encounter important information. 13. I consciously focus my attention on important information. 30. I focus on the meaning and significance of new information. 31. I create my own examples to make information more meaningful. 37. I draw pictures or diagrams to help me understand while learning. 39. I try to translate new information into my own words. 41. I use the organizational structure of the text to help me learn. 43. I ask myself if what I’m reading is related to what I already know. 47. I try to break studying down into smaller steps. 48. I focus on overall meaning rather than specifics. Total /10 Debugging Strategies Score Evaluation Score 25. I ask others for help when I don’t understand something. 7. I know how well I did once I finish a test. 40. I change strategies when I fail to understand. 18. I ask myself if there was an easier way to do things after I finish a task. Academic Support Center * ASC 603 * 856-681-6250 * rcsj.edu/tutoring/gloucester Schraw, G. & Dennison, R.S. (1994). Assessing metacognitive awareness. Contemporary Educational Psychology, 19, 460-475. 44. I re-evaluate my assumptions when I get confused. 24. I summarize what I’ve learned after I finish. 51. I stop and go back over new information that is not clear. 36. I ask myself how well I accomplish my goals once I’m finished. 52. I stop and reread when I get confused. 38. I ask myself if I have considered all options after I solve a problem. 49. I ask myself if I learned as much as I could have once I finish a task. Total /5 Total /6\n\nTitle: [PDF] Psychometric properties of the Metacognitive Awareness Inventory ...\nURL: https://metacog-global.com/wp-content/uploads/2025/02/Gutierrez-de-Blume-et-al.-in-press-Standardization-of-MAI-in-Spanish-5.pdf\nContent: Vol.:(0123456789) Metacognition and Learning https://doi.org/10.1007/s11409-024-09388-9 1 3 Psychometric properties of the Metacognitive Awareness Inventory (MAI): standardization to an international spanish with 12 countries Antonio P. 1 3 Table 1 Research regarding the psychometric properties of the metacognitive awareness inventory Key: KoC Knowledge of Cognition, RoC Regulation of Cognition Authors Country Language Sample Size Cronbach’s α Version Akın et al. Russia Russian N=527 KoC=.81 RoC=.82 Final version with only 32 of the original 52 items Psychometric properties of the Metacognitive Awareness… 1 3 Table 2 Research regarding the psychometric properties of the metacognitive awareness inventory in spanish-speaking countries Key: KoC Knowledge of Cognition, RoC Regulation of Cognition Authors Country Participants Sample Size Cronbach’s α Version Huertas et al.\nRaw Content: Vol.:(0123456789) Metacognition and Learning https://doi.org/10.1007/s11409-024-09388-9 1 3 Psychometric properties of the Metacognitive Awareness Inventory (MAI): standardization to an international spanish with 12 countries Antonio P. Gutierrez de Blume1 · Diana Marcela Montoya Londoño2 · Virginia Jiménez Rodríguez3 · Olivia Morán Núñez4 · Ariel Cuadro5 · Lilián Daset5 · Mauricio Molina Delgado6 · Claudia García de la Cadena7 · María Beatríz Beltrán Navarro8 · Aníbal Puente Ferreras3 · Sebastián Urquijo9 · Walter Lizandro Arias10 Received: 9 January 2024 / Accepted: 26 May 2024 © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024 Abstract Metacognition is defined as a higher-order thinking skill that enables individuals to moni-tor, control, and regulate their thinking and behavior. In education, this skill is important, as learners need to self-regulate their learning behaviors for successful lifelong learning. Thus, it is essential for educators and learners alike to know their metacognitive skills. Research-ers can assist in this endeavor by developing sound and valid quantitative measures for psy-chological phenomena such as metacognition. No measure is more commonly used for this purpose than the Metacognitive Awareness Inventory (MAI). In the present study, the Inter-national Group on Metacognition validated the MAI employing a standard, international Spanish with a robust sample of 12 Spanish-speaking countries and 1,622 undergraduate uni-versity students. Results revealed a solid final baseline confirmatory factor analysis model for all 12 countries that supports the original two-factor structure reported in English-speaking samples from the United States. Additionally, multigroup measurement invariance analyses revealed that although five parameters varied slightly across some countries, chi-square dif-ference tests indicated that the comparison model with these constraints freely estimated was not significantly better than the fully constrained null model, supporting measurement invari-ance across countries. Thus, our version of the MAI using standard, international Spanish is a valid and reliable tool for measuring metacognitive awareness in Spanish-speaking countries.\nKeywords International spanish validation · Metacognition · Subjective metacognitive awareness · Self-regulated learning Introduction Metacognition has been generally defined as a higher-order thinking skill that involves monitoring and control of one’s cognitive resources, and it is recognized as a major component of self-regulated learning (Dinsmore et al., 2008; Efklides, 2006, 2008; Extended author information available on the last page of the article A. P. Gutierrrez de Blume et al.\n1 3 Gutierrez & Schraw, 2015; Gutierrez de Blume et al., 2020; Schraw & Dennison, 1994; Schraw, 1998; Winne & Azevedo, 2014). Schraw and Dennison (1994) were the first to introduce the notion of metacognitive awareness (i.e., the Metacognitive Awareness Inventory [MAI]), a specific metacognitive phenomenon, which they defined as individuals’ perceptions of their own metacognitive skills. In their seminal study, they developed the first self-report instrument of metacognitive awareness with a sample of 197 university undergraduate students. The 52-item measure was found to be comprised of two higher-order factors of knowledge of cognition (incorporating declarative, procedural, and conditional knowledge) and regulation of cognition (subsuming planning, monitoring, information management, debugging, and evaluation). While the MAI has a long history of being translated and employed in various cultures and languages, previous research has only tested the viability of the measure using single samples from their respective populations. Nevertheless, researchers have assumed that the results of these studies generalized to the entire population without empirically testing this claim. To address this research gap, the present study employed the Spanish-version of the MAI that was developed using an international Spanish among a sample of 1,622 university undergraduate students from 12 Spanish-speaking countries in Latin America and Spain.\nBackground Different researchers propose that studies on metacognition constitute one of the most prom-ising alternatives to generate a change in training processes, to the extent that their promotion in the classroom favors a higher level of self-awareness of students about their own learning processes and cognitive resources. Metacognition: 1) allows one to know oneself and reflect on one’s own capabilities and preferences in the face of learning demands; 2) allows one to identify possible difficulties and problems as well as select the best strategies to solve them; and 3) monitor and employ evaluation and planning processes of learning behavior, in a per-spective of self-regulation of learning, which favors the development of one’s own agency (Cheng & Chan, 2021; Pandey & Mohan, 2023; Schraw, 2009a; Veenman et al., 2014). In fact, researchers have argued that a person’s metacognitive performance is the greatest pre-dictor of their learning potential (Veenman et al., 2006; Wang et al., 1990). The development of the capacity for agency is based on the idea that it allows us to recognize that people are capable of making metacognitive evaluations about the control they have over the results of their own actions and about when to execute them, and is oriented towards the capacity of exercising control over the nature of one’s own quality of life; in this case, associated with learning behavior (Bandura, 2001; Metcalfe & Greene, 2007).\nFrom this perspective, the development and evaluation of metacognitive abilities is essential to face the demands of the development of contemporary thinking. This is often characterized by the need to train the person in the skills necessary to acquire new, complex knowledge and to build and access deep learning processes, given the changing dynamics of the global labor market. In this context, professions and jobs increasingly involve evolv-ing roles that require problem-solving skills, thinking independent and creative profession-als, as well as development of skills to enhance metacognitive thinking and self-regulated learning (Double & Birney, 2019; Dunlosky & Rawson, 2019; Ozturk, 2017; Pintrich et al., 2000; Quinn et al., 2021; Winne & Perry, 2005; Zohar & Dori, 2012, Zohar, 2020).\nIn general, metacognition is considered a higher-order executive thinking process (Flores-Lázaro et al., 2014a, 2014b; Flores et al., 2008; Follmer & Sperling, 2016; Psychometric properties of the Metacognitive Awareness… 1 3 Livingston, 2003; Veenman et al., 2006), which involves knowledge and regulation of the activity of cognitive processes and products (Flavell, 1976). Likewise, it represents a critical, reflective thinking process that shows the level of consciousness that people reach in relation to their own learning. This involves understanding and manipulating one’s own cognitive abilities to perform more efficiently and effectively (Schraw & Dennison, 1994; Serra & Metcalfe, 2009; Zohar, 2020).\nMetacognitive knowledge is understood as everything that the individuals know about themselves as learners (declarative knowledge), everything they know about how they can do it, which includes the use of learning strategies (procedural knowledge), and about when, where, and why to use the knowledge that tasks require (conditional or strategic knowledge), and it is considered the basis of individuals’ regulation processes (Brown, 1987; Cross & Paris, 1988; Garner, 1990; Schraw & Dennison, 1994; Ozturk, 2017; Pin-trich et al., 2000; Schraw, 1998, 2002; Veenman et al., 2006; Zohar, 2020).\nOn the other hand, metacognitive regulation refers to the way in which individuals control their cognitive activity; therefore, it involves the type of practical strategies that individuals use to regulate and monitor their own resources and processes, as well as the results of their learning. Regulatory skills are: 1) planning (which involves anticipation, setting objectives, choosing strategies, designing a sequence of steps, allocation of time and resources, etc.); 2) follow-up, also called monitoring skill (involves online supervision of the task in progress, which requires processes such as testing, rehearsal, review, adjust-ment, and awareness of the state of performance); and, finally, 3) evaluation (which can be understood as a value judgment regarding one’s own performance, which involves the com-parison between the objectives and the result, and the analysis of the use of the strategies and their level of effectiveness, both the process and the product obtained are evaluated) (Brown, 1987; Cheng & Chan, 2021; Jacobs & Paris, 1987; Schraw & Dennison, 1994).\nIn the present study, we focus on learners’ metacognitive knowledge and regulation as measured by the MAI (Schraw & Dennison, 1994) because it is widely considered the gold standard for measuring the construct (Akın et al., 2007; Harrison & Vallin, 2018). This instrument has been used in almost all existing languages with adequate Cronbach’s alpha coefficients and construct validity outcomes. Table 1 shows some of the main background studies on the psychometric properties of the MAI in the case of university students.\nThe MAI is the most used instrument to evaluate self-report metacognitive knowledge and regulation in different languages due to its easy and quick administration, as well as its collective application (which saves time for the researcher) and low cost. In this context, although it is a tool that was originally created in English (Schraw & Dennison, 1994) and has been translated into almost all languages, the studies referring to the validation and standardization of the MAI in Spanish are scarce and incongruent regarding their results. Table 2 presents research attempts to adapt the instrument to the specifications of the Span-ish language.\nThe present study constitutes the first effort to adapt and standardize the MAI (Schraw & Dennison, 1994) into a standard, international Spanish that can be used with confidence to evaluate undergraduate university students in different cultural contexts in Ibero-Amer-ica. For this purpose, the researchers employed a process of translation, back translation, and agreement on the most appropriate linguistic form of the different items, so that their use could be relevant in different cultural contexts and Spanish-speaking countries, a pro-cess in which the guidelines proposed by the International Test Commission (ITC) were considered to search for psychometric evaluation tasks at an international level (Elosua, 2017; Hambleton, 1996; Hernández et al., 2022; Muñiz et al., 2013, 2015, 2016). A. P. Gutierrrez de Blume et al.\n1 3 Table 1 Research regarding the psychometric properties of the metacognitive awareness inventory Key: KoC Knowledge of Cognition, RoC Regulation of Cognition Authors Country Language Sample Size Cronbach’s α Version Akın et al. (2007).\nTurkey Turkish N=607 Full Scale, .95 Final version with 52 items Lima Filho & Bruni (2015) Brazil Portuguese N= 1,058 KoC=.83 RoC=.84 Final version with 52 items Masoodi (2020) Lithuania Farsi N Lithuania=296 Iran=459 N total=755 Full Scale= 88 KoC=.85 RoC=.92 Final version with 52 items Xethakis (2020).\nJapan Japanese N=729 KoC=.84 RoC=.84 Final version with 52 items Omprakash et al. (2021) India Hindi, English N=933 Full Scale, .93 Final version with only 40 of the original 52 items Perikova & Byzova (2022).\nRussia Russian N=527 KoC=.81 RoC=.82 Final version with only 32 of the original 52 items Psychometric properties of the Metacognitive Awareness… 1 3 Table 2 Research regarding the psychometric properties of the metacognitive awareness inventory in spanish-speaking countries Key: KoC Knowledge of Cognition, RoC Regulation of Cognition Authors Country Participants Sample Size Cronbach’s α Version Huertas et al. (2014) Colombia Middel School and High School Students (14-18 years) N=536 Full Scale=.94 Validated final version on the 52 items, rating form on a Likert Scale from: 1. Completely disagree, to 5. Com-pletely agree.\nUlloa Ordaya (2019) Peru Middle School and High School Students (11-18 years) N=554 McDonald’s Omega (in lieu of α) KoC ω=.886 RoC ω=.934 Validated final version on the 52 items, rating form on a Likert Scale from: 1. Completely disagree, to 5. Com-pletely agree.\nGutierrez de Blume & Mon-toya Londoño (2021) Colombia Undergraduate University Students in Education (20- 30 years) N=528 KoC=.86 RoC=.93 McDonald’s Coefficient KoC ω=.83 RoC ω=.90 Validated final version on the 52 items, the score for each item was marked on a vertical bar in the form of a continuous bipolar line from 0-100 (where 0 represents “not at all true for me” to 100 which means “very true for me.”) González-Cabañes et al. (2022) Spain Undergraduate University Students (17- 54 years) N=1,076 Study 1 KoC=.81 RoC=.77 Study 2 KoC=.81 RoC=.81 Validated final version on only 19 of the original 52 items, on a Likert scale from 5 as “very typical of me” to 1 = “not at all typical of me”). A. P. Gutierrrez de Blume et al.\n1 3 Method Participants The study employed a convenience sampling approach in which 1,622 undergraduate stu-dents from 12 Latin American cultures and one European culture (Spain) participated. Participants were pursuing an undergraduate degree during the year 2021-2022 and all of them voluntarily agreed to participate in the study. No incentives were provided to partici-pants for their inclusion in the study.\nRegarding gender, 699 identified as male and 923 as female. All students met the fol-lowing inclusion criteria: 1) age between 18 and 25 years (M = 20.93; Median = 20; SD = 6.01); 2) absence of repetition or school lag; and 3) they had to have completed informed consent for their involvement in the research process. Thus, the sociodemographic-variable distribution was typical of each of the participating universities. Table 3 includes addi-tional sociodemographic characteristics of the sample.\nProcedure Process Phase 1) Translation, review, and development stage of the test: First, the original English language instrument was consulted, available and freely accessible to the researchers, through the publication of the original research study (Schraw & Dennison, 1994). Next, this original version was reviewed in its final form to begin the translation process by one of the group’s researchers, who was trained directly in his doctoral studies by one of the original authors of the MAI, Dr. Gregory Schraw. The original English version we employed for translation is displayed in Appendix A and the Spanish version we translated using the translation-back translation method is found in Appendix B. Subsequently, for the translation and back-translation process of the final form of the test in Spanish, a commission was formed from the International Metacognition Group (https://​ metac​ og-​ global.​ com) made up of 22 experts in research centered on metacognition, 20 with doctoral degrees, and two doctoral students, among whom are psychologists, a graduate in pedagogy, a statistician, and an anthropologist, and some of these researchers with competence in both languages (Spanish and English). An extensive process of adapting the items was executed, including reviewing the forms, equivalences, and linguistic correction. The final form of the test approved by the 22 researchers was compared with previous psychometric studies of the instrument already published and available in Spanish for its original form of 52 items (Gutierrez de Blume & Montoya Londoño, 2021; Huertas et al., 2014; Muñiz et al., 2016; Ulloa Ordaya, 2019). However, the present study included a sample of students from a signifi-cant number of Spanish-speaking countries: Argentina, Chile, Uruguay, Bolivia, Peru, Panama, Colombia, Mexico, Costa Rica, Guatemala, Puerto Rico, Spain, and Ecuador. For the final translated version, the format of the items, the response scale, and the method of administration and scoring of the tool were modified from the original Eng-lish version (Schraw & Dennison, 1994). Rather than rely on an ordinal Likert scale, we employed a truly continuous scale from 0-100 for each item, instructing participants Psychometric properties of the Metacognitive Awareness… 1 3 that any value from 0-100 was valid, and we employed two qualitative anchors on each extreme of the continuum: “0 indicates the statement is not at all true of me”; and “100 indicates the statement is completely true of me”. Per the advice of Schraw (2009b), using truly continuous (ratio) scales is superior to ordinal Likert scales, and it improves psychometric parameters of measurement, an approach that was successful in previous studies (Gutierrez & Price, 2017; Gutierrez & Schraw, 2015). In addition, a pilot study was conducted, a process in which it was verified that the items were understood by students from the countries that were included in the study, with an approximate time to complete the items between 20 and 30 minutes. This pilot study included 75 university undergraduate students in which a Google Form was distributed with open-ended ques-tions related to clarity of individual items.\n2) Confirmation and test application stage: Prior to full-scale administration, we evaluated the psychometric properties of the proposed version, adjusted to standard, international Spanish. For this process, we relied on the Standards for Educational and Psychological Testing’s (AERA et al., 2014) guidelines for establishing validity evidence via an exploratory factor analysis, with common factor extraction and an oblique rotation, given that the factors were expected to be highly correlated. In this psychometric analysis of the pilot test, the evaluation of the Table 3 Sociodemographic variables of the sample N = 1,461 Variable Frequency % Highest Educational Level of the Family Grade/Elementary School 138 9.4 High School or Equivalent 357 18.9 Professional Degree 312 15.9 Vocational Degree 151 10.3 Some College 147 10.1 Baccalaureate Degree 300 20.5 Graduate Degree (Masters or Doctorate) 217 14.9 Year at University First 484 33.1 Second 374 25.6 Third 357 19.0 Fourth 265 12.6 Fifth 142 9.7 Type of University State-subsidized/Public 975 61.1 Private 647 38.9 Academic Program of Study Natural Sciences 237 16.2 Social Sciences 863 59.1 Developmental and Construction Sciences 125 8.6 Fine Arts and Humanities 155 5.1 Health Sciences 171 6.2 Other 71 4.9 A. P. Gutierrrez de Blume et al.\n1 3 items showed adequate anticipated internal structure of the MAI, with Cronbach’s alpha coefficients ranging from .794 to .911, showing correlations in the expected theoretical direction (i.e., positive). In all countries, the application of the test was done by the main researchers of the study, almost all of them with a postgraduate degree or doctorate in psychology, or related areas, who had extensive experience in the application of psychometric tests. The process in which the proposed guidelines for the application of this type of task in educational contexts were also considered (Hambleton, 1996).\n3) Stage of establishing scores and interpretation: Field work was done with the application of the MAI with samples of students from all participating countries. For this purpose, students from different universities where there was a researcher who was participating in the standardization process from their respective country were recruited. Sampling was by convenience and the students were recruited by the researcher responsible for each country, who first held a meeting to explain the objective of the study and administer the informed consent process. Once informed consent was understood and signed by the students who agreed to participate, there was support from teachers from said universities, who authorized the administra-tion of the instrument collectively in their classes during the first and second semester of 2022. The application of the instrument was administered with the directions and guidelines given by the country’s researcher and online, through a questionnaire that was uploaded to the Qualtrics platform (link to the elect​ ronic​ surve​ y ), with an approximate duration of half an hour. Participants were permitted to toggle back and forth between pages of the Qualtrics survey and items were offered in blocks to avoid fatigue. The ethical guidelines for conducting research with human participants of each respective country were adopted for informed consent.\nData analysis Before performing the data analysis process, outlier detection and assumption testing pro-cedures were performed, such as univariate and multivariate normality tests, reproducibil-ity of correlation matrices, and lack of multicollinearity. The data did not contain univariate or multivariate outliers and they met all the required statistical assumptions, except multi-variate normality (Mardia’s Normalized Estimate [MNE] = 20.636). Therefore, corrections were necessary for this violation of multivariate normality. According to Bentler (2005), any value greater than six for MNE is considered a multivariate value that does not com-ply with the principles of multivariate normality, and a greater distance from six indicates greater degrees of lack of multivariate normality, which is why robust maximum likelihood (RML) statistics, instead of normally distributed statistics, were used. RML statistics adjust the standard errors of parameter estimates to account for the magnitude of multivariate nonnormality; that is, through this procedure a greater adjustment of the standard errors is made for more serious violations of multivariate normality. The EQS 6.4 software (Bentler, 2005) was used to perform a standard confirmatory factor analysis (CFA).\nWe randomly split the total sample of 1,622 participants into two separate samples using the random number generator subcommand in SPSS 28. This yielded two randomly generated samples of participants, each sample consisting of 811 cases. First, we employed Sample 1 for initial calibration sample analyses, as we describe next. Subsequently, we Psychometric properties of the Metacognitive Awareness… 1 3 conducted cross-validation analyses with Sample 2 to examine whether the CFA model we evaluated in Sample 1 is valid in a different sample from the same population.\nAdjusted RML goodness-of-fit indices (*NNFI, *CFI, *IFI) ≥ .90 suggest an adequately fitting model, and those ≥ .95 suggest excellent fit of the model to observed data. With respect to residuals, standardized root mean square residual (SRMR) values ≤ .08 suggest reasonable errors in estimating model parameters and root mean square error of approxi-mation (*RMSEA) values ≤ .08 suggest that the model parameters approximate those of the population adequately and those < .05 suggest good fit to the data (Byrne, 2006; Kline, 2005). Dillon-Goldstein’s rho (ρ) was also used to assess the overall or composite reliabil-ity of the model. Rho measures how well the manifest/indicator v"
      },
      {
        "type": "text",
        "text": "\n\n[OUTPUT TRUNCATED - exceeded 25000 token limit]\n\nThe tool output was truncated. If this MCP server provides pagination or filtering tools, use them to retrieve specific portions of the data. If pagination is not available, inform the user that you are working with truncated output and results may be incomplete."
      }
    ]
  }
]

---

### User
> 11/30/2025, 3:48:19 PM

[
  {
    "tool_use_id": "toolu_01FTvntJ3UwXYWV2sW3yShNB",
    "type": "tool_result",
    "content": [
      {
        "type": "text",
        "text": "Detailed Results:\n\nTitle: (PDF) Behavior Rating Inventory of Executive Function\nURL: https://www.academia.edu/21409975/Behavior_Rating_Inventory_of_Executive_Function_Adult_Version_BRIEF_A_\nContent: The Behavior Rating Inventory of Executive Function - Adult Version (BRIEF-A) is developed to assess executive functioning in adults through a detailed\n\nTitle: Brief A | PDF | Executive Functions | Mental Disorder\nURL: https://www.scribd.com/document/874775810/BRIEF-A\nContent: The Behavior Rating Inventory of Executive Function-Adult ... BRIEF: Behavior Rating Inventory of Executive Function. Lutz, Florida: Psychological Assessment\nRaw Content: ![Scribd](data:image/svg+xml;base64,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)\n\n# Brief A\n\nBrief A\n\n## Uploaded by\n\nAI-enhanced title\n\n# Brief A\n\n# Brief A\n\nBrief A\n\n## Uploaded by\n\nAI-enhanced title\n\n## Share this document\n\n![]()\n\n## Footer menu\n\nAbout\n\nSupport\n\nLegal\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nAbout\n\nLegal\n\nSupport\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nTitle: Behavior Rating Inventory of Executive Function - Adult ...\nURL: https://www.researchgate.net/publication/283461640_Behavior_Rating_Inventory_of_Executive_Function_-_Adult_Version_BRIEF-A\nContent: The Behavior Rating Inventory of Executive Function-Adult is a 75-item scale designed to measure aspects of executive functions (Roth et al.,\n\nTitle: The Behavior Rating Inventory of Executive Function- Adult ...\nURL: https://www2.psy.unsw.edu.au/Users/smcdonald/Resources/Social%20Behaviour/Behavior%20Rating%20Inventory%20of%20Executive%20Function%20-%20Adult%20Version%20(BRIEF-A).pdf\nContent: The BRIEF-A is composed of 75 items within nine theoretically and empirically derived clinical scales that measure various aspects of executive functioning;\nRaw Content: Outcome Measure Behavior Rating Inventory of Executive Function - Adult Version (BRIEF-A) Sensitivity to Change No information available Population Adult How to obtain Available from https://paa.com.au/product/brief-a/ for purchase Domain Behavioural Function Type of Measure Informant and/or Self-ratings Time to administer 10-15 minutes Description The BRIEF-A is a standardised measure that captures views of an adult's executive functions or self-regulation in his or her everyday environment. Two formats are used: a Self-report and an Informant report. Available from https://paa.com.au/product/brief-a/ The Self-report Form is completed by adults 18-90 years of age, including adults with a wide variety of developmental, systemic, neurological, and psychiatric disorders such as attention disorders, learning disabilities, autism spectrum disorders, traumatic brain injury, multiple sclerosis, depression, mild cognitive impairment, dementias, and schizophrenia. The BRIEF-A can be completed by an informant who has good knowledge of the person or as a self-rating. The BRIEF-A is composed of 75 items within nine theoretically and empirically derived clinical scales that measure various aspects of executive functioning; Inhibit, Self-Monitor, Plan/Organise, Shift, Initiate, Task Monitor, Emotional Control, Working Memory, Organisation of Materials. The clinical scales form two broader indexes: Behavioral Regulation (BRI) and Metacognition (MI), and these indexes form the overall summary score, the Global Executive Composite (GEC). The BRIEF-A also includes three validity scales (Negativity, Inconsistency, and Infrequency). The BRIEF-A takes approximately 10-15 minutes to administer. All 75 items are rated in terms of frequency on a 3-point scale: 0 (never), 1 (sometimes), 2 (often). Raw scores for each scale are summed and T scores (M = 50, SD = 10) are used to interpret the individual’s level of executive functioning. Properties The following information is reported in the manual: Inter-rater reliability: The correlation between Self-Report and Informant Report forms were moderate (.44-.68). Approximately 50-70% of individuals and their informants reported t-scores within one standard deviation of each other. A number of individuals rated themselves as having more difficulties than their informant (22.2% were between 1-2 SD higher, 6.7% were >2 SD higher), whereas only approximately 7% of individuals reported lower T-scores on the overall scale than their informants. Internal consistency: Cronbach’s alpha for the self-report form was moderate to high for the clinical scales (.73-.90) and high for the indexes and overall score (.93-.96). For the Informant Report, internal consistency was high, ranging from .80-.98 for the clinical scales, indexes and overall score. Test-retest reliability: Test re-test correlations for the Self-Report form ranged from .82-.94 for the clinical scales, indexes and overall score, with an average interval of 4.22 weeks. For the Informant Report, correlations ranged from .91-.94 for the clinical scales and correlations for the indexes and overall score were .96. Construct validity: Adults with clinical diagnoses (n=18) and a subset of informants (n=9) completed the BRIEF-A and the FrSBe. Moderate to strong correlations were obtained for the majority of scales and indexes. Importantly, the BRIEF-A indexes correlated significantly with the executive dysfunction scale of the FrSBe for both the self-report form (.63-.67) and informant-report form (.68-.74). 40 adults from a mixed healthy/clinical population completed the BRIEF-A and the DEX. Total score on the DEX correlated significantly with BRI (.84), MI (.73) and GEC (.84). Factor analysis of Self-Report Form data yielded a 2-factor solution (i.e., Behavioral Regulation, Metacognition) for normative and mixed clinical/healthy adult samples, accounting for 73% and 76% of the variance, respectively. Factor analysis of Informant Report Form data also yielded a similar 2-factor solution for the normative and mixed clinical/healthy adult samples, accounting for 81% and 78% of the variance, respectively. Concurrent validity: BRIEF-A Self-Report forms for 23 patients with TBI (60% mild, 10% moderate, 30% severe) were compared to 23 healthy individuals. Significant group differences were found for the GEC (η2 = .19), BRI (η2 =.23) and MI (η2 = .08), as well as the individual scales Shift (η2 = .14), Initiate (η2 = .17), Working Memory (η2 = .26), Plan/Organise (η2 =.22), and Task Monitor (η2 = .22). Advantages • It is a reasonably brief measure of self-reported and informant-reported EF difficulties. • Covers various aspects of EF and provides T scores for each scale. • Strong psychometric properties for each scale, as well as indexes and GEC. • Reasonably well priced. • Can be administered and scored by individuals who do not have formal training. Disadvantages • Must score by hand unless purchase computer scoring program. • Validated in U.S. normative sample. References: Roth, R. M., Isquith, P. K., & Gioia, G. A. (2005). BRIEF-A: Behavior Rating Inventory of Executive Function--adult Version: Professional Manual: Psychological Assessment Resources.\n\nTitle: Confirmatory Factor Analysis of the Behavior Rating Inventory ...\nURL: https://pmc.ncbi.nlm.nih.gov/articles/PMC3711374/\nContent: by RM Roth · 2013 · Cited by 289 — The Behavior Rating Inventory of Executive Function-Adult Version (BRIEF-A) is a questionnaire measure designed to assess executive functioning in everyday life\n\nTitle: Behavior Rating Inventory Of Executive Function Brief\nURL: http://www.dc.narpm.org/browse/mL0AD6/6001025/Behavior%20Rating%20Inventory%20Of%20Executive%20Function%20Brief.pdf\nContent: 4. Given their significance, accurate assessment of executive functions is vital. The BRIEF-. BRIEF serves this purpose by capturing real-world behaviors\n\nTitle: Behavior Rating Inventory of Executive Function - Adult ... - PAA\nURL: https://paa.com.au/product/brief-a/\nContent: York Assessment of Reading for Comprehension – Australian Edition Speech and Language Link Cognitive Abilities Test: Fourth Edition #### BRIEF-A online Interpretive Report (each) min order 5 BRIEF-A Self-Report / Informant Interpretive Reports online via PARiConnect with PAA. #### BRIEF-A online Score Report (each) min order 5 BRIEF-A Self-Report / Informant Score Reports online via PARiConnect with PAA. Self-report / Informant i-Admins for online administration of the BRIEF-A via PARiConnect with PAA. When administered in conjunction with the Self-Report Form, the BRIEF-A Informant Report Form provides a clinically comprehensive picture of the individual being rated. The BRIEF-A materials consist of the Professional Manual, the carbonless Self-Report Form, the carbonless Informant Report Form, the Self-Report Scoring Summary/Profile Form, and the Informant Report Scoring Summary/Profile Form.\nRaw Content: [Skip to content](#main)\n\n\n[About](https://paa.com.au/about-paa/) [Help and Support](https://paa.com.au/help-and-support/) [Blog](https://paa.com.au/blog/) [Contact Us](https://paa.com.au/contact-us/) [(02) 9589 0011](tel:+61295890011) [Log In](/login) [Sign Up](/sign-up) [My account](https://paa.com.au/my-account/) [Cart](https://paa.com.au/cart/)\n\n\n\n[Psychological](https://paa.com.au/product-catalogue/)\n\n[Forensic Assessments](https://paa.com.au/category/catalogue/forensic/)\n\n[Neuropsychological Assessments](https://paa.com.au/category//neuropsychological-assessments/)\n\n[Adult Clinical Assessments](https://paa.com.au/category//adult-mental-health-assessments/)\n\n[Infant, Child, Adolescent & Family Assessments](https://paa.com.au/category//child-adolescent-family-assessments/)\n\n[HR Assessments: Selection; Emotional Intelligence](https://paa.com.au/category//hr-recruitment-assessments/)\n\n[Autism & Related Disorders Assessments](https://paa.com.au/category//autism-related-disorders/)\n\n [Educational](https://paa.com.au/education/)\n\n[Educational Assessments](https://paa.com.au/category//educational/)\n\n[York Assessment of Reading for Comprehension – Australian Edition](https://paa.com.au/product/yarc-australian/) [Speech and Language Link](https://paa.com.au/product/speech-language-link/) [Cognitive Abilities Test: Fourth Edition](https://paa.com.au/product/cat-4/)\n\n[Educational Assessments (cont.)](#)\n\n[Woodcock Johnson Fourth Edition – Australasian Adaptation](https://paa.com.au/product/wj-iv/) [New Group Reading Test](https://paa.com.au/product/ngrt/) [New Group Spelling Test](https://paa.com.au/product/ngst/)\n\n[Autism & Related Disorders Assessments](https://paa.com.au/category//autism-related-disorders/)\n\n[Childhood Autism Rating Scale, Second Edition](https://paa.com.au/product/cars-2/)\n\n[My Virtual Reading Coach](https://paa.com.au/product/mvrc/)\n\n[My Virtual Reading Coach](https://paa.com.au/product/mvrc/)\n\n[PAA Education](https://paa.com.au/education/)\n\n [Direct](https://paa.com.au/direct)\n\n[PAA Direct Contact form](https://paa.com.au/paa-direct-contact-form/)\n\n[Blog](https://paa.com.au/blog/)\n\n[PAA Direct](https://paa.com.au/direct/)\n\n [Online Assessments](https://paa.com.au/online-assessments/)\n\n[MHS Assessment Centre+ (MAC+)](https://paa.com.au/online-assessments/mhs-assessment-centre-plus-products/)\n\n[MAC+ Account Help Page](https://paa.com.au/mac-plus/)\n\n[MHS Talent Assessment Portal (TAP)](https://paa.com.au/online-assessments/mhs-tap-products/)\n\n[WPS Online Evaluation System](https://paa.com.au/online-assessments/wps-online-evaluation-system-products/)\n\n[PARiConnect](https://paa.com.au/online-assessments/par-iconnect/)\n\n[Transition of PARiConnect Accounts from ACER to PAA](https://paa.com.au/transition-of-pariconnect-accounts-from-acer-to-paa/)\n\n[Testwise](https://paa.com.au/online-assessments/testwise-products/)\n\n[GL Ready](https://paa.com.au/online-assessments/gl-ready/)\n\n[All Online Assessments](https://paa.com.au/online-assessments/)\n\n[Ability/Aptitude](https://paa.com.au/category/education/ability_aptitude/)\n\n[Education](https://paa.com.au/category/education/)\n\n[User Level A, B](https://paa.com.au/user-levels-overview/)\n\n[Continue Browsing →](https://paa.com.au/product-catalogue/)\n\n## Behavior Rating Inventory of Executive Function – Adult Version [BRIEF-A]\n\nAssess adult executive functioning/self-regulation\n\n**For Ages:** 18 – 90 years  \n**Administration Time:** 10 – 15 minutes  \n**Format & Scoring:** [Online administration and scoring via PARiConnect](https://paa.com.au/online-assessments/par-iconnect/); Paper and pencil  \n**Authors:** Robert M. Roth, PhD, Peter K. Isquith, PhD, Gerard A. Gioia, PhD  \n   \nManuals available in hard copy (book) or **[electronic version (e-Manual)](https://paa.com.au/help-and-support/par-e-manuals-faqs/)**\n\n### New version of BRIEF-A (BRIEF2-A) now available.\n\n[Shop BRIEF2-A now](https://paa.com.au/product/brief2-a/)\n\n### Online Forms, Reports, Kits & e-Manuals\n\nAll online resources including Forms, Reports, i-Admins, Kits and e-Manuals.\n\n4 Items\n\nSort by\n\n← Back to Product Description\n\n#### BRIEF-A e-Manual\n\n10077-EM\n\n$218.35\n\n$218.35 inc GST\n\n#### BRIEF-A online Interpretive Report (each) min order 5\n\n10411-II\n\nBRIEF-A Self-Report / Informant Interpretive Reports online via PARiConnect with PAA.\n\n$7.70\n\n$7.70 inc GST\n\n#### BRIEF-A online Score Report (each) min order 5\n\n10410-IS\n\nBRIEF-A Self-Report / Informant Score Reports online via PARiConnect with PAA.\n\n$6.60\n\n$6.60 inc GST\n\n#### BRIEF-A online i-Admin (each) min order 5\n\n10409-IC\n\nSelf-report / Informant i-Admins for online administration of the BRIEF-A via PARiConnect with PAA.\n\n$8.25\n\n$8.25 inc GST\n\n← Back to Product Description\n\nThe BRIEF-A is a standardised measure that captures views of an adult’s executive functions or self-regulation in his or her everyday environment. Both a self-report and an informant report are used.\n\nThe Self-Report Form is designed to be completed by adults 18-90 years of age, including adults with a wide variety of developmental, systemic, neurological and psychiatric disorders such as attention disorders, learning disabilities, autism spectrum disorders, traumatic brain injury, multiple sclerosis, depression, mild cognitive impairment, dementia and schizophrenia.\n\nThe Informant Report Form is administered to an adult informant who is familiar with the rated individual’s everyday functioning. It may be used alone when the rated individual is unable to complete the Self-Report Form or has limited awareness of his or her own difficulties, or with the Self-Report Form to gain multiple perspectives on the individual’s functioning. When administered in conjunction with the Self-Report Form, the BRIEF-A Informant Report Form provides a clinically comprehensive picture of the individual being rated.\n\nThe BRIEF-A, based on the original Behavior Rating Inventory of Executive Function (BRIEF), is composed of 75 items within nine non-overlapping theoretically and empirically derived clinical scales that measure various aspects of executive functioning such as:\n\n* Inhibit\n* Self-Monitor\n* Plan/Organise\n* Shift\n* Initiate\n* Task Monitor\n* Emotional Control\n* Working Memory\n* Organisation of Materials\n\n### Test structure\n\nThe clinical scales form two broader indexes: Behavioural Regulation (BRI) and Metacognition (MI), and these indexes form the overall summary score, the Global Executive Composite (GEC). The BRIEF-A also includes three validity scales (Negativity, Inconsistency and Infrequency).\n\nThe BRIEF-A materials consist of the Professional Manual, the carbonless Self-Report Form, the carbonless Informant Report Form, the Self-Report Scoring Summary/Profile Form, and the Informant Report Scoring Summary/Profile Form. The BRIEF-A may be used in research and clinical settings by neuropsychologists, psychologists, physicians and rehabilitation professionals.\n\nThe BRIEF-A was standardised and validated for use with men and women from ages 18-90 years. The normative sample includes adults from a wide range of racial/ethnic backgrounds, educational backgrounds, as well as geographic regions that are matched to U.S. Census data (U.S. Bureau of the Census, 2002).\n\n### **Reliability and Validity**\n\nThe BRIEF-A has demonstrated evidence of reliability, validity, and clinical utility as an ecologically sensitive measure of executive functioning in individuals with a range of conditions across a wide age range.\n\n### Online administration in **[PARiConnect Online account](https://paa.com.au/online-assessments/par-iconnect/)**\n\n[APPLY FOR NEW PARICONNECT](https://paa.com.au/online-assessments/par-iconnect/#PARiConnect-request-form)\n\nLeading the way in online assessment, PAR launched their online assessment platform called PARiConnect. For over ten years, it is one of the most popular platform in the online assessment industry. Updated with features customers asked for, adding trustworthy instruments, PARiConnect remains in-demand-feature in the decades to come.\n\n#### WHY USE THE BRieF-A ONLINE?\n\n* **Flexible administration options**\n* **Powerful report options**\n* **Client-centric design**\n* **Reliable verification tools**\n* **Easy and affordable purchase options** via [PAA website above](https://paa.com.au/product/brief-a/#item-list)\n* **Adaptability for any type of organisation**\n* **Strict data security**\n* **Simple technical requirements**\n* **Enterprise manager**\n\n**Sample Reports**\n\n[BRIEF-A Informant Interpretive Report Download](https://paa.com.au/wp-content/uploads/2018/09/BRIEF-A-Informant-Interpretive-Report.pdf)[BRIEF-A Informant Report Form Feedback Report Download](https://paa.com.au/wp-content/uploads/2018/09/BRIEF-A-Informant-Report-Form-Feedback-Report.pdf)[BRIEF-A Self-Report Interpretive Report Download](https://paa.com.au/wp-content/uploads/2018/09/BRIEF-A-Self-Report-Interpretive-Report.pdf)[Sample BRIEF-A PARiConnect Informant Interpretive Report Download](https://paa.com.au/wp-content/uploads/2018/09/Sample-BRIEF-A-PARiConnect-Informant-Interpretive-Report.pdf)[Sample BRIEF-A PARiConnect Informant Score Report Download](https://paa.com.au/wp-content/uploads/2018/09/Sample-BRIEF-A-PARiConnect-Informant-Score-Report.pdf)[Sample BRIEF-A PARiConnect Self Interpretive Report Download](https://paa.com.au/wp-content/uploads/2018/09/Sample-BRIEF-A-PARiConnect-Self-Interpretive-Report.pdf)[Sample BRIEF-A PARiConnect Self Score Report Download](https://paa.com.au/wp-content/uploads/2018/09/Sample-BRIEF-A-PARiConnect-Self-Score-Report.pdf)\n\n[View Cart](https://paa.com.au/cart/)\n\nAll prices are displayed inclusive of GST.   \nNew Zealand customers need to log in to see prices exclusive of GST.\n\n[Checkout](https://paa.com.au/cart/?wb_checkout_cart)\n\n## Related Items\n\n## [Cognitive Abilities Test: Fourth Edition](https://paa.com.au/product/cat-4/)\n\ncat-4\n\nThe Cognitive Abilities Test: Fourth Edition (CAT4) has been developed and normed in the UK.  It consists of four different tests designed to measure different aspects of cognitive functioning that are all predictive of academic outcomes. By measuring a student’s ability to reason with different types…\n\nLevel M\n\n[Read More](https://paa.com.au/product/cat-4/)\n\n## Choose an Assessment Category\n\n[### Forensic Assessments\n\nLearn More](https://paa.com.au/category/catalogue/forensic/)\n\n## Visit our New Zealand website!\n\nYou have accessed the Australian PAA website, however it looks like you are in New Zealand.  \nVisit our local website to place orders for New Zealand.\n\n[Access NZ Website](https://paa.nz/)\n\n[Stay on AU website](#close_popup)\n\n \n\nTitle: Behavior Rating Inventory of Executive Function\nURL: https://www.rmmemory.org/wp-content/uploads/2018/07/4.-RMMC-Behavior-Rating.pdf\nContent: During the past month, how often has each of the following behaviors been a problem? N = Never. S = Sometimes. O = Often. 1. I have angry outbursts. N. S.\n\nTitle: Behavior Rating Inventory of Executive Function\nURL: https://documents.acer.org/sample_reports/brief-interpretive.pdf\nContent: Client: Sample Client Test Date: 02/29/2008 Client ID: SC 987 Page 3 of 10 BRIEF® Score Summary Table Index/Scale Raw Score T Score Percentile 90% C.I. Inhibit 29 80 98 75 - 85 Shift 14 57 79 49 - 65 Emotional Control 21 60 86 55 - 65 Behavioral Regulation Index (BRI) 64 69 96 65 - 73 Initiate 14 53 70 45 - 61 Working Memory 24 67 95 62 - 72 Plan/Organize 27 65 91 59 - 71 Organization of Materials 10 45 35 39 - 51 Monitor 19 62 91 54 - 70 Metacognition Index (MI) 94 62 85 58 - 66 Global Executive Composite (GEC) 158 66 93 63 - 69 Scale Raw Score Cumulative Percentile Protocol Classification Negativity 0  90 Acceptable Inconsistency 0  98 Acceptable Note: Male,age-specific norms have been used to generate this profile.\nRaw Content: PAR Psychological Assessment Resources, Inc. / 16204 North Florida Ave. / Lutz, FL 33549 / 1.800.331.8378 / www.parinc.com BRIEF®: Interpretive Report Copyright © 1996, 1998, 2000, 2001, 2002, 2003, 2004, 2007, 2008 by Psychological Assessment Resources, Inc. All rights reserved. May not be reproduced in whole or in part in any form or by any means without written permission of Psychological Assessment Resources, Inc. Version: 3.01.007 Behavior Rating Inventory of Executive Function® BRIEF® Interpretive Report Developed by Peter K. Isquith, PhD, Gerard A. Gioia, PhD, and PAR Staff Client Information Client Name : Sample Client Client ID : SC 987 Gender : Male Grade: 2 nd. Age : 8 Birthdate : 02/13/2000 Test Date : 02/29/2008 Test Form : Parent Form Test Description : ADHD Rater Name : Mrs Client Relationship to Client : Parent Client: Sample Client Test Date: 02/29/2008 Client ID: SC 987 Page 2 of 10 The BRIEF was developed to provide a window into the everyday behavior associated with specific domains of the executive functions. The BRIEF can serve as a screening tool for possible executive dysfunction. The clinical information gathered from an in-depth profile analysis is best understood, however, within the context of a full assessment that includes (a) a detailed history of the child and the family, (b) performance-based testing, and (c) observations of the child’s behavior. A thorough understanding of the BRIEF, including its development and its psychometric properties, is a prerequisite to interpretation. As with any clinical method or procedure, appropriate training and clinical supervision is necessary to ensure competent use of the BRIEF. This report is confidential and intended for use by qualified professionals only. This report should not be released to the parents or teachers of the child being evaluated. If a summary of the results specifically written for parents and teachers is desired, the BRIEF Feedback Report can be generated and given to the interested parents and/or teachers. T scores are used to interpret the child’s level of executive functioning as reported by parents and/or teachers on the BRIEF rating forms. These scores are linear transformations of the raw scale scores (M = 50, SD = 10). T scores provide information about an individual’s scores relative to the scores of respondents in the standardization sample. Percentiles, which are also presented within the BRIEF-SP, represent the percentage of children in the standardization sample who fall below a given raw score. In the process of interpreting the BRIEF, review of individual items within each scale can yield useful information for understanding the specific nature of the child’s elevated score on any given clinical scale. In addition, certain items may be particularly relevant to specific clinical groups. Placing too much interpretive significance on individual items, however, is not recommended due to lower reliability of individual items relative to the scales and indexes. Overview Sample's parent completed the Parent form of the Behavior Rating Inventory of Executive Function (BRIEF) on 02/29/2008. There are no missing item responses in the protocol. Responses are reasonably consistent. The respondent’s ratings of Sample do not appear overly negative. In the context of these validity considerations, ratings of Sample's executive function exhibited in everyday behavior reveal some areas of concern. The overall index, the Global Executive Composite (GEC), was elevated (GEC T = 66, %ile = 93). The Metacognition Index (MI) was within normal limits (MI T = 62, %ile = 85) while the Behavioral Regulation Index (BRI) was elevated (BRI T = 69, %ile = 96). Within these summary indicators, all of the individual scales are valid. One or more of the individual BRIEF scales were elevated, suggesting that Sample exhibits difficulty with some aspects of executive function. Concerns are noted with his ability to inhibit impulsive responses (Inhibit T = 80, %ile = 98), sustain working memory (Working Memory T = 67, %ile = 95), and plan and organize problem solving approaches (Plan/Organize T = 65, %ile = 91). Sample's ability to adjust to changes in routine or task demands (Shift T = 57, %ile = 79), modulate emotions (Emotional Control T = 60, %ile = 86), initiate problem solving or activity (Initiate T = 53, %ile = 70), organize his environment and materials (Organization of Materials T = 45, %ile = 35), and monitor his own behavior (Monitor T = 62, %ile = 91) is not described as problematic by the respondent. Client: Sample Client Test Date: 02/29/2008 Client ID: SC 987 Page 3 of 10 BRIEF® Score Summary Table Index/Scale Raw Score T Score Percentile 90% C.I. Inhibit 29 80 98 75 - 85 Shift 14 57 79 49 - 65 Emotional Control 21 60 86 55 - 65 Behavioral Regulation Index (BRI) 64 69 96 65 - 73 Initiate 14 53 70 45 - 61 Working Memory 24 67 95 62 - 72 Plan/Organize 27 65 91 59 - 71 Organization of Materials 10 45 35 39 - 51 Monitor 19 62 91 54 - 70 Metacognition Index (MI) 94 62 85 58 - 66 Global Executive Composite (GEC) 158 66 93 63 - 69 Scale Raw Score Cumulative Percentile Protocol Classification Negativity 0  90 Acceptable Inconsistency 0  98 Acceptable Note: Male,age-specific norms have been used to generate this profile. For additional normative information, refer to Appendix A - D in the BRIEF® Professional Manual. Client: Sample Client Test Date: 02/29/2008 Client ID: SC 987 Page 4 of 10 Profile of BRIEF® T Scores T Score  30 35 40 45 50 55 60 65 70 75 80 85 90 95  100 T Score  30 35 40 45 50 55 60 65 70 75 80 85 90 95  100 Emotional Working Plan/ Org. of Inhibit Shift Control Initiate Memory Organize Materials Monitor BRI MI GEC T Score 80 57 60 53 67 65 45 62 69 62 66 Percentile 98 79 86 70 95 91 35 91 96 85 93 Raw score 29 14 21 14 24 27 10 19 64 94 158 Missing n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a Note: Male,age-specific norms have been used to generate this profile. For additional normative information, refer to Appendixes A - D in the BRIEF® Professional Manual. Client: Sample Client Test Date: 02/29/2008 Client ID: SC 987 Page 5 of 10 Validity Before examining the BRIEF profile, it is essential to carefully consider the validity of the data provided. The inherent nature of rating scales (i.e., relying upon a third party for ratings of a child’s behavior) brings potential bias to the scores. The first step is to examine the protocol for missing data. With a valid number of responses, the Inconsistency and Negativity scales of the BRIEF provide additional validity indexes. Missing items The respondent completed 86 of a possible 86 BRIEF items. There are no missing responses in the protocol, providing a complete data set for interpretation. Inconsistency Scores on the Inconsistency scale indicate the extent to which the respondent answered similar BRIEF items in an inconsistent manner relative to the clinical samples. For example, a high Inconsistency score might be associated with marking Never in response to the item “Gets out of control more than friends” while at the same time marking Often in response to the item “Acts too wild or out of control.” T scores are not generated for the Inconsistency scale. Instead, the raw difference scores for the 10 paired items are summed and the total difference score (i.e., the Inconsistency score) is used to classify the protocol as either “Acceptable,” “Questionable,” or as “Inconsistent.” The Inconsistency score of 0 falls within the Acceptable range, suggesting that the rater was reasonably consistent in responding to BRIEF items. Negativity The Negativity scale measures the extent to which the respondent answered selected BRIEF items in an unusually negative manner relative to the clinical sample. A higher raw score on this scale indicates a greater degree of negativity, with less than 3% of respondents scoring above 7 in the clinical sample. As with the Inconsistency scale, T scores are not generated for this scale. The Negativity score of 0 falls within the acceptable range, suggesting that the respondent’s view of Sample is not overly negative and that the BRIEF protocol is likely to be valid. Composite and Summary Indexes Global Executive Composite The Global Executive Composite (GEC) is an overarching summary score that incorporates all of the BRIEF clinical scales. Although review of the Metacognition Index, Behavioral Regulation Index, and individual scale scores is strongly recommended for all BRIEF profiles, the GEC can sometimes be useful as a summary measure. In this case, the two summary indexes are not substantially different, with T scores separated by 7 points. Thus, the GEC adequately captures the nature of the overall profile. With this in mind, Sample's T score of 66 (%ile = 93) on the GEC is moderately elevated as compared to the scores of his peers, suggesting some difficulty in one or more areas of executive function. Client: Sample Client Test Date: 02/29/2008 Client ID: SC 987 Page 6 of 10 Behavioral Regulation and Metacognition Indexes The Behavioral Regulation Index (BRI) captures the rated child’s ability to shift cognitive set and modulate emotions and behavior via appropriate inhibitory control. It is comprised of the Inhibit, the Shift, and the Emotional Control scales. Intact behavioral regulation is likely to be a precursor to appropriate metacognitive problem solving. Behavioral regulation enables the metacognitive processes to successfully guide active systematic problem solving; and more generally, behavioral regulation supports appropriate self-regulation. The Metacognition Index (MI) reflects the rated child’s ability to initiate, plan, organize, self-monitor, and sustain working memory. It can be interpreted as Sample's ability to cognitively self-manage tasks and to monitor his performance. The MI relates directly to a child’s ability to actively problem solve in a variety of contexts. It is composed of the Initiate, Working Memory, Plan/Organize, Organization of Materials, and Monitor scales. Examination of the indexes reveals that the Behavioral Regulation Index is elevated (T = 69, %ile = 96) while the Metacognition Index is within the average range (T = 62, %ile = 85). This suggests difficulties with inhibitory control, emotional modulation, or ability to shift set but also suggests relatively preserved working memory, initiating, planning, organizing, and self-monitoring. Clinical Scales The BRIEF clinical scales measure the extent to which the respondent reports problems with different types of behavior related to the eight domains of executive functioning. The following sections describe the scores obtained on the clinical scales and the suggested interpretation for each individual clinical scale. Inhibit The Inhibit scale assesses inhibitory control and impulsivity. This can be described as the ability to resist impulses and the ability to stop one’s own behavior at the appropriate time. Sample's score on this scale is highly elevated (T = 80, %ile = 98) as compared to his peers. Children with similar scores on the Inhibit scale typically have marked difficulty resisting impulses and difficulty considering consequences before acting. They are often perceived as (a) less in control of themselves than their peers, (b) having difficulty staying in place in line or in the classroom, (c) interrupting others or “calling out” in class frequently, and (d) requiring higher levels of adult supervision. Often, caregivers and teachers are particularly concerned about the verbal and social intrusiveness and the lack of personal safety observed in children who do not inhibit impulses well. Such children may display high levels of physical activity, inappropriate physical responses to others, a tendency to interrupt and disrupt group activities, and a general failure to “look before leaping.” In the contexts of the classroom and assessment settings, children with inhibitory control difficulties often require a higher degree of external structure to limit their impulsive responding. They may start an activity or task before listening to instructions, before developing a plan, or before grasping the organization or gist of the situation. Examination of the individual items that comprise the Inhibit scale may be informative and may help guide interpretation and intervention. Client: Sample Client Test Date: 02/29/2008 Client ID: SC 987 Page 7 of 10 Shift The Shift scale assesses the ability to move freely from one situation, activity, or aspect of a problem to another as the circumstances demand. Key aspects of shifting include the ability to (a) make transitions, (b) tolerate change, (c) problem-solve flexibly, (d) switch or alternate attention, and (e) change focus from one mindset or topic to another. Sample's score on the Shift scale falls within the average range as compared to like-aged peers (T = 57, %ile = 79). This suggests that Sample is generally able to change from task to task or from place to place without difficulty, is able to think of or accept different ways of solving problems, and is able to demonstrate flexibility in the performance of day to day activities. Emotional Control The Emotional Control scale measures the impact of executive function problems on emotional expression and assesses a child’s ability to modulate or control his or her emotional responses. Sample's score on the Emotional Control scale falls within the average range as compared to like-aged peers (T = 60, %ile = 86). This suggests that Sample demonstrates an appropriate ability to modulate or regulate emotions overall. Sample is generally described as reacting to events appropriately; without outbursts, sudden and/or frequent mood changes, or excessive periods of emotional upset. Initiate The Initiate scale reflects a child’s ability to begin a task or activity and to independently generate ideas, responses, or problem-solving strategies. Sample's score on the Initiate scale is within the average range as compared to like-aged peers (T = 53, %ile = 70). This suggests that Sample is generally able to begin, start or “get going” on tasks, activities, and problem-solving approaches appropriately. Working Memory The Working Memory scale measures “on-line representational memory;” that is, the capacity to hold information in mind for the purpose of completing a task, encoding information, or generating goals, plans, and sequential steps to achieving goals. Working memory is essential to carry out multistep activities, complete mental manipulations such as mental arithmetic, and follow complex instructions. Sample's score on the Working Memory scale is moderately elevated as compared to like-aged peers (T = 67, %ile = 95). This suggests that Sample has some difficulty holding an appropriate amount of information in mind or in “active memory” for further processing, encoding, and/or mental manipulation. Further, Sample's score suggests difficulties sustaining working memory, which has a negative impact on his ability to remain attentive and focused for appropriate lengths of time. Caregivers describe children with fragile or limited working memory as having trouble remembering things (e.g., phone numbers or instructions) even for a few seconds, losing track of what they are doing as they work, or forgetting what they are supposed to retrieve when sent on an errand. They often miss information that exceeds their working memory capacity such as instructions for an assignment. Clinical evaluators may observe that a child cannot remember the rules governing a specific task (even as he or she works on that task), rehearses information repeatedly, loses track of what responses he or she has already given on a task that requires multiple answers, and struggles with mental manipulation tasks (e.g., repeating digits in reverse order) or solving arithmetic problems that are orally presented without writing down figures. Client: Sample Client Test Date: 02/29/2008 Client ID: SC 987 Page 8 of 10 Appropriate working memory is necessary to sustain performance and attention. Parents of children with difficulties in this domain report that the children cannot “stick to” an activity for an age-appropriate amount of time and frequently switch tasks or fail to complete tasks. Although working memory and the ability to sustain it have been conceptualized as distinct entities, behavioral outcomes of these two domains are often difficult to distinguish. Plan/Organize The Plan/Organize scale measures the child’s ability to manage current and future-oriented task demands. The scale is comprised of two components: plan and organize. The plan component captures the ability to anticipate future events, to set goals, and to develop appropriate sequential steps ahead of time in order to carry out a task or activity. The organize component refers to the ability to bring order to information and to appreciate main ideas or key concepts when learning or communicating information. Sample's score on the Plan/Organize scale is moderately elevated as compared to like-aged peers (T = 65, %ile = 91). This suggests that Sample has some difficulty with the planning and the organization of information which has a negative impact on his approach to problem solving. Planning involves developing a goal or end state and then strategically determining the most effective method or steps to attain that goal. Evaluators can observe planning when a child is given a problem requiring multiple steps (e.g., assembling a puzzle or completing a maze). Sample may underestimate the time required to complete tasks or the level of difficulty inherent in a task. He may often wait until the last minute to begin a long-term project or assignment for school, and he may have trouble carrying out the actions needed to reach his goals. Organization involves the ability to organize oral and written expression as well as to understand the main points expressed in presentations or written material. Organization also has a clerical component that is demonstrated, for example, in the ability to efficiently scan a visual array or to keep track of a homework assignment. Sample may approach tasks in a haphazard fashion, getting caught up in the details and missing the “big picture.” He may have good ideas that he fails to express on tests and written assignments. He may often feel overwhelmed by large amounts of information and may have difficulty retrieving material spontaneously or in response to open-ended questions. He may, however, exhibit better performance with recognition (multiple choice) questions. Organization of Materials The Organization of Materials scale measures orderliness of work, play, and storage spaces (e.g., desks, lockers, backpacks, and bedrooms). Caregivers and teachers typically can provide an abundance of examples describing a child’s ability to organize, keep track of, and/or clean up their belongings. Sample's score on the Organization of Materials scale falls within the average range for like-aged children (T = 45, %ile = 35). Sample is described as being able to keep materials and his belongings reasonably well organized, as having his materials readily available for projects or assignments, and as being able to find his belongings when needed. Monitor The Monitor scale assesses two types of monitoring behaviors: Task-oriented monitoring or work-checking habits and Self-monitoring or interpersonal awareness. The task monitoring portion of the scale captures whether a child assesses his or her own performance during or shortly after finishing a task to ensure accuracy or appropriate attainment of a goal. The self monitoring portion of the scale evaluates whether a child keeps track of the effect that his or her Client: Sample Client Test Date: 02/29/2008 Client ID: SC 987 Page 9 of 10 behavior has on others. Sample's score on the Monitor scale is within normal limits, suggesting an appropriate overall level of monitoring (T = 62, %ile = 91). Client: Sample Client Test Date: 02/29/2008 Client ID: SC 987 Page 10 of 10 Executive System Intervention (This section removed for sample report) End of Report\n\nTitle: Behavior Rating Inventory of Executive Function\nURL: https://www.parinc.com/products/BRIEF-A\nContent: This cookies is set by ASP.NET and is used to track users within a session without requiring the user to log in. PAR Talks Website ONLY - FuelPHP uses this cookie to track authentication information. Saves the user's cookie consent preferences (whether or not they consent to Functional, Analytics, Performance, Advertisement, or Other cookies) so that they don't have to enter them each time they visit. The \\_ga cookie, installed by Google Analytics, calculates visitor, session and campaign data and also keeps track of site usage for the site's analytics report. Installed by Google Analytics, \\_gid cookie stores information on how visitors use a website, while also creating an analytics report of the website's performance.\nRaw Content: We value your privacy\n\nWe use cookies to allow you to make full use of our website, analyze website traffic, personalize your experience, and show more relevant ads. By clicking “Accept,” you agree to our use of cookies in accordance with our [Privacy Policy](https://www.parinc.com/trust-center/general-privacy-policy). You can change your preferences at any time by clicking “Manage Cookies.”\n\nWe use cookies to help you navigate efficiently and perform certain functions. You will find detailed information about all cookies under each consent category below.\n\nThe cookies that are categorized as \"Necessary\" are stored on your browser as they are essential for enabling the basic functionalities of the site. ...\n\n* This cookie is used by parinc.com to determine if the visitor is browsing from a mobile device. It is necessary for the site functionality.\n\n* Cookie\n* Duration\n\n  2 months 8 days 11 hours\n* Description\n\n  This cookies is set by ASP.NET and is used to track users within a session without requiring the user to log in.\n\n* Cookie\n* Duration\n\n  session\n* Description\n\n  This cookie is set by web application built in ASP.NET MVC Technologies. This is an anti-forgery cookie used for preventing cross site request forgery attacks.\n\n* Cookie\n\n  language\n* Duration\n\n  session\n* Description\n\n  This cookie is used to store the language preference of the user.\n\n* Cookie\n\n  fuelrid\n* Duration\n\n  session\n* Description\n\n  PAR Talks Website ONLY - FuelPHP uses this to track session variables.\n\n* Cookie\n\n  sentry\\_rm\n* Duration\n\n  past\n* Description\n\n  PAR Talks Website ONLY - FuelPHP uses this cookie to track authentication information.\n\n* Cookie\n\n  fuel\\_csrf\\_token\n* Duration\n\n  session\n* Description\n\n  PAR Talks Website ONLY - FuelPHP uses this session token to prevent Cross-Site Scripting attacks from occurring.\n\n* Cookie\n\n  ASP.NET\\_SessionId\n* Duration\n\n  session\n* Description\n\n  Issued by Microsoft's ASP.NET Application, this cookie stores session data during a user's website visit.\n\n* Cookie\n\n  \\_\\_cfruid\n* Duration\n\n  session\n* Description\n\n  Cloudflare sets this cookie to identify trusted web traffic.\n\n* Cookie\n\n  AWSALBCORS\n* Duration\n\n  7 days\n* Description\n\n  This cookie is managed by Amazon Web Services and is used for load balancing.\n\n* Cookie\n\n  \\_GRECAPTCHA\n* Duration\n\n  5 months 27 days\n* Description\n\n  This cookie is set by the Google recaptcha service to identify bots to protect the website against malicious spam attacks.\n\n* Cookie\n\n  \\_\\_RequestVerificationToken\\_\\*\n* Duration\n\n  Session\n* Description\n\n  PAR Gateway Portal Website ONLY - Used to prevent Cross-Site Scripting attacks.\n\n* Cookie\n\n  cookieyes-consent\n* Duration\n\n  1 Year\n* Description\n\n  Saves the user's cookie consent preferences (whether or not they consent to Functional, Analytics, Performance, Advertisement, or Other cookies) so that they don't have to enter them each time they visit.   \n    \n  Cookie preferences can be updated in the 'Manage Cookies' section of the footer.\n\nFunctional cookies help perform certain functionalities like sharing the content of the website on social media platforms, collecting feedback, and other third-party features.\n\n* Cookie\n\n  zte2095\n* Duration\n\n  session\n* Description\n\n  Session cookie created by Zendesk to track which domain/sub-domain their chat widget is located on.\n\n* Cookie\n\n  PLL\\_SESSION\n* Duration\n\n  session\n* Description\n\n  Used by Digitell.IO/BroadcastMed Live Events Platforms to track session information.\n\n* Cookie\n\n  YSC\n* Duration\n\n  session\n* Description\n\n  YSC cookie is set by Youtube and is used to track the views of embedded videos on Youtube pages.\n\n* Cookie\n\n  VISITOR\\_INFO1\\_LIVE\n* Duration\n\n  5 months 27 days\n* Description\n\n  A cookie set by YouTube to measure bandwidth that determines whether the user gets the new or old player interface.\n\n* Cookie\n\n  yt-remote-device-id\n* Duration\n\n  never\n* Description\n\n  YouTube sets this cookie to store the video preferences of the user using embedded YouTube video.\n\n* Cookie\n\n  yt-remote-connected-devices\n* Duration\n\n  never\n* Description\n\n  YouTube sets this cookie to store the video preferences of the user using embedded YouTube video.\n\n* Cookie\n\n  \\_\\_zlcstore\n* Duration\n\n  never\n* Description\n\n  Zopim sets this cookie to store information about the current status of the chat.\n\n* Cookie\n\n  HubSpot Script Loader\n* Duration\n\n  60\n* Description\n\n  Loads the Hubspot Header/Body Tag\n\n* Cookie\n\n  Forms HubSpot\n* Duration\n\n  60\n* Description\n\n  Initializes the Forms HubSpot\n\n* Cookie\n\n  Hubspot Collected Forms\n* Duration\n\n  60\n* Description\n\n  Initializes the Hubspot Collected Forms\n\n* Cookie\n\n  HubSpot Forms\n* Duration\n\n  60\n* Description\n\n  Initializes the HubSpot Forms\n\n* Cookie\n\n  HubSpot Scripts\n* Duration\n\n  60\n* Description\n\n  Initializes the HubSpot Scripts\n\nAnalytical cookies are used to understand how visitors interact with the website. These cookies help provide information on metrics such as the number of visitors, bounce rate, traffic source, etc.\n\n* Cookie\n\n  \\_ga\n* Duration\n\n  1 Month\n* Description\n\n  The \\_ga cookie, installed by Google Analytics, calculates visitor, session and campaign data and also keeps track of site usage for the site's analytics report. The cookie stores information anonymously and assigns a randomly generated number to recognize unique visitors.\n\n* Cookie\n\n  \\_gid\n* Duration\n\n  1 day\n* Description\n\n  Installed by Google Analytics, \\_gid cookie stores information on how visitors use a website, while also creating an analytics report of the website's performance. Some of the data that are collected include the number of visitors, their source, and the pages they visit anonymously.\n\n* Cookie\n\n  \\_gat\\_gtag\\_UA\\_\\*\n* Duration\n\n  1 minute\n* Description\n\n  Google Analytics sets this cookie to store a unique user ID.\n\n* Cookie\n\n  CONSENT\n* Duration\n\n  2 years\n* Description\n\n  YouTube sets this cookie via embedded youtube-videos and registers anonymous statistical data.\n\n* Cookie\n\n  \\_\\_zlcmid\n* Duration\n\n  1 Year\n* Description\n\n  Used by Clickdimensions\n\n* Cookie\n\n  cd\\_optout\\_parinc.com\n* Duration\n\n  6 Months\n* Description\n\n  Used by ClickDimensions to Opt Out of ClickDimensions Tracking.\n\n* Cookie\n\n  \\_ga\\_\\*\n* Duration\n\n  1 Year 1 Month\n* Description\n\n  Used by ClickDimensions\n\nPerformance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors.\n\nNo cookies to display.\n\nAdvertisement cookies are used to provide visitors with customized advertisements based on the pages you visited previously and to analyze the effectiveness of the ad campaigns.\n\nNo cookies to display.\n\nOther uncategorized cookies are those that are being analyzed and have not been classified into a category as yet.\n\nNo cookies to display.\n\n\n\n[Go Home](/home)\n\n## My Account\n\nQualification Level\n\n[Manage Profile](https://account.parinc.com/myprofile) \n[Log Out](/Sitefinity/SignOut?sts_signout=true&redirect_uri=)\n\n[Quotes](/account/quotes) \n[Orders](/account/order-history) \n[Downloads](/account/downloads)\n\n[Log In](/sitefinity/external-login-handler?provider=OpenIDConnect&amp;returnUrl=https%3A%2F%2Fwww.parinc.com%2Fhome&amp;errorUrl=https%3A%2F%2Fwww.parinc.com%2Fhome%3floginerror%3dTrue)\n\n## Register now and start:\n\n* Accessing PAR Training\n* Shopping PAR products & tools\n* Using online assessments with PARiConnect\n\n[Register Now](https://account.parinc.com/registration)\n\n## Still the Leader\n\nPARiConnect saves time, offers insightful reports, & exceptional reliability!\n\n[PARiConnect Log In](https://app.pariconnect.com/auth/login)\n\nCart (0)\n\n## Cart\n\n### Your cart is currently empty\n\n[Checkout or Save as Quote](/checkout-redirect)\n\n## Do you want to remove from your cart?\n\n## This cart was converted from a quote, and is using the quoted pricing. Adding, updating or removing items and/or coupons from this cart will update all cart items to current pricing. Proceed?\n\n \n\n\n# BRIEF®-A (Old Version)\n\nBehavior Rating Inventory of Executive Function® Adult Version\n\nJump to...[Details](#details)[Shop by Item](#items)[Related Products](#related-products)\n\n## Details\n\n### Purpose\n\nAssesses adult executive functioning/self-regulation\n\n### Authors\n\nRobert M. Roth, PhD, Peter K. Isquith, PhD, Gerard A. Gioia, PhD\n\n### Administration Formats\n\nPrint\n\nDigital\n\n### Additional Details\n\n### Useful for Assessing Adults with a Variety of Developmental, Neurological, and Psychiatric Disorders\n\n##### We recommend the newest version, [BRIEF2A](/products/BRIEF2A).\n\nThe BRIEF-A is a standardized measure that captures views of an adult’s executive functions or self-regulation in his or her everyday environment. Both a self-report and an informant report are used.\n\n[Expand all Additional Details](#)\n\n#### Features and benefits\n\n* Based on the original [BRIEF](/products/BRIEF), the BRIEF-A includes 75 items within nine nonoverlapping theoretically and empirically derived clinical scales: Inhibit, Self-Monitor, Plan/Organize, Shift, Initiate, Task Monitor, Emotional Control, Working Memory, and Organization of Materials.\n* Useful for a wide variety of developmental, systemic, neurological, and psychiatric disorders such as attention disorders, learning disabilities, autism spectrum disorders, traumatic brain injury, multiple sclerosis, depression, mild cognitive impairment, dementias, and schizophrenia.\n\n#### Available in Spanish\n\nBRIEF-A Self-Report and Informant forms have been translated into U.S. Spanish. This product uses English norms only.\n\n#### Licensing\n\nThe BRIEF Adult Self-Report Scoring Summary/Profile Form (item 5749-PF) and the BRIEF Adult Self-Report Forms (5747-TB) are available for [licensing](/programs-partnerships/permissions-and-licensing).\n\n[Collapse all Additional Details](#)\n\n**Age Range**\n18 years to 90 years\n\n**Admin Time**\n10–15 minutes\n\n**Qualification Level**\nB\n\n## Shop by Item\n\n### No items for your selection.\n\n\n\n## FAQs\n\n### What is the technical information of the BRIEF®-A?\n\n#### Technical information\n\n* Normative sample included 1,136 adults from a wide range of racial/ethnic backgrounds, educational backgrounds, and geographic regions.\n* Profiles for diagnostic groups, including ADHD, Alzheimer’s disease, and multiple sclerosis, are presented.\n* Demonstrates evidence of reliability, validity, and clinical utility as an ecologically sensitive measure of executive functioning in individuals with a range of conditions across a wide age range.\n\n#### Test structure\n\nTwo broad indexes (Behavioral Regulation and Metacognition), an overall summary score, and three validity scales (Negativity, Inconsistency, and Infrequency) are included.\n\n\n\n## Related Products\n\n### BRIEF®2\n\nThe Behavior Rating Inventory of Executive Function, Second Edition, (BRIEF2) assesses executive functioning in home and school in children 5-18 years. 25 minutes to administer and score. Buy from PAR.\n\n[See Details](https://www.parinc.com/products/BRIEF-2)\n\n### BRIEF®2 Screening Forms\n\nThe BRIEF 2 SF is designed to use in medical and educational settings to estimate whether a comprehensive assessment is needed. Find out more.\n\n[See Details](https://www.parinc.com/products/BRIEF-2-SF)\n\n### BRIEF®2 ADHD Form\n\nRule In or Rule Out ADHD & Help Determine Subtype with the BRIEF2 ADHD Form. Buy from PAR.\n\n[See Details](https://www.parinc.com/products/BRIEF2-ADHD)\n\n### BRIEF®2 Interventions Handouts\n\nHandouts for parents, teachers, and students that provide interventions to improve executive function in youth\n\n[See Details](https://www.parinc.com/products/BRIEF2-INTERV)\n\n### BRIEF®2 Interpretive Guide\n\nInterpretive guide book for the BRIEF2. Use to write reports using language that is concise, accurate, and clear to parents and teachers. Order from PAR.\n\n[See Details](https://www.parinc.com/products/BOOK-BRIEF2-INTERP)\n\n### BRIEF®2A\n\nNow with the 3-factor model found in the BRIEF2, BRIEF2A allows multiple sources to rate executive function in an adult’s everyday setting. Order now!\n\n[See Details](https://www.parinc.com/products/BRIEF2A)\n\n### BRIEF® (Old Version)\n\nAssesses impairment of executive function\n\n[See Details](https://www.parinc.com/products/BRIEF)\n\n### BRIEF®-P\n\nBRIEF-P assesses preschool children for emerging attention disorders, LD, TBI, autism and lead exposure. Buy the BRIEF-P preschool executive functioning test from PAR.\n\n[See Details](https://www.parinc.com/products/BRIEF-P)\n\n### BRIEF®-SR (Old Version)\n\nAssess cognitive, emotional, & behavioral functions in adolescents with the Behavior Rating Inventory of Executive Function—Self-Report Version (BRIEF-SR). Order from PAR.\n\n[See Details](https://www.parinc.com/products/BRIEF-SR)\n\n "
      }
    ]
  }
]

---

### User
> 11/30/2025, 3:48:24 PM

[
  {
    "tool_use_id": "toolu_019e6XZmJH4NHxagprwyZY2T",
    "type": "tool_result",
    "content": [
      {
        "type": "text",
        "text": "Detailed Results:\n\nTitle: LASSI - Learning and Study Strategies Inventory | PDF\nURL: https://www.scribd.com/document/883799343/LASSI-Learning-and-Study-Strategies-Inventory\nContent: The Learning and Study Strategies Inventory (LASSI) report for Anita Rodimina provides percentile scores across ten scales, highlighting areas of strength\nRaw Content: ![Scribd](data:image/svg+xml;base64,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)\n\n# LASSI - Learning and Study Strategies Inventory\n\nLASSI - Learning and Study Strategies Inventory\n\n## Uploaded by\n\nAI-enhanced title and description\n\nTopics covered\n\n# LASSI - Learning and Study Strategies Inventory\n\nThe Learning and Study Strategies Inventory (LASSI) report for Anita Rodimina provides percentile scores across ten scales, highlighting areas of strength and those needing improvement. Key findings include low anxiety levels but significant challenges in attitude, concentration, and time management, indicating a need for strategic enhancements in these areas. The report encourages seeking assistance and developing skills to improve academic performance.\n\n# LASSI - Learning and Study Strategies Inventory\n\nLASSI - Learning and Study Strategies Inventory\n\n## Uploaded by\n\nAI-enhanced title and description\n\nTopics covered\n\n## Share this document\n\n![]()\n\n## Footer menu\n\nAbout\n\nSupport\n\nLegal\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nAbout\n\nLegal\n\nSupport\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nTitle: Learning and Study Strategies Inventory (3rd Edition) (LASSI)\nURL: https://edinstruments.org/instruments/learning-and-study-strategies-inventory-3rd-edition-lassi\nContent: Learning and Study Strategies Inventory (LASSI): User's manual (3rd ed.). Clearwater, FL: H & H Publishing. https://www.hhpublishing.com/LASSImanual.pdf.\nRaw Content: ![Home](/sites/default/files/edinstruments_logo.webp)\n\n##### Main navigation\n\n## Breadcrumb\n\n# Learning and Study Strategies Inventory (3rd Edition) (LASSI)\n\n## Search and Filter\n\n### Instrument Overview\n\nThe Learning and Study Strategies Inventory (3rd Edition) (LASSI) assesses awareness and use of learning and study strategies. It can be used diagnostically and prescriptively, for planning remediation enrichment, or as a pre-post measure for program evaluation. Subscore(s): There are 10 subscores: Anxiety, Attitude, Concentration, Information Processing, Motivation, Selecting Main Ideas, Self Testing, Test Strategies, Time Management, Using Academic Resources\n\nNote: The overview provided for this instrument includes content that may have been sourced from the instrument publisher's or author’s website (or other site providing information about the instrument). This information is presented for educational and informational purposes only. If you have any questions about the content or its permitted uses, please contact annenberg@brown.edu.\n\n### Organization\n\n![](https://dev-edinstruments2.pantheonsite.io/sites/default/files/2025-02/air_logo.png)\n\n**American Institutes for Research®** partnered with the **Annenberg Institute at Brown University** to collect instruments related to student well-being.\n\n### Content\n\n### Administration Information\n\n### Access and Use\n\nFong, C. J., Krou, M. R., Johnston-Ashton, K., Hoff, M. A., Lin, S., & Gonzales, C. (2021). LASSI's great adventure: A meta-analysis of the Learning and Study Strategies Inventory and academic outcomes. Educational Research Review, 34, 100407. https://doi.org/10.1016/j.edurev.2021.100407\n\nKallison Jr, J. M. (2017). The effects of an intensive postsecondary transition program on college readiness for adult learners. Adult Education Quarterly, 67(4), 302-321. https://doi.org/10.1177/0741713617725394\n\nYip, M. C., & Chung, O. L. (2002). Relation of study strategies to the academic performance of Hong Kong University students. Psychological Reports, 90, 338-340. https://doi.org/10.2466/pr0.2002.90.1.338\n\n### Psychometrics [(additional guidance)](/psychometric-considerations/)\n\n**Psychometric References**\n\nCano, F. (2006). An in-depth analysis of the Learning and Study Strategies Inventory (LASSI). *Educational and Psychological Measurement*, *66*(6), 1023-1038. <https://doi.org/10.1177/0013164406288167>\n\nOlejnik, S., & Nist, S. L. (1992). Identifying latent variables measured by the Learning and Study Strategies Inventory (LASSI). *The Journal of experimental education*, *60*(2), 151-159. <https://doi.org/10.1080/00220973.1991.10806587>\n\nPrevatt, F., Petscher, Y., Proctor, B. E., Hurst, A., & Adams, K. (2006). The revised learning and study strategies inventory: An evaluation of competing models. *Educational and psychological measurement*, *66*(3), 448-458. <https://doi.org/10.1177/0013164405282454>\n\nWeinstein, C. E., & Palmer, D. R. (2002). *Learning and Study Strategies Inventory (LASSI): User’s manual (2nd ed.).* Clearwater, FL: H & H Publishing.\n\nWeinstein, C.E., Palmer, D.R., & Acee, T.W. (2016). *Learning and Study Strategies Inventory (LASSI): User’s manual (3rd ed.).* Clearwater, FL: H & H Publishing. <https://www.hhpublishing.com/LASSImanual.pdf>\n\nWeinstein, C. E., Schulte, A. C., & Palmer, D. P. (1987). *Learning and Study Strategies Inventory.* Clearwater, FL: H & H Publishing.\n\n## Related Instruments\n\nFrom the same study that created the SESQ (Student Engagement in Schools Questionnaire) the TERF-N is a teacher-report form measuring teacher perceptions of student engagement (affective, behavioral, cognitive) for each student.\n\nThis document is a student engagement, motivation, and beliefs survey that contains statements for students to rate their level of agreement on a scale.\n\n### Related Resources from the EdExchange\n\n![External Link](/modules/custom/edexchange_related_resources/images/external-link.svg)\n![EdResearchForAction Logo](/modules/custom/edexchange_related_resources/images/Annenberg_Logos_RGB_Ed-Research-for-Action_Full-Color.svg)\n\nA new model for informed decision-making in education\n\n### Helping Students Make Informed Choices About College\n\n**Category:** Pathways to and Through Postsecondary\n\n**Tags:** College readiness, Counseling, Higher education\n\n![Right arrow](/modules/custom/edexchange_related_resources/images/circle-caret-right.svg)\n\n### Guidance And Support For Students Moving Into Postsecondary\n\n**Category:** Pathways to and Through Postsecondary\n\n**Tags:** College readiness, Counseling, Higher education\n\n![Right arrow](/modules/custom/edexchange_related_resources/images/circle-caret-right.svg)\n\n### Promoting Student Success in Early College Credit Courses\n\n**Category:** Student Learning\n\n**Tags:** College readiness, Higher education\n\n![Right arrow](/modules/custom/edexchange_related_resources/images/circle-caret-right.svg)\n![EdWorkingPapers Logo](/modules/custom/edexchange_related_resources/images/Annenberg_Logos_RGB_Ed-Working-Papers_Full-Color.svg)\n\nThe trusted source for emerging education research\n\n### Labor Market Strength and Declining Community College Enrollment\n\n**Category:** Pathways to and Through Postsecondary\n\n**Tags:** Career and technical education, College readiness, Higher education, Human capital, Returns to education and skills\n\n![Right arrow](/modules/custom/edexchange_related_resources/images/circle-caret-right.svg)\n\n### Labor Market Strength and Declining Community College Enrollment\n\n**Category:** Pathways to and Through Postsecondary\n\n**Tags:** Career and technical education, College readiness, Higher education, Human capital, Returns to education and skills\n\n![Right arrow](/modules/custom/edexchange_related_resources/images/circle-caret-right.svg)\n\n### The Long-Term Effects of Rank in Elementary School\n\n**Category:** Pathways to and Through Postsecondary\n\n**Tags:** College readiness, Higher education, Returns to education and skills\n\n![Right arrow](/modules/custom/edexchange_related_resources/images/circle-caret-right.svg)\n![Annenberg Institute at Brown University](/sites/default/files/logo_ai_white.webp)\n\n[**Annenberg Institute at Brown University**](https://annenberg.brown.edu)  \nMailing address: Box 1985, Providence, RI 02912  \nLocation: 164 Angell St., 2nd floor, Providence, RI 02906  \nTelephone: 401.863.7990  \nEmail: [annenberg@brown.edu](mailto:annenberg@brown.edu)\n\n##### Footer\n\nTitle: Learning and Study Strategies Inventory (LASSI)\nURL: https://www.csuohio.edu/tutoring/learning-and-study-strategies-inventory-lassi\nContent: The LASSI is a 10-scale, 60-item assessment of students' awareness about and use of learning and study strategies related to following components of Strategic Learning. The LASSI scales related to the skill component of strategic learning are: Information Processing, Selecting Main Ideas and Test Strategies. The LASSI Scales related to the self-regulation component of strategic learning are: Concentration; Time Management; Self-Testing and Study Aids. These scales measure how students manage, or self-regulate and control, the whole learning process through using their time effectively, focusing their attention and maintaining their concentration over time, checking to see if they have met the learning demands for a class, an assignment or a test, and using study supports such as review sessions, tutors or special features of a textbook.\nRaw Content: ##### Main navigation\n\n* [About CSU](https://www.csuohio.edu/about-csu \"Expand menu About CSU\")\n  + [At a Glance](https://www.csuohio.edu/about-csu/glance)\n  + [Concerned Vikes](https://www.csuohio.edu/report-a-concern)\n  + [Free Speech at CSU](https://www.csuohio.edu/freespeech)\n  + [President's Office](https://www.csuohio.edu/president)\n* [Admissions](https://www.csuohio.edu/admissions \"Expand menu Admissions\")\n  + [Undergraduate](https://www.csuohio.edu/admissions)\n  + [Graduate](https://graduate-studies.csuohio.edu/)\n  + [International](http://www.csuohio.edu/international-admissions)\n  + [Law](http://www.law.csuohio.edu/)\n  + [Online](https://online.csuohio.edu)\n  + [CampusNet](https://campusnet.csuohio.edu)\n  + [Financial Aid and Scholarships](http://www.csuohio.edu/financial-aid)\n  + [Tuition and Fees](https://www.csuohio.edu/bursar/current-academic-year-tuition-and-fees)\n  + [Pre-College Programs](https://www.csuohio.edu/admissions/college-credit-plus)\n* [Academics](https://www.csuohio.edu/academic/ \"Expand menu Academics\")\n  + [Academic Calendar](https://www.csuohio.edu/registrar/academic-calendar)\n  + [Colleges](https://www.csuohio.edu/academics/colleges)\n  + [Majors](https://www.csuohio.edu/majors)\n  + [Blackboard Login](https://www.csuohio.edu/center-for-elearning/blackboard-login)\n  + [Workforce Development](https://www.csuohio.edu/continuing-education/course-catalog)\n* [Athletics](https://www.csuvikings.com/)\n* [Give](https://www.supportcsu.org/)\n* [Research](https://www.csuohio.edu/research/ \"Expand menu Research\")\n  + [Office of Research](https://www.csuohio.edu/research)\n  + [Sponsored Programs and Research Services](https://www.csuohio.edu/sprs)\n  + [Technology Transfer](https://www.csuohio.edu/technology-transfer)\n  + [Faculty Expertise Database](http://expertise.csuohio.edu/)\n  + [Library](http://library.csuohio.edu/)\n  + [Research Centers](https://www.csuohio.edu/research/research-centers)\n\n* [A-Z Index](https://www.csuohio.edu/azindex)\n* [Alumni](https://www.csualumni.com/)\n* [Career Services](https://www.csuohio.edu/career-development-exploration)\n* [Disability Resources](http://www.csuohio.edu/disability)\n* [Military and Veterans](http://www.csuohio.edu/veteran-benefits)\n* [Parking](http://www.csuohio.edu/parking)\n* [Recreation Services](https://csurec.com/)\n* [Residence Life](https://www.csuohio.edu/residence-life/residence-life-and-housing)\n* [Viking Outfitters](http://www.vikingoutfitters.com/)\n\n\n\n#### [Academic Support Hub](/tutoring)\n\n---\n\n**Fall Semester Hours of Operation**  \nMonday–Thursday: 9 A.M.–7 P.M.\n\nFriday: 9 A.M.–4 P.M.\n\n**Campus Location**  \nBerkman Hall (BH) 233  \n1899 East 22nd Street  \nCleveland, Ohio 44115-2214  \nPhone: 216-687-2012  \n[tutoring@csuohio.edu](mailto:tutoring@csuohio.edu)\n\n**Mailing Address**  \nAcademic Support Hub  \nCleveland State University  \n2121 Euclid Ave., BH 233  \nCleveland, Ohio 44115-2214\n\n# Learning and Study Strategies Inventory (LASSI)\n\n**What is LASSI?**\n\nThe LASSI is a 10-scale, 60-item assessment of students' awareness about and use of learning and study strategies related to following components of Strategic Learning.  It may take 10 to 20 minutes to complete.\n\nYou will be asked to respond to 60 statements. To help you decide which responses to select, here is an explanation of what is meant by each option.\n\n* By Not at all typical of me, this would be true of you only in rare instances.\n* By Not very typical of me, the statement would generally not be true of you.\n* By Somewhat typical of me, the statement would be true about half the time.\n* By Fairly Typical of me, the statement would generally be true of you.\n* By Very much typical of me, This answer is not necessarily meant to describe you always, but it would be true almost all of the time.\n\nAfter completing all the items and successfully submitting the results, a two-page report will be displayed listing your scores for each of ten scales. An explanation of the results will be a part of the report. Your scores should help you understand more about yourself and how you compare to others who have taken this assessment. With these results you can also take steps to make meaningful improvements to your learning and study skills; personal tools that impact your success as a student.\n\n#### **Interested In Taking The LASSI?**\n\n**Interested in taking the LASSI?  Cleveland State students should contact the Academic Support Hub at [tutoring@csuohio.edu](mailto:tutoring@csuohio.edu) or call us at 216-687-2012 to set up an appointment with a Success Coach.**\n\n#### The Ten Scales Of The LASSI:\n\n### **The Skill**\n\nThe LASSI scales related to the skill component of strategic learning are: Information Processing, Selecting Main Ideas and Test Strategies. These scales examine students' learning strategies, skills and thought processes related to identifying, acquiring and constructing meaning for important new information, ideas and procedures, and how they prepare for and demonstrate their new knowledge on tests or other evaluative procedures.\n\n### **The Will**\n\nThe LASSI Scales related to the will component of strategic learning are: Attitude, Motivation and Anxiety. These scales measure students' receptivity to learning new information, their attitudes and interest in college, their diligence, self-discipline, and willingness to exert the effort necessary to successfully complete academic requirements, and the degree to which they worry about their academic performance.\n\n### **The Self-regulation**\n\nThe LASSI Scales related to the self-regulation component of strategic learning are: Concentration; Time Management; Self-Testing and Study Aids. These scales measure how students manage, or self-regulate and control, the whole learning process through using their time effectively, focusing their attention and maintaining their concentration over time, checking to see if they have met the learning demands for a class, an assignment or a test, and using study supports such as review sessions, tutors or special features of a textbook.\n\nThe focus is on both covert and overt thoughts, behaviors, attitudes and beliefs that relate to successful learning and that can be altered through educational interventions.\n\nResearch has repeatedly demonstrated that these factors contribute significantly to success in college and that they can be learned or enhanced through educational interventions such as learning and study skills courses.\n\nThe LASSI provides standardized scores (percentile score equivalents) and national norms for ten different scales (there is no total score since this is a diagnostic measure). The LASSI is both diagnostic and prescriptive. It provides students with a diagnosis of their strengths and weaknesses, compared to other college students, in the areas covered by the 10 scales and it is prescriptive in that it provides feedback about areas where students may be weak and need to improve their knowledge, attitudes, beliefs and skills.\n\n### Anxiety\n\n[Reducing Anxiety](https://www.csuohio.edu/sites/default/files/Reducing%20Anxiety.pdf)\n\n[Stress Management Strategies](https://www.csuohio.edu/sites/default/files/Stress%20Management%20Strategies.pdf)\n\n[Successful Strategies](https://www.csuohio.edu/sites/default/files/Successful%20Strategies.pdf)\n\n### Attitude\n\n[Attitude Is Everything](https://www.csuohio.edu/sites/default/files/Attitude%20Is%20Everything.pdf)\n\n[Creating SMART Goals](https://www.csuohio.edu/sites/default/files/Creating%20SMART%20Goals.pdf)\n\n[Develop Positive Habits](https://www.csuohio.edu/sites/default/files/Develop%20Positive%20Habits.pdf)\n\n[Practice Goal-Setting](https://www.csuohio.edu/sites/default/files/Practice%20Goal%20Setting.pdf)\n\n### Concentration\n\n[Learning Styles Inventory and Strategies](https://www.csuohio.edu/sites/default/files/Learning%20Styles.pdf)\n\n[Listening Skills](https://www.csuohio.edu/sites/default/files/Listening%20Skills.pdf)\n\n[My Ideal Study Environment](https://www.csuohio.edu/sites/default/files/My%20Ideal%20Study%20Environment.pdf)\n\n[The Pomodoro Technique](https://www.csuohio.edu/sites/default/files/The%20Pomodoro%20Technique.pdf)\n\n### Information Processing\n\n[Active Study](https://www.csuohio.edu/sites/default/files/Active%20Study.pdf)\n\n[Annotating in Five Easy Steps](https://www.csuohio.edu/sites/default/files/Annotating%20In%20Five%20Easy%20Steps.pdf)\n\n[Breaking Barriers to Reading](https://www.csuohio.edu/sites/default/files/Breaking%20Barriers%20To%20Reading.pdf)\n\n[Effective Reading](https://www.csuohio.edu/sites/default/files/Effective%20Reading.pdf)\n\n[Fold Out to Find Out](https://www.csuohio.edu/sites/default/files/Fold%20Out%20to%20Find%20Out.pdf)\n\n[Know Wonder Learn](https://www.csuohio.edu/sites/default/files/Know%20Wonder%20Learn.pdf)\n\n[Main Idea Map](https://www.csuohio.edu/sites/default/files/Main%20Idea%20Map.pdf)\n\n### Motivation\n\n[Creating SMART Goals](https://www.csuohio.edu/sites/default/files/Creating%20SMART%20Goals.pdf)\n\n[Go For It!](https://www.csuohio.edu/sites/default/files/Go%20For%20It%21.pdf)\n\n[Motivation & Your Beliefs](https://www.csuohio.edu/sites/default/files/Motivation%20And%20Your%20Beliefs.pdf)\n\n[Motivation](https://www.csuohio.edu/sites/default/files/Motivation.pdf)\n\n[The Benefits of Higher Education](https://www.csuohio.edu/sites/default/files/The%20Benefits%20Of%20Higher%20Education.pdf)\n\n### Selecting Main Ideas\n\n[Cornell Notes](https://www.csuohio.edu/sites/default/files/Cornell%20Notes.pdf)\n\n[Fold Out to Find Out](https://www.csuohio.edu/sites/default/files/Fold%20Out%20to%20Find%20Out.pdf)\n\n[Note Taking: Cornell Method](https://www.csuohio.edu/sites/default/files/Note%20Taking%20Cornell%20Method.pdf)\n\n[Reviewing the Main Ideas](https://www.csuohio.edu/sites/default/files/Reviewing%20the%20Main%20Ideas.pdf)\n\n[Study Guide Map](https://www.csuohio.edu/sites/default/files/Study%20Guide%20Map.pdf)\n\n[Taking Lecture Notes](https://www.csuohio.edu/sites/default/files/Taking%20Lecture%20Notes.pdf)\n\n### Self Testing\n\n[Learning Styles Inventory and Strategies](https://www.csuohio.edu/sites/default/files/Learning%20Styles%20Inventory%20and%20Strategies.pdf)\n\n[Memory Power for Facts and Concepts](https://www.csuohio.edu/sites/default/files/Memory%20Power%20for%20Facts%20and%20Concepts.pdf)\n\n[Ten Tips for Self-Testing](https://www.csuohio.edu/sites/default/files/Ten%20Tips%20for%20Self-Testing.pdf)\n\n### Test Strategies\n\n[Before, During, and After](https://www.csuohio.edu/sites/default/files/Before%20During%20and%20After.pdf)\n\n[Fold Out to Find Out](https://www.csuohio.edu/sites/default/files/Fold%20Out%20to%20Find%20Out.pdf)\n\n[Organized Checklist for Binder and Notebooks](https://www.csuohio.edu/sites/default/files/Organized%20Checklist%20for%20Binders%20and%20Notebooks.pdf)\n\n[LASSI Post-Test Analysis](https://www.csuohio.edu/sites/default/files/Post-Test%20Analysis.pdf)\n\n[Test-Taking Strategies](https://www.csuohio.edu/sites/default/files/Test-Taking%20Strategies.pdf)\n\n### Time Management\n\n[168 Hour Week](https://www.csuohio.edu/sites/default/files/168%20Hour%20Week.pdf)\n\n[168 Recorded Hours](https://www.csuohio.edu/sites/default/files/168%20Recorded%20Hours.pdf)\n\n[Daily Prioritizer](https://www.csuohio.edu/sites/default/files/Daily%20Prioritizer.pdf)\n\n[How Well Do You Plan?](https://www.csuohio.edu/sites/default/files/How%20Well%20Do%20You%20Plan.pdf)\n\n[Study Log](https://www.csuohio.edu/sites/default/files/Study%20Log.pdf)\n\n[Weekly Planner](https://www.csuohio.edu/sites/default/files/Weekly%20Planner.pdf)\n\n### Using Academic Resources\n\n[Campus Resources](https://www.csuohio.edu/sites/default/files/Campus%20Resources_1.pdf)\n\n**Fall Semester Hours of Operation**  \nMonday–Thursday: 9 A.M.–7 P.M.\n\nFriday: 9 A.M.–4 P.M.\n\n**Campus Location**  \nBerkman Hall (BH) 233  \n1899 East 22nd Street  \nCleveland, Ohio 44115-2214  \nPhone: 216-687-2012  \n[tutoring@csuohio.edu](mailto:tutoring@csuohio.edu)\n\n**Mailing Address**  \nAcademic Support Hub  \nCleveland State University  \n2121 Euclid Ave., BH 233  \nCleveland, Ohio 44115-2214\n\n \n\nTitle: Complete a LASSI (Learning & Study Skills Inventory)\nURL: https://www.kpu.ca/sites/default/files/Learning%20Centres/Study_LASSI_LA_0.pdf\nContent: The LASSI is a 10-scale, 80-item assessment of learners' awareness about and use of learning and study strategies related to skill, will and self-regulation.\nRaw Content: The Learning Centres KPU Surrey  KPU Richmond  KPU Langley  KPU Tech kpu.ca/learningcentres Complete a LASSI (Learning & Study Skills Inventory) 1 of 2 Learning Aid This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License Overview of LASSI Extensive research, development, and testing led to the creation of this statistically valid and reliable tool for the diagnosis of study skills. The LASSI is a 10-scale, 80-item assessment of learners' awareness about and use of learning and study strategies related to skill, will and self-regulation components of strategic learning. The focus is on both covert and overt thoughts, behaviors, attitudes and beliefs that relate to successful learning and that can be altered through educational interventions. Research has repeatedly demonstrated that these factors contribute significantly to success in college and that they can be learned or enhanced through educational interventions such as learning and study skills courses. The LASSI provides standardized scores (percentile score equivalents) and national norms for ten different scales (there is no total score since this is a diagnostic measure). The LASSI is both diagnostic and prescriptive. It provides learners with a diagnosis of their strengths and weaknesses, compared to other college learners, in the areas covered by the 10 scales and it is prescriptive in that it provides feedback about areas where learners may be weak and need to improve their knowledge, attitudes, beliefs and skills. The LASSI was developed at the University of Texas at Austin by Claire Ellen Weinstein, Ph.D., Ann C. Schulte, Ph.D., and David R. Palmer, Ph.D. Skill Component of Strategic Learning The LASSI scales related to the skill component of strategic learning are: Information Processing, Selecting Main Ideas and Test Strategies. These scales examine learners' learning strategies, skills and thought processes related to identifying, acquiring and constructing meaning for important new information, ideas and procedures, and how they prepare for and demonstrate their new knowledge on tests or other evaluative procedures. Will Component of Strategic Learning The LASSI Scales related to the will component of strategic learning are: Attitude, Motivation and Anxiety. These scales measure learners' receptivity to learning new information, their attitudes and interest in college, their diligence, self-discipline, and willingness to exert the effort necessary to successfully complete academic requirements, and the degree to which they worry about their academic performance. Self-regulation Component of Strategic Learning The LASSI Scales related to the self-regulation component of strategic learning are: Concentration; Time Management; Self-Testing and Study Aids. These scales measure how learners manage, or self-regulate and control, the whole learning process through using their time effectively, focusing their attention and maintaining their concentration over time, checking to see if they have met the learning demands for a class, an assignment or a test, and using study supports such as review sessions, tutors or special features of a textbook. Completing the LASSI The Learning and Study Strategies Inventory (LASSI) is designed to gather information about learning and study practices and attitudes. Upon submission and approval of your institution number, The Learning Centres KPU Surrey  KPU Richmond  KPU Langley  KPU Tech kpu.ca/learningcentres Complete a LASSI (Learning & Study Skills Inventory) 2 of 2 Learning Aid This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License 60 statements will be presented that relate to your knowledge of these areas. You can access the inventory on any web enabled computer. Try to use one that is connected to a printer so that you can print your results. When you are ready to begin, locate the following URL with your web browser: http://collegelassi.com This URL will direct you to a web page that contains directions for taking the LASSI. After you have read these directions, you must enter your school number to continue. Your school number is listed below along with your user name and password. School Number: 80280 User Name: auwv User Password: kyr8g After entering this information, the next screen to appear requires you to enter your first and last name into the spaces provided for the page to be submitted correctly. The ID and E-mail fields are optional. The next screen to appear will be the LASSI assessment. You will be asked to respond to 80 statements. To help you decide which responses to select, we would like to explain what is meant by each option. • By Not at all typical of me, we do not necessarily mean that the statement would never describe you, but that it would be true of you only in rare instances. • By Not very typical of me, we mean that the statement generally would not be true of you. • By Somewhat typical of me, we mean that the statement would be true of you about half of the time. • By Fairly typical of me, we mean that the statement would generally be true of you. • By Very much typical of me, we do not necessarily mean that the statement would always describe you, but that it would be true of you almost all the time. After completing all the items and successfully submitting the results, a two-page report will be displayed listing your scores for each scale, together with your name, institution, date of administration, and an explanation of your results. You should print a copy of the results for your records. The next step is to book an appointment with a Learning Strategist in your nearest Learning Centre to debrief your results and discuss actions that you can take to become an even better learner.\n\nTitle: LASSI 3rd Ed User's Manual\nURL: https://www.hhpublishing.com/LASSImanual.pdf\nContent: by CE Weinstein · 2016 · Cited by 57 — What is the LASSI, 3rd Edition, and What Does it Measure? The Learning and Study Strategies Inventory (LASSI) is a 10-scale, 60-item assessment of students'\nRaw Content: ! ! LASSI 3rd Edition – User’s Manual – Page \"1 by Claire Ellen Weinstein, Ph.D. Professor Emeritus The University of Texas at Austin !\nDavid R. Palmer, Ph.D. Principal David Palmer Consulting !\nTaylor W. Acee, Ph.D. Associate Professor Texas State University Learning and Study Strategies Inventory, 3rd Edition Learning and Study Strategies Inventory LASSI Third Edition User’s Manual ! LASSI 3rd Edition – User’s Manual – Page \"2 LASSI Acknowledgements !\nIt is impossible to thank the large number of individuals who have contributed to the development of the LASSI over the years. Many generations of graduate students, numerous colleagues, and other friends have generously given of their time, talents, and skills. In addition, much of the research support for the design and development of earlier versions of the LASSI was provided by the Army Research Institute for the Behavioral and Social Sciences and the Spencer Foundation. Finally, people have made such enormous contributions that they deserve individual mention: the original inspirations for this work, “Mama” and “Papa” Weinstein; our unconditional support team, Leona Sheryl Weinstein, Dr. Linda Hargrove, Chandler Hargrove Palmer, and Danielle H. Acee; the original psychometric consultant for our project, Dr. Gary Hanson, our original research assistant, Ann Schulte, our publisher and editorial team: Dr. Robert Hackworth, Michael Ealy, Priscilla Trimmier, and Karen Hackworth. And finally, we want to thank the thousands of learning-assistance professionals who used the LASSI, who continue to use the LASSI, and those who have given us feedback which was so helpful in creating this new edition of the LASSI. To all of you we are eternally grateful and appreciative of your efforts.\nUser’s Manual Learning and Study Strategies Inventory Third Edition !\nCopyright ©2016 !\nClaire Ellen Weinstein, Ph.D. David R. Palmer, Ph.D. Taylor W. Acee, Ph.D. !\nH&H Publishing Company, Inc. (800) 366-4079 (727) 442-7760 hhservice@hhpublishing.com www.hhpublishing.com !\n! LASSI 3rd Edition – User’s Manual – Page \"3 Table of Contents !\nPart 1: What is New about the LASSI, 3rd Edition? 4 Part 2: Overview of the LASSI, 3rd Edition 6 Part 3: Administration and Scoring 11 Part 4: Description of the Individual LASSI Scales 13 Part 5: The Development of the LASSI, 1st Edition 22 Part 6: The Development of the LASSI, 2nd Edition 26 Part 7: The Development of the LASSI, 3rd Edition 29 Part 8: Administering the WEB LASSI 33 Appendix A: Descriptions of the Field Test and Norming Sample (Tables 1-9) 43 Appendix B: Summaries of the Item Statistics for each LASSI, 3rd Edition Scale (Tables 10-19) 47 Appendix C: Individual Scale Statistics (Table 20) 52 Appendix D: Correlations Among LASSI Scales (Table 21) 53 Appendix E: LASSI, 3rd Edition Scale Norms (Table 22) 54 !\nPART 1: WHAT IS NEW ABOUT THE LASSI, 3RD EDITION? !\nMost of the changes in the LASSI, 3rd Edition, are in response to student data, user comments, changing practices in the ﬁeld, and an expanding research base. For example, users requested a shorter version of the LASSI, 2nd Edition; in response we worked to reduce the number of items from 80 to 60, while maintaining the strong psychometric properties of the scales. In response to the changing practices in the ﬁeld as well as more recent research, we put a greater emphasis on student-initiated help-seeking by creating a new scale. The UAR Scale (Using Academic Resources) was created and replaces the Study Aids Scale. !\nSummary of the Changes in the LASSI, 3rd Edition !\n1. The largest change in the LASSI, 3rd Edition, is that we reduced the number of items from 80 to 60. Now each scale is comprised of 6 items as opposed to 8 items. Completing the LASSI, 3rd Edition, will take approximately 9-11 minutes. This change was largely in response to users’ comments and requests. This change makes it easier to administer the LASSI, 3rd Edition, in a timely manner while maintaining the psychometric strengths that have made it a standard in strategic and self-regulated learning assessment. !\n2. We removed the somewhat dated Study Aids Scale and replaced it with a new scale called Using Academic Resources (UAR), which ﬁts with current conceptions and research in self-regulated learning and student learning assistance. All items on the UAR scale are new (and were selected from a larger pool of items used in ﬁeld testing). UAR measures students’ help-seeking preferences and behaviors. For example, do they go to a writing center, or a tutor, or a classmate if they need help with a course or assignment? Conversely, do they avoid seeking help? !\n3. We added one new item to the Motivation Scale to address students’ effort. This is a better ﬁt with current conceptions of motivation components. ! LASSI 3rd Edition – User’s Manual – Page \"4 4. To improve readability, we made revisions to two items that we kept from the LASSI, 2nd Edition. The wording in Item #5 (TST Scale) was changed from past tense to present tense. The wording in Item #9 (SMI Scale) was changed to use a singular tense. !\n5. The LASSI, 3rd Edition, has four introspective questions which follow the 60 items. These questions are unscored for the students. Results will be given to the administrator. We expect both students and advisors to beneﬁt from this addition. LASSI 3rd Edition – User’s Manual – Page \"5 !\nPART 2: OVERVIEW OF THE LASSI, 3RD EDITION !\nWhat is the LASSI, 3rd Edition, and What Does it Measure? !\nThe Learning and Study Strategies Inventory (LASSI) is a 10-scale, 60-item assessment of students’ awareness about and use of learning and study strategies related to skill, will and self-regulation components of strategic learning. The focus is on covert and overt thoughts, behaviors, attitudes, motivations and beliefs that relate to successful learning in postsecondary educational and training settings. Furthermore, these thoughts, behaviors, attitudes, motivations and beliefs can be altered through educational interventions. Research has repeatedly demonstrated that these factors contribute signiﬁcantly to success in college and that they can be learned or enhanced through educational interventions such as learning strategies and self-regulated study courses and programs. !\nThe LASSI is both diagnostic and prescriptive. The LASSI provides standardized scores (percentile score equivalents) and national norms for ten different scales (there is no total score reported because this is a diagnostic instrument). It provides students with a diagnosis of their strengths and weaknesses, compared to other college students, in the areas covered by the ten scales; it is prescriptive in that it provides feedback about areas where students may be weak and need to improve their knowledge, skills, attitudes, motivations and beliefs. !\nHow Can the LASSI Be Used? !\nThe LASSI is designed to be used as: !\n(1) A screening measure to help students develop greater awareness of their learning and studying strengths and weaknesses. (2) A diagnostic measure to help identify areas in which students could beneﬁt most from educational interventions. (3) A basis for planning individual prescriptions for both remediation and enrichment. (4) A tool for tutors and academic coaches to help students identify areas they need to improve for different courses. LASSI 3rd Edition – User’s Manual – Page \"6 (5) A tool for a learning center to use to determine areas of greatest need for workshops, seminars and independent study. (6) A means for instructors to use for examining individual students’ scores and class trends to help them decide where to place the greatest emphasis for assignments, projects, individual logs, journals, portfolios and other class activities. (7) A pre-post achievement measure for students participating in programs or courses focusing on learning strategies and study skills. (8) An evaluation tool to assess the degree of success of intervention courses or programs. (9) An advising/counseling tool for college orientation programs, ﬁrst-year experience or seminar courses, advisors, developmental education programs, learning assistance programs, and learning centers. !\nIntroduction to the LASSI Scales !\n!\nThere are six items on each of the ten scales of the LASSI, 3rd Edition. These scales are: Anxiety, Attitude, Concentration, Information Processing, Motivation, Selecting Main Ideas, Self Testing, Test Strategies, Time Management, and Using Academic Resources. !\nEach of these scales is primarily related to one of three of the components of strategic learning: skill, will and self-regulation. The conceptual framework of strategic learning underlies each of these components, so there is some overlap and interaction among and within the components and individual scales. However, strategic learners need to know about each of these categories and about how to use information and skills in each of these categories. They also need to know how to pick and choose among the various elements in each category to help them reach speciﬁc learning goals and objectives. !\nThe Skill Component of Strategic Learning !\nThe LASSI scales related to the skill component of strategic learning are: Information Processing, Selecting Main Ideas, and Test Strategies. These scales examine students’ learning strategies, skills and thought processes related to identifying, acquiring and LASSI 3rd Edition – User’s Manual – Page \"7 constructing meaning for important new information, ideas and procedures, and how they prepare for and demonstrate their new knowledge on tests or other evaluative procedures. !\nThe Information Processing Scale assesses how well students’ can use imagery, verbal elaboration, organization strategies, and reasoning skills as learning strategies to help learn new information and skills. These strategies are also used to build bridges between what students already know or believe and what they are trying to learn and remember. !\nDo students try to summarize or paraphrase their class reading assignments? Do they try to relate what is being presented in class to their prior knowledge? !\nThe Selecting Main Ideas Scale assesses students’ thinking skills for identifying important information for further study from less important information and supporting details. !\nCan students identify the key points in a lecture? Can they decide what is important to underline in a textbook? !\nThe Test Strategies Scale assesses students’ use of both test preparation and test taking strategies. !\nDo students know how to study for tests in different types of courses? Do they review their answers to essay questions? !\nThe Will Component of Strategic Learning !\nThe LASSI scales related to the will component of strategic learning are: Anxiety, Attitude, and Motivation. These scales measure the degree to which students worry about their academic performance, their receptivity to learning new information, their attitudes and interest in college, their diligence, self-discipline, and willingness to exert the effort necessary to successfully complete academic requirements. !\nThe Anxiety Scale assesses the degree to which students worry about school and their academic performance. LASSI 3rd Edition – User’s Manual – Page \"8 Do students worry so much that it is hard for them to concentrate? Are they anxious even when they are well-prepared? !\nThe Attitude Scale assesses students’ attitudes and interests in college and achieving academic success. !\nDo students only study for the courses they like? Is college really important or worthwhile to them? !\nThe Motivation Scale assesses students’ diligence, self-discipline, and willingness to exert the effort necessary to successfully complete academic requirements. !\nAre students willing to put in the effort necessary to succeed on academic assignments? Do they easily “give up” in difﬁcult classes? !\nThe Self-Regulation Component of Strategic Learning !\nThe LASSI scales related to the self-regulation component of strategic learning are: Concentration, Self Testing, Time Management and Using Academic Resources. These scales measure how students manage, self-regulate or control the entire learning process. These processes include: using time effectively, focusing attention and maintaining concentration, checking to determine if learning demands for a class, assignment, or a test have been met, and a willingness to seek help from instructors, fellow students, tutors, academic coaches, learning centers and tutoring programs. !\nThe Concentration Scale assesses students’ ability to direct and maintain their attention on academic tasks. !\nAre students easily distracted? Can they direct their attention to academic tasks? ! LASSI 3rd Edition – User’s Manual – Page \"9 The Self Testing Scale assesses students’ use of comprehension monitoring techniques, such as reviewing or paraphrasing, to determine their level of understanding of the information or skill to be learned. !\nDo students create and respond to questions that might be asked on a test? Do they stop periodically while reading to review the content? !\nThe Time Management Scale assesses students’ use of time management principles and practices for academic tasks. !\nDo students procrastinate about completing academic tasks? Do they strategically manage their time for studying? !\nThe Using Academic Resources Scale assesses students’ willingness to use different academic resources such as writing centers, tutoring centers and learning or academic support centers, when they encounter problems with their coursework or performance. !\nDo students go to a resource center for guidance? Do they avoid going for help? NOTES: Sample items for each scale are included in Part 4: Description of the Individual LASSI Scales. Coeﬃcient Alphas for the scales range from a low of .76 to a high of. 87 !\n! LASSI 3rd Edition – User’s Manual – Page \"10 !\nPART 3: ADMINISTRATION AND SCORING !\nThe LASSI is designed to simplify administration and scoring as much as possible without losing power or diagnostic information. To help achieve this goal, it uses a self-report format and does not require any special administration procedures, such as specially trained personnel. The LASSI, 3rd Edition, is not a timed measure but most students complete it in approximately 9-11 minutes. The scoring is completed online and the scoring reports are computer-generated and available immediately. !\nFor each of the 60 items on the LASSI, students are requested to select one of the ﬁve responses that corresponds to how well the statement describes them. Students are also cautioned to respond according to how well the statements reﬂect their behaviors or thinking processes and not how they think they should respond or how others would respond. !\nThe LASSI yields ten individual scale scores, one for each of the ten scales. No total score is computed because this is a diagnostic instrument. These scale scores can then be compared numerically or graphically to the norms provided or to local norms or cut-off scores developed by an institution or program. The data provided with the LASSI includes percentile score equivalents. Based on a student’s scale scores, either in relation to the national norms included with the instrument or to a percentile cut-off score (the 75th percentile being a common cut-off used on many campuses), prescriptions can then be made. For example, if a student scores poorly on the Test Strategies Scale, he/she should be advised to concentrate at least part of his/her efforts on learning more about how to prepare for and take tests. A low score on the Anxiety Scale indicates a difﬁculty with focusing attention on task-relevant thoughts and behaviors rather than on fears and concerns about failure and incompetence. The student doing poorly on this scale would need to learn more about dealing with irrational thoughts and negative self-talk. She or he would have to learn how to cope with anxiety-arousing stimuli and take more responsibility for the direction of her or his own thinking processes. !\nEach LASSI contains the following parts: !\n1) An introduction to the inventory. LASSI 3rd Edition – User’s Manual – Page \"11 2) An explanation of how to complete the LASSI. 3) The inventory items. 4) Information about interpreting individual scale scores. !\nAll scoring, reporting, and graphics are generated automatically and available to the administrator. The student also receives individual scores unless the administrator has speciﬁcally asked for a No Student Results version. !\nIt should also be noted that approximately half of the items use reverse scoring to reduce response bias. Some of the items are stated in a positive direction (“I try to identify potential test questions when reviewing my class material.”) while others are stated in a negative direction (“I ﬁnd it hard to pay attention during lectures.”). To get a better overall view of their performance, these total scale scores are shown on a graph using the national norms for each scale to transform the raw scores into percentiles. In this way, relative performance in different areas are assessed. !\nStudents can see how their answers compare to the answers of the norm groups. The graph is also marked off at the 75th and 50th percentiles to facilitate advising and counseling. Students who score above the 75th percentile often do not need to work on the strategies or skills for that scale. Students who score between the 75th and the 50th percentile on any scale should consider improving the relevant learning and study skills to optimize their academic performance. Students who score below the 50th percentile usually need to improve their relevant knowledge and skills to increase their chances of succeeding in a post secondary setting. It should also be noted that these cut-offs could be modiﬁed depending on the local setting or the development of local norms. A copy of the national norms used to create the graph can be found in Table 22 of this user’s manual. The data in Table 22 represents the percentile score of students in the norm group that fall at or below a given raw score for each scale. ! LASSI 3rd Edition – User’s Manual – Page \"12 !\nPART 4: DESCRIPTION OF THE INDIVIDUAL LASSI SCALES !\nANXIETY !\nCurrent conceptions of anxiety emphasize the interactive effects of students’ thought processes, beliefs, and emotions along with how they affect academic performance. Cognitive worry, a major component of anxiety, is manifested in negative self-referent statements. These negative thoughts, beliefs and feelings about one’s abilities, intelligence, future, interactions with others, or likelihood of success, divert a student’s attention from the task at hand, such as studying or taking a test. If a student is worried that he will not have the time to ﬁnish a test, then he is just making matters worse by wasting time while worrying about his performance. This type of self-defeating behavior often sabotages a student’s efforts. If students are tense, anxious, or fearful about studying or performing in academic situations, this will divert their attention from the academic task and inward toward self-criticism or irrational fears. !\nStudents’ scores on this scale measure how tense or concerned they are when approaching academic tasks. Students who score low on this measure (indicating high anxiety) need to learn techniques for coping with anxiety and reducing worry so that they can focus on the task at hand and not on their anxiety. Many very capable students are often incapable of demonstrating their true level of knowledge and skill because they are paralyzed or distracted by debilitating anxiety. In fact, helping some students learn how to reduce their anxiety is sufﬁcient for helping them to improve their performance. Once these attentional blocks are removed, many students show large increases in performance. !\nCoefﬁcient Alpha = .87 !\nSample Items: !\nWhen I am studying, worrying about doing poorly in a course interferes with my concentration. !\nI feel very panicky when I take an important test. !\n!\n! LASSI 3rd Edition – User’s Manual – Page \"13 !\nA TTITUDE !\nStudents’ general attitudes toward school and their reasons, or lack of reasons, for succeeding in school have a great impact on their diligence when studying, particularly in autonomous situations in which they must study on their own. If the relationships between school and life goals (academic, personal, social and work-related goals) are not clear, then it is difﬁcult to maintain a mind-set that promotes good work habits, concentration, attention to school, and its related tasks. !\nStudents’ scores on this scale measure their general attitudes and reasons for succeeding in school and interest in performing the tasks related to school success. Students who score low on this measure need to work on higher-level goal setting and reassess how school ﬁts into their future. If school is not seen as relevant to the student’s life goals and attitudes, then it will be difﬁcult, if not impossible, to generate the level of motivation needed to help take responsibility for one’s own learning and successfully managing one’s own study activities. !\nCoefﬁcient Alpha = .76 !\nSample Items: !\nI have a positive attitude about attending my classes. !\nI only study the subjects I like. !\nCONCENTRA TION !\nConcentration helps students to focus their attention on school-related activities, such as studying and listening in class, rather than on distracting thoughts, emotions, feelings, or situations. People have a limited capacity to process what is going on around them and in their own thoughts; if they are distracted, there will be less capacity to focus on the task at hand. For students this means that distractions, or anything else that interferes with concentration, will divert attention from school-related tasks. !\nStudents’ scores on this scale measure their abilities to direct and maintain their attention to school and school-related tasks, including study activities. Students who score high on this measure are effective at focusing their attention and maintaining a high level of concentration. LASSI 3rd Edition – User’s Manual – Page \"14 Students who score low on this measure are less successful at focusing their attention on the task at hand by eliminating interfering thoughts, emotions, feelings, and situations. They need to learn techniques to enhance concentration and to set priorities so that they can attend to school as well as to their other responsibilities. Learning techniques for focusing attention and maintaining concentration help students implement effective learning strategies and can make learning and studying both more effective and more efﬁcient. !\nCoefﬁcient Alpha = .85 !\nSample Items: !\nMy mind wanders a lot when I study. !\nIf I get distracted during class, I am able to refocus my attention. !\nINFORMA TION PROCESSING !\nMeaningful learning is enhanced by the use of elaboration and organization strategies. These strategies help build bridges between what a student knows and what he or she is trying to learn and remember. Using what we already know (prior knowledge, experiences, attitudes, beliefs, and reasoning skills) to help make meaning out of new information is critical to success in educational and training settings. The difference between an expert and a novice is not just the amount of knowledge they possess but also, and perhaps even more important, the way that knowledge is acquired and organized. It is the difference between storing one thousand folders by throwing them in the middle of a room versus storing them by some meaningful organization in ﬁling cabinets. !\nStudents’ scores on this scale measure how well they can create imaginal and verbal elaborations and organizational schemes to foster understanding and recall. Students who score low on this measure need to learn methods that they can use to help add meaning and organization to what they are trying to learn. These methods range from simple paraphrasing and summarizing to creating analogies, the use of application, creating organizational schemes and outlining, and the use of synthesis, inferential, and analytic reasoning skills. A student who does not have a repertoire of these strategies and skills will ﬁnd it difﬁcult to incorporate new knowledge and understanding in such a way that acquisition and recall will be effective, often despite the large amount of time spent studying. The effectiveness and efﬁciency of both LASSI 3rd Edition – User’s Manual – Page \"15 autonomous and classroom learning are facilitated by the use of information processing strategies. !\nCoefﬁcient Alpha = .81 !\nSample Items: !\nTo help me remember new principles we are learning in class, I practice applying them. !\nI try to ﬁnd relationships between what I am learning and what I already know. !\nMOTIVATION !\nThe Motivation Scale measures the degree to which students take responsibility for studying, put effort into learning course material, and persist towards reaching their academic goals, especially when facing tasks that are difﬁcult or uninteresting. The Attitude Scale measures students’ general attitudes toward school and their reasons for wanting to succeed in school. While the Attitude Scale focuses on positive and negative attitudes that inﬂuence motivation, the Motivation Scale focuses on students’ levels of academic effort, persistence, and self-diligence. Although general attitudes and general sources of motivation are important, so is a student’s motivation to perform the speciﬁc tasks related to achievement. These behaviors include reading the textbook, preparing for class, ﬁnishing assignments on time, and being diligent in studying, even if the topic is not particularly interesting to them (or even trying to ﬁgure out ways to make it more interesting). Students’ beliefs also play a big role in motivation. For example, a student who “knows” (believes) he or she just cannot learn math will ﬁnd that generating motivation to study or go to someone for help is very difﬁcult. !\nStudents’ scores on this scale measure the degree to which they accept responsibility for performing the speciﬁc tasks related to school success. Students who score low on this measure need to work on goal setting, perhaps at the more global levels assessed on the Attitude Scale, but certainly at the more speciﬁc level of individual tasks and assignments. Accepting more responsibility for studying and achievement outcomes requires that students learn to attribute much of what happens to them in school to their own efforts rather than to outside forces such as luck or poor teachers, or to uncontrollable forces such as innate ability. LASSI 3rd Edition – User’s Manual – Page \"16 Accepting more responsibility and attributing success to one’s efforts results in more effective studying and academic performance. !\nCoefﬁcient Alpha = .77 !\nSample Items: !\nWhen work is difﬁcult I either give up or study only the easy parts. !\nI set goals for the grades I want to get in my classes. !\nSELECTING MAIN IDEAS !\nEffective and efﬁcient studying requires that students are able to select the important material for in-depth processing. Most lectures, discussions, and textbooks contain redundant material, extra examples, and many supporting details to help explain what is being taught or presented. A major academic task involves separating the important from the unimportant or simply didactic information that does not have to be remembered. If a student cannot select the critical information, then the learning task becomes complicated by the huge amount of material the individual is trying to acquire. Lacking this skill also increases the likelihood that the student will not have enough time to study everything that must be covered. !\nStudents’ scores on this scale measure their skills at selecting important information to concentrate on for further study in classroom, lecture or autonomous learning situations. Students who score low on this measure need to learn more about how to identify important information so that they can focus their attention and information processing strategies on appropriate material. !\nCoefﬁcient Alpha = .86 !\nSample Items: !\nI have difﬁculty identifying the important points in my reading. !\nWhen studying, I seem to get lost in the details and miss the important information. !\n!\n! LASSI 3rd Edition – User’s Manual – Page \"17 SELF TESTING !\nReviewing and testing one’s level of understanding are important for knowledge acquisition and comprehension monitoring. These strategies both support and contribute to meaningful learning and effective performance. Without them learning could be incomplete or errors might persist undetected. Reviewing and self testing also contribute to knowledge consolidation and integration across topics. Using mental reviews, going over class notes and the text, thinking up potential questions to guide reading or help prepare for an exam are all important methods for checking understanding, consolidating new knowledge, integrating related information (both from what is being learned and from what is already known), and identifying if additional studying must be done. !\nStudents’ scores on this scale measure their awareness of the importance of self testing and reviewing and the degree to which they use these methods. Students who score low on this scale need to learn more about the importance of self testing as well as speciﬁc methods for reviewing school material and monitoring their comprehension. These methods include structured reviews of large amounts of material; mental reviews of individual study segments; asking questions before, during, and after reading, studying, or going to class; trying to use new information in novel ways; trying to apply a principle or method; and using a systematic approach to studying. !\nCoefﬁcient Alpha = .80 !\nSample Items: !\nI stop periodically while reading and mentally go over or review what was said. !\nTo check my understanding of the material in a course, I make up possible test questions and try to answer them. !\nTEST STRATEGIES !\nEffective test performance depends on both preparation strategies and test-taking strategies. A student needs to know how to prepare for the type of performance that will be required and how to maximize that performance. Test preparation includes knowing about the type of test LASSI 3rd Edition – User’s Manual – Page \"18 they will be taking. For example, is it going to be a short-answer or a multiple-choice exam? Will performance require simple recall or will concepts, principles, and ideas need to be applied? Test preparation also includes knowing about methods for studying and learning the material in a way that will facilitate remembering the material and using it at a later time. Test-taking strategies include knowing about the characteristics of tests and test items, and how to create an effective test-taking plan. !\nStudents’ scores on this scale measure their use of test-taking and test-preparation strategies. Students who score low on this measure may need to learn more about how to prepare for tests, how to create a plan of attack for taking a test, the characteristics of different types of tests and test items, and how to reason through to an answer. Often, students’ performance on a test is not an accurate indicator of what they have learned. Knowing about test-taking and test-preparation strategies and how to use them helps students target their study activities, set up useful study goals, implement an effective study plan, and demonstrate their knowledge and skill acquisition so it can be accurately evaluated. !\nCoefﬁcient Alpha = .77 !\nSample Items: !\nI have difﬁculty adapting my studying to different types of courses. !\nI review my answers during essay tests to make sure I have made and supported my main points. !\nTIME MANAGEMENT !\nManaging time effectively is an important self-regulation strategy for learning. Most students have various demands on their time; only by creating realistic schedules and using them can they ﬁt in much or all of what they need to do. Creating and using schedules also encourages students to take more responsibility for their own behavior. It requires some knowledge about themselves as students and learners. What are their best and worst times of day? Which subjects are easier or harder for them? What are their preferences for learning methods? This type of knowledge and self awareness helps students to create workable schedules, and perhaps even more importantly, it helps students to create the motivation to use them. LASSI 3rd Edition – User’s Manual – Page \"19 !\nStudents’ scores on this scale measure the degree to which they create and use schedules. Students who score low on this scale may need to learn about how to create a schedule and how to deal with distractions, competing goals, and procrastination. Accepting more responsibility for studying and achievement outcomes requires that students set realistic school goals and create plans that will facilitate goal achievement. Effective time management enhances these activities. !\nCoefﬁcient Alpha = .80 !\nSample Items: !\nI ﬁnd it hard to stick to a study schedule. !\nI set aside more time to study the subjects that are difﬁcult for me. !\nUSING ACADEMIC RESOURCES !\nStudents need to know about and how to access and use a variety of academic resources designed to help them understand, learn, and retain what they are studying in their classes. Almost all post secondary educational institutions provide one or more of the following academic success resources: student success centers, learning centers, tutoring centers, academic coaches, writing centers, math centers, and mentoring. Students can also use more localized sources of help, such as instructors’ ofﬁce hours, student study groups and other classmates. When students encounter problems comprehending, learning or applying course concepts and skills, they need to seek help. Even though students may know they need learning assistance, many students are hesitant, even embarrassed, to seek help from others. The research literature on help-seeking suggests three major types of help-seeking approaches used by students: (1) avoidance help-seeking refers to students who do not want to ask for help, (2) executive help-seeking refers to students who just want someone to give them the answer (whether they understand it or not), and (3) instrumental help-seeking refers to students who seek help and want the answer but also want to learn how to do it on their own. Success and thriving in college requires an emphasis on instrumental help-seeking. !\nStudents’ scores on this scale measure their awareness, knowledge about, and use (or intended use) of informal and formal academic resources commonly available to students at 2- LASSI 3rd Edition – User’s Manual – Page \"20 year and 4-year post secondary institutions. Students who score low on this scale may need help identifying and effectively using resources as the need for learning assistance becomes apparent. It is important to tell students about tutoring centers and other services at orientation, but students are not generally concerned about grades at that point. After their ﬁrst assignment or test, the information may be perceived as more timely and relevant. In order to better reach students as their concerns are arising, have representatives of different student support services provide brief presentations during class or as part of a residence life program or other special program. Also, share testimonials from past and current students about their experiences using academic resources. Even when students do not like a course, they still have to learn the information for the ﬁnal exam or semester project; seeking help can provide students the necessary scaffolding to reach their goals. Students can also develop more effective learning strategies when they seek help. !\nCoefﬁcient Alpha = .76 !\nSample Items: !\nIf I am having trouble with a writing assignment, I seek help from resources available at my college such as the writing center, learning center, or tutoring center. !\nI am not comfortable asking for help from instructors in my courses. !\n!\n!\n!\n!\n!\n!\n!\n!\n!\n!\n!\n!\n! LASSI 3rd Edition – User’s Manual – Page \"21 !\nPART 5: THE DEVELOPMENT OF THE LASSI, 1ST EDITION !\nThe developmental work that led to the creation of the LASSI began in 1982 as part of the Cognitive Learning Strategies Project at the University of Texas at Austin. In response to the increasing numbers of academically underprepared students entering post secondary educational and training settings, many institutions were creating programs to address student weaknesses. However, one of the major problem areas in this ﬁeld related to assessment. The successful implementation of a learning and study strategies course or program requires a reliable and valid means for measuring students’ strengths and areas where they need to develop more effective and efﬁcient strategies and skills. In addition, an accurate diagnosis of entry-level skills could be used to create individualized prescriptions for improvement and subsequent assessments, as well as to provide a basis for evaluating the effectiveness of a course or program. !\nEarly Developmental Activities !\n!\nThe ﬁrst few years of work focused on data gathering. In addition, an analysis was made of existing published and experimental instruments and inventories. We found that the topics encompassed by the terms “study skills” and “learning strategies” varied considerably among researchers, practitioners, and assessment measures. Since there was no consensus concerning deﬁnitional components, the initial phases of this work involved an attempt to create a conceptual categorical scheme. To assist in this work, we conducted a survey project to examine the contents of study skills and learning books, manuals, and programs. Input was also gathered from a series of experts in the area. !\nDevelopment of an Item Pool !\nUsing the data gathered in the ﬁrst series of studies, an initial item pool was created. This pool of 645 items was drawn from all of the sources used in the early developmental stage. Using a tentative categorical scheme that was developed, expert judges were asked to sort the items into these categories. ! LASSI 3rd Edition – User’s Manual – Page \"22 During the process of sorting the items, two major problems were identiﬁed: ﬁrst, many items were close duplicates; and second, a number of items ﬁt into more than one category (e.g., time management as a test-taking strategy). The ﬁrst problem was resolved by eliminating duplicate items and the second was left to be addressed after the initial pilot tests when the categorical scheme could be revised based on both the descriptive and correlational data collected. In addition, items that did not directly deal with study practices (e.g., items about personality and personal characteristics) and items whose content concerned an aspect of behavior or experience that could not be altered by an educational intervention and, therefore, could not be a target for remediation (e.g., “My parents read to me as a child.”) were eliminated. Specialists in tests and measurements rewrote items that were confusing, compound items (those containing more than one question or statement in the same item), and poorly worded items. !\nAs a result of these selection processes, the pool of potential items was reduced to 291. Although the LASSI currently uses a Likert-type scale, these initial pilot items were converted to a true-false format. Approximately half of the items were worded positively and half were worded negatively. !\nPilot Testing !\nA preliminary pilot test was conducted to evaluate the administration procedures and to begin collecting psychometric data about the items. Different groups of students completed approxi- mately one third of the items (to reduce the burden of testing for any one individual), a mea- sure of social desirability and a questionnaire about the items and administration procedures. A subset of this population was also interviewed. !\nThe measure of social desirability was used to determine the degree of relationship between responses to individual items and the subject’s desire to be socially acceptable, or the degree to which they wanted to “look” good. This response bias can be a major problem for self-report instruments. The post-experimental questionnaire was used to gather information from the students about perceived difﬁculties, problem questions, and suggested modiﬁcations and improvements. ! LASSI 3rd Edition – User’s Manual – Page \"23 Based on an analysis of this data set and its relation to other student data such as Scholastic Aptitude Test scores, grade-point average, and high school rank, a number of changes were made. First, the format was changed to a Likert-type measure. Second, wording and phrasing changes were made on a number of items. Finally, items correlating above .50 with the mea- sure of social desirability were eliminated. In addition, confusing or unclear items were re- written or eliminated. !\nIn addition to eliminating items from the potential pool, a number of new items were added. The sources of these new items included: a survey of current research literature in cognitive psychology, responses from students on the post-experimental questionnaire, suggestions from practitioners, and student responses on the Learning Activities Questionnaire, a precursor of the LASSI developed as part of the project. !\nTwo content matter specialists and two psychometricians then examined this new pool of items independently. A revised set of 14 categories containing at least seven items for each category was created. This version of the LASSI had 149 items. !\nA second pilot test was conducted to evaluate the administration procedures and to examine the properties of the items on the revised instrument. The descriptive data collected and the student comments made during the feedback portion of the administration sessions were used to establish criteria for selecting items for the ﬁeld test version of the LASSI. This version of the LASSI had 130 items. In addition, a preliminary study of test-retest reliability (with a 3- to 4-week interval) was conducted. A test-retest correlation of .88 was computed for the total instrument. !\nScale Construction !\nA series of ﬁeld tests was conducted over a 2-year period. During this period the number of items was reduced from 130 to 90, and 10 scales measuring clusters of metacognitive approaches, learning strategies, self-regulation strategies, study skills, attitudes, motivation, and beliefs were developed. These clusters were identiﬁed by groups of experts and reﬁned using psychometric data, such as Coefﬁcient Alpha, for each potential scale. In addition, preliminary norms were developed using the Fall 1982 incoming freshman class at a small private college in the eastern United States. This college was identiﬁed by the U.S. Department LASSI 3rd Edition – User’s Manual – Page \"24 of Education as having a nationally representative student body. A total of 850 students participated, with complete data available for 780 students. !\nThe scales were reﬁned and 30 new items were created and added prior to another large- scale ﬁeld test in 1984. Item analysis data were used to create the 77-item form of the LASSI. Norms were developed using a sample of 880 incoming freshman from a large southern university. Test-retest correlations (3-week intervals) were computed on a sample of 209 students from an introductory course in communications at the same school. !\nA number of different approaches were used to examine the validity of the LASSI. First, the scale scores were compared, where possible, to other tests or subscales measuring similar factors. Second, several of the scales were validated against performance measures. Finally, the LASSI was subjected to repeated tests of user validity. Professors, advisors, developmental educators, counselors, tutors, and learning center specialists at more than 30 colleges and universities used the LASSI on a trial basis. They reported few, if any, administration problems and a high degree of usefulness in their settings. !\nWe have also examined the usefulness of the LASSI as part of our own work on the Cognitive Learning Strategies Project. It has been used repeatedly in an undergraduate course in learning-to-learn that is a part of our real-world laboratory. This course is designed to help academically underprepared and educationally disadvantaged students who are either experiencing, or are predicted to experience, academic problems while attending college. Approximately 1,000 students per year enroll. This 3-credit elective course is taught in sections of about 30 each. The LASSI has been used to help diagnose individual student problems, to direct both remediation and enrichment activities, and to evaluate student progress and course components. ! LASSI 3rd Edition – User’s Manual – Page \"25 !\nPART 6: THE DEVELOPMENT OF THE LASSI, 2ND EDITION !\nThe developmental work that led to the creation of the LASSI, 2nd Edition, (2002) began in 1997as part of the Cognitive Learning Strategies Project at the University of Texas at Austin. The LASSI, 2nd Edition, was developed to: !\n1. Update the LASSI and remove dated items, such as Item #72, “Often when studying I seem to get lost in details and ‘can’t see the forest for the trees’.” The expression, “… can’t see the forest for the trees,” was commonly used in the 1980’s when the LASSI was developed but is no longer familiar to many college students. !\n2. Incorporate then-current research ﬁndings in the areas of cognitive educational psychology, developmental education, higher education, instructional psychology and the psychology of learning. For example, a greater emphasis was placed on the metacognitive concepts of awareness, reﬂection and self-regulation. !\n3. Incorporate changes in educational practice and instruction in higher education. For example, the Study Aids scale was updated to reﬂect students’ use of Web sites associated with their textbooks or courses. !\n4. Broaden the scope of some of the scales to increase the degree to which they sample the underlying domains. For example, the Concentration Scale samples more broadly from the domain of academic tasks required of a college student. !\n5. Create equal numbers of items for each scale. The Selecting Main Ideas Scale on the original LASSI contained only ﬁve items. The changes made each of the ten scales contain eight items. !\n6. Improve further the psychometric properties of the LASSI. For example, the lowest Coefﬁcient Alpha for any scale on the LASSI, 2nd Edition, became .73, and all but two scales were above .80. ! LASSI 3rd Edition – User’s Manual – Page \"26 7. Create national norms based on a more broad-based sample. The sample was drawn from twelve different institutions representing different geographical regions as well as university, community college, state college and technical institutions. !\nEarly Developmental Activities !\nThe initial task in this project consisted of a series of interviews with professionals in both developmental education and educational psychology who either worked with or conducted research about students who were at-risk, or predicted to be at-risk, for academic failure or low performance in higher education settings, broadly deﬁned. The data from these interviews helped us identify criteria for the improvement of the LASSI, 1st Edition. In addition, feed-back was also solicited from educational psychometricians with expertise in diagnostic/prescriptive assessments. Finally, a review of relevant research, related textbooks, and other learning assistance materials and Web sites was conducted. !\nDevelopment of an Item Pool !\nUsing the data gathered during the early development activities, an initial item pool was created. This initial pool of 134 items consisted of 77 items drawn from the 1st edition of the LASSI and 57 items created for the 2nd edition to address the seven developmental goals listed above in the introduction to this section. This pool of items was then examined by a team of developmental educators and educational psychologists, and, as a result of their input, a number of modiﬁcations were made: the wording of some of the items was changed, several items were deleted and new items were created to replace the discarded ones. After a second review, the items were randomly sorted to create a pilot test version of the instrument. !\nPilot Testing !\nThe pilot test was administered to 2,400 entering students at a major university in the south-western part of the United States. Students’ Scholastic Aptitude Test (SAT) scores, if available, were also collected from these students in both the fall and spring semesters of 1998 and 1999. Based on an analysis of the students’ LASSI item pool data set and its psychometric properties (including item/scale characteristics) and relation to other student data such as their LASSI 3rd Edition – User’s Manual – Page \"27 SAT scores, grade-point averages, and high school rank, a number of changes were made. For example, some items were eliminated, some were modiﬁed, and work began on the development of additional items to strengthen further the scale deﬁnitions and psychometric properties. !\nA team of developmental educators, educational psychologists and educational psychometricians examined this new pool of 166 items (77 items from the LASSI, 1st Edition, 29 items from the pilot test version of the LASSI, 2nd Edition, and 60 new items written for the ﬁeld test of the LASSI, 2nd Edition). After relatively minor wording revisions, a series of pilot tests were conducted with ﬁve groups of college students to examine the item characteristics and interpretation by students. This student feedback was the ﬁnal step in preparing for the broad-based ﬁeld test and norm development. !\nField Testing and Norm Development !\nThe ﬁeld test and norming version of the LASSI, 2nd Edition, contained extra items for each scale (only 80 of the 166 items ﬁeld tested were needed for the ﬁnal instrument). The ﬁeld test/ norming version was administered to 1,092 students from twelve different institutions representing different geographical regions as well as university, community college, state college and technical institutions. See Appendix A in the LASSI, 2nd Edition, Manual for a summary of the sample size by institution breakdown, breakdowns of the sample according to age, ethnicity, gender, and GPA, as well as the breakdowns across these categories. !\nBalancing both conceptual and psychometric analyses, ten scales of eight items each were developed using those items that best represented the breadth and depth of the conception underlying each scale and that provided the strongest psychometric properties for the scale. Summaries of the item statistics for each of the LASSI, 2nd Edition, scales can be found in Appendix B, Tables 14-23 of the manual for the LASSI, 2nd Edition. Appendix C, Table 24 in that manual also presents scale statistics (mean, standard deviation and Coefﬁcient Alpha) for each of the 10 scales. Appendix D, Table 25 lists the inter-scale correlations for all scales and Appendix E, Table 26 contains a listing of the norms for the LASSI, 2nd Edition. Again, all of these tables are in the User’s Manual for the LASSI, 2nd Edition. ! LASSI 3rd Edition – User’s Manual – Page \"28 !\nPART 7: THE DEVELOPMENT OF THE LASSI, 3RD EDITION !\nSince the publication of the LASSI, 2nd Edition, in 2002, we have been gathering feedback from users, data from students, and research published on strategic and self-regulated learning theory and practice to help inform the development of the LASSI, 3rd Edition. Based on the information we gathered, analyzed, and synthesized, the LASSI, 3rd Edition, was developed to: !\n!\n1. Reduce the length and time it takes to complete the LASSI while maintaining high standards for psychometric quality. The LASSI, 2nd Edition, was 80 items in length with 8 items per scale, and it took students approximately 15-20 minutes to complete and self-score the paper-and-pencil version. The LASSI, 3rd Edition, is 60 items in length with 6 items per scale, and it takes students approximately 9-11 minutes to complete the online version. !\n2. Maintain high standards of psychometric quality. The lowest Cronbach’s alpha reliability coefﬁcient on the LASSI, 3rd Edition, is now .76 (it was .73 on the LASSI, 2nd Edition), and all but four scales are .80 or above. !\n3. Incorporate current research ﬁndings in the areas of educational psychology, developmental education, higher education, and instructional psychology as well as research published directly on the LASSI, 2nd Edition. The development of the Using Academic Resources Scale (UAR) to replace the Study Aids Scale (STA) was largely in response to changes in the research base. Over the past 14 years, there have been major developments in the study of students’ academic help-seeking that the Study Aids scale of the LASSI, 2nd Edition, did not reﬂect. In practice, students’ use of academic resources has also gained increased attention and the resources available to students have expanded and changed over time. The UAR scale was designed to reﬂect these developments in research and practice. In addition, the STA scale had the lowest reliability of the LASSI, 2nd Edition, scales. With two fewer items, the UAR scale that replaced the STA scale has a stronger Cronbach’s alpha reliability coefﬁcient (.76). We also modiﬁed the motivation scale to include an item on effort that is central to motivational constructs in contemporary research. LASSI 3rd Edition – User’s Manual – Page \"29 !\n4. Improve minor wording issues with two items. Item #9 of the LASSI, 3rd Edition, was revised from the LASSI, 2nd Edition, version of this item to use the phrase “During class discussion…” as opposed to “During class discussions…” because we found that the singular form was more commonly used among students and instructors. Item #5 of the LASSI, 3rd Edition, was revised from the LASSI, 2nd Edition, version to use present tense instead of past tense. !\n5. Create national norms based on a broad-based sample of students that reﬂects today’s postsecondary student body. Since the publication of the LASSI, 2nd Edition, the char-acteristics of students entering postsecondary education have changed to include higher percentages of nontraditionally-aged students, students of lower income, and students of underrepresented ethnic minorities. The LASSI, 3rd Edition, norms are based on a 2014 sample of 1,386 students. Students were recruited from 23 postsec-ondary institutions that had previously used the LASSI, 2nd Edition, and were asked to ﬁeld test the LASSI, 3rd Edition. We strategically selected these institutions to represent different geographic regions as well as universities, 4-year colleges, 2-year colleges, adult education programs, and public and private institutions. !\nEarly and Ongoing Developmental Activities !\nAs part of our efforts to monitor and improve the quality of the LASSI, we have been continuously gathering, analyzing, and synthesizing information relevant to the LASSI. For example, we routinely monitor the LASSI in Action, a user-driven newsletter that allows professionals to share their experiences with the LASSI assessment. We also receive feedback from LASSI users and potential users via emails and phone calls that come directly to the senior author and publisher, and through face-to-face visits during conferences and professional development workshops. To keep up with general concerns of practitioners and trends across different ﬁelds focused on student support in higher education, we also monitor a number of listservs in the areas of developmental education, learning assistance, student affairs, and higher education. Moreover, we routinely review, and contribute to, the cutting-edge research that forms the basis of strategic and self-regulated learning theory and practice as well as research published directly on the LASSI. Our ongoing efforts to listen to feedback from LASSI 3rd Edition – User’s Manual – Page \"30 LASSI users and potential users and stay current with emerging research and practice have greatly informed the changes we have made to the LASSI 3rd Edition. These changes are described in the Summary of the Changes in the LASSI, 3rd Edition, in Part 1 of this Manual and are discussed in even more detail in the previous section. !\nDevelopment of the Field Test Version of the LASSI, 3rd Edition !\nIn order to investigate approaches for reducing the length of the LASSI, 2nd Edition, while maintaining its strong psychometric properties, we analyzed a dataset of 30,005 participants who took the LASSI, 2nd Edition. These analyses helped us identify items that could be removed from each LASSI scale without compromising its psychometric quality. We also based our decisions about removing items on the content of each item. Our goal was to maintain a representative sampling of items from the construct domain and keep items that were core to the construct being measured. Based on analyses of the data and item content, we identiﬁed six items from each LASSI, 2nd Edition, scale to retain for the Field Test Version of the LASSI, 3rd Edition, with the exception of the Study Aids Scale (STA) because we planned to replace STA with a new scale. We closely examined each of these items and identiﬁed two items for minor revisions, which are described in the beginning section of Part 7. !\nBased on our review of the literature, it was clear to us that we needed to replace the STA scale with a new scale that reﬂected current conceptualizations of help-seeking and developments in learning assistance. We developed 10 items for the Using Academic Resources Scale (UAR) to examine in the Field Test Version of the LASSI, 3rd Edition. Our goal was to reduce the UAR scale to six items based on the Field Test results, which we did. !\nTo reﬂect recent developments in research on student motivation and represent a broader sampling of items from the construct domain of the Attitude (ATT) and Motivation (MOT) scales, we included three additional items on the Field Test Version of the LASSI, 3rd Edition. We included two new items for the ATT scale and one new item for the MOT scale. Of these three items, only the MOT item was used in the ﬁnal version of the LASSI, 3rd Edition. In total, the Field Test Version of the LASSI, 3rd Edition, included 67 items. Of these, 60 items were retained in the ﬁnal version of the LASSI, 3rd Edition. ! LASSI 3rd Edition – User’s Manual – Page \"31 Field Testing and Norm Development !\nThe Field Test Version of the LASSI, 3rd Edition, was administered online to 1,386 students at 23 different postsecondary institutions who were currently using the LASSI. Institutions were strategically selected to represent diverse geographic locations and types of institutions. See Appendix A, Tables 1-2 for a summary of the sample size by geographic location and institution type. See Appendix A, Tables 3-9 for a breakdown by students’ age, gender, race/ethnicity, ﬁrst time in college status, and current reason for enrolling in college courses. !\nBalancing both conceptual and psychometric analyses, 10 scales of six items each were developed using items that best represented the breadth and depth of the conception underlying each scale and that provided the strongest psychometric properties for the scale. Summaries of the item statistics for each of the LASSI, 3rd Edition, scales can be found in Appendix B, Tables 10-19. Appendix C, Table 20 presents scale statistics (mean, standard deviation, and Coefﬁcient Alpha) for each of the 10 scales. Appendix D, Table 21 lists the correlations among all scales. Appendix E, Table 22 contains a listing of the norms for the LASSI, 3rd Edition. !\n!\n! LASSI 3rd Edition – User’s Manual – Page \"32 PART 8: ADMINISTERING THE WEB LASSI !\nThis section will guide you through the process of administering the Web version of LASSI. Administering the Web LASSI !\nThe Web LASSI is administered online and requires only an Internet connection and a web browser such as Internet Explorer, Chrome, Firefox, Safari, etc. There are no special plug-ins required. Upon placing an order for the Web LASSI, you will receive an email with attached PDF instructions. Page 2 of the PDF will contain speciﬁc instructions to the student. The instructions direct the student to an introductory page similar to Figure 1. If this is the ﬁrst time taking the LASSI, enter the school number, user name, and password into the First Administration box and select the submit button to continue. If the student is returning to take a post-test, enter the school number and student key into the Second Administration box and select the “Take Post-Test” button to continue. The student key is unique for each student and is printed on the LASSI Proﬁle Report each student receives at the conclusion of the pre-test. Administrators can also view a list of student keys at the Administrative Web Site. See below for instructions on accessing the Web LASSI Administrative Account. !\n! LASSI 3rd Edition – User’s Manual – Page \"33 Figure 1 !\nFirst Administration !\nUpon entering a school number, user name, password and clicking the “Login” button, the student will be directed to a page similar to Figure 2. This page requires the student to enter a ﬁrst and last name, ID Number, and email address. The ID Number ﬁeld is optional. Click the “Continue” button to proceed. !\nNote: The ID Number ﬁeld can be set to be required. Contact your LASSI support representative to request this option for your account. !\nSecond Administration !\nIf the student enters a school number and a valid student key into the Second Administration box (Figure 1), the next screen to appear will be the post-test LASSI (Figure 3). Using the Second Administration login box will assure the student’s pre-test and post-test records are linked in the system. LASSI 3rd Edition – User’s Manual – Page \"34 Figure 2 LASSI Items !\nThe next screen to appear (Figure 3) requires the student to read each statement carefully and click one of the ﬁve responses. To help students decide what is meant by each response, a summary is shown below. !\n• By Not at all typical of me, we do not necessarily mean that the statement would never describe you, but that it would be true of you only in rare instances. • By Not very typical of me, we mean that the statement generally would not be true of you. • By Somewhat typical of me, we mean that the statement would be true of you about half of the time. • By Fairly typical of me, we mean that the statement would generally be true of you. • By Very much typical of me, we do not necessarily mean that the statement would always describe you, but that it would be true of you almost all the time. !\n!\nAlthough there is no time limit, it is estimated that it will take about 9-11 minutes to complete all items. !\n!\n!\n!\n!\n!\n! LASSI 3rd Edition – User’s Manual – Page \"35 Figure 3 LASSI Student Proﬁle After completing all the items, a report will be displayed listing percentile scores for each of the ten LASSI scales. A sample Student Proﬁle is shown in Figure 4. !\n!\n!\n! LASSI 3rd Edition – User’s Manual – Page \"36 Figure 4 !\nWeb LASSI Administrative Account !\nAdministrators of the Web LASSI can view previously administered results, download raw data, and review the status of their institution’s account by locating the URL provided on the Administrator Instruction Sheet. The Administrator Instruction Sheet is located on Page 3 of the PDF that is emailed to the administrator overseeing the Web LASSI account. Do not copy the Administrator Instruction Sheet and pass it out to your students. Some of the information on the sheet is meant only for the administrator. !\nThe following information is available to administrators through the Administrative Web Site: • The Search link allows you to search for individual students and displays a report of the following results: • Student Name, ID Number, Administration Date • Percentile rankings along with an explanation of the ten scales • A link to the student's original LASSI results • A link to a report that details how the student responded to all LASSI items • A link to a counselor/advisor report that shows a side-by-side comparison of how a student responded to all items on both the pre- and post-test LASSI (for students who have taken both pre- and post-tests) • The Student Keys link shows a list of student keys for each student who has taken the pre-test of the LASSI. A student key is required to take the post-test. • The Raw Data link allows you to download an Excel ﬁle of your school's raw data. The ﬁle includes each student's name, ID, email, student key, test date/time, ten percentile scores, ten raw scores, and item scores. • The Status link shows how many administrations your institution was issued, the date they were issued, and the number remaining to be used. !\n! LASSI 3rd Edition – User’s Manual – Page \"37 Home Page !\nThe home page of the LASSI Administrator Site is shown in Figure 5. Navigate the site us-ing the buttons at the top of the page. ! LASSI 3rd Edition – User’s Manual – Page \"38 Figure 5 Search Records !\nThe page to the right (Figure 6) appears after selecting the “Search” tab. Click “Search Records” without entering any search parameters to ﬁnd a list of all students in your account. Use the ﬁelds to reﬁne your search and return fewer records. !\n!\n!\n!\n!\n! !\n!\nFigure 7 shows the results of a search query. Both pre- and post-test results are shown in the ﬁgure. To view a Proﬁle Report or Item Responses Report, click the “View” link. A Proﬁle Report is similar to Figure 4. !\n!\n!\n!\n!\n!\n!\n! LASSI 3rd Edition – User’s Manual – Page \"39 Figure 7 Figure 6 Item Response Report !\nA sample Item Responses Report is shown in Figure 8. The Item Responses report groups the LASSI items by scale. All the items that make up the ten scales along with how the student responded to each are shown. A score of 1 is least desirable while a 5 is the most desirable. This report can be a valuable resource for counselors and academic advisors. !\n!\n!\n!\nAdvisor/Counselor Report !\nAn “Advisor/Counselor Report” is shown in Figure 9. This report displays ten percentiles, 10 raw scales scores and the percentage change in raw score from pre- to post-test. Responses for both pre- and post-test are also shown. !\n!\n!\n!\n!\n!\n!\n! LASSI 3rd Edition – User’s Manual – Page \"40 Figure 8 Figure 9 Student Keys !\nThe page to the right (Figure 10) appears after selecting the “Student Keys” button. Student Keys are unique and generated upon completion of a pre-test. Students will use a Student Key along with a School Number to take a post-test. (See Second Administration box in Figure 1). While Student Keys are included on each student’s LASSI Proﬁle Report (Figure 4), you may ﬁnd it helpful to have a list available for students who may not have their key immediately available. !\n!\n!\n!\n!\n!\n!\n! LASSI 3rd Edition – User’s Manual – Page \"41 Figure 10 Raw Data !\nThe Raw Data link allows you to download a ﬁle of your school's raw data (Figure 11). The ﬁle includes each student's name, ID, email, student key, test date/time, ten percentile scores, ten raw scores, and 60 item scores. The ﬁle can be opened with Excel, SPSS, or any other spreadsheet or data-analysis program. !\n!\n!\n! Account Status !\nThe page to the right (Figure 12) appears after selecting the “Status” button. The account status relates the number of administrations remaining in your account. When reordering, note your school number so we can add new administrations to your existing account. !\n! LASSI 3rd Edition – User’s Manual – Page \"42 Figure 11 Figure 12 Appendix A: Descriptions of the Field Test and Norming Sample (Tables 1-9) !\n!\n!\n!\nTable 1: Sample Size by Type of Institution Number of Institutions Number of Students Public Private Total Public Private Total Community College or Junior College 7 0 7 518 0 518 4-Year College 1 4 5 1 257 258 4-Year University 7 3 10 389 178 567 Adult Education Program 1 0 1 43 0 43 Grand Total 16 7 23 951 435 1386 Table 2: Sample Size by Geographic Location Number of Institutions Number of Students Urban Suburban Rural Total Urban Suburban Rural Total New England 0 1 0 1 0 34 0 34 Mid-Atlantic 0 1 1 2 0 1 48 49 East North Central 3 1 0 4 232 17 0 249 West North Central 1 0 2 3 29 0 140 169 South Atlantic 1 4 0 5 99 251 0 350 East South Central 0 2 0 2 0 201 0 201 West South Central 1 0 0 1 99 0 0 99 Mountain 1 0 1 2 20 0 52 72 Paciﬁc 2 0 0 2 127 0 0 127 Nova Scotia, Canada 0 1 0 1 0 36 0 36 Grand Total 9 10 4 23 606 540 240 1386 LASSI 3rd Edition – User’s Manual – Page \"43 !\n!\n!\n!\n!\n!\nTable 3: Race/Ethnicity"
      },
      {
        "type": "text",
        "text": "\n\n[OUTPUT TRUNCATED - exceeded 25000 token limit]\n\nThe tool output was truncated. If this MCP server provides pagination or filtering tools, use them to retrieve specific portions of the data. If pagination is not available, inform the user that you are working with truncated output and results may be incomplete."
      }
    ]
  }
]

---

### User
> 11/30/2025, 3:48:27 PM

[
  {
    "tool_use_id": "toolu_01T9GBDo7SpdF7XzAaJCy2Zz",
    "type": "tool_result",
    "content": [
      {
        "type": "text",
        "text": "Detailed Results:\n\nTitle: [PDF] Psychometric Features of Motivated Strategies for Learning ...\nURL: https://www.researchgate.net/profile/Salima-Ali-8/publication/366603906_Psychometric_Features_of_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_Among_the_Students_of_Higher_Education_Sector_in_Karachi_-Pakistan/links/66cd6cfac2eaa500231aee21/Psychometric-Features-of-Motivated-Strategies-for-Learning-Questionnaire-MSLQ-Among-the-Students-of-Higher-Education-Sector-in-Karachi-Pakistan.pdf\nContent: The Motivated Strategies for Learning Questionnaire (MSLQ) is a self-report tool designed to measure learners' motivational orientations and their usage of\n\nTitle: (PDF) Revised Motivated Strategies for Learning Questionnaire for ...\nURL: https://www.academia.edu/26599439/Revised_Motivated_Strategies_for_Learning_Questionnaire_for_Secondary_School_Students\nContent: THE TURKISH ADAPTATION STUDY OF MOTIVATED STRATEGIES FOR LEARNING QUESTIONNAIRE (MSLQ) FOR 12-18 YEAR OLD CHILDREN: RESULTS OF CONFIRMATORY FACTOR ANALYSIS 1 The Turkish adaptation study of Motivated Strategies for Learning Questionnaire (MSLQ) for 12-18 year old children: Results of confirmatory factor analysis. The Motivated Strategies for Learning Questionnaire (MSLQ) is a widely used self-report instrument to measure student motivation and learning strategies at the course-specific level (i.e., an individual course or subject domain). An Adaptation of the Motivated Strategies for Learning Questionnaire (MSLQ) for Postgraduate Students in Pakistan: Results of an Exploratory Factor Analysis This paper presents the results of an exploratory factor analysis of the motivation scales of Motivated Strategies for Learning Questionnaire (MSLQ).\nRaw Content: Academia.edu uses cookies to personalize content, tailor ads and improve the user experience. By using our site, you agree to our collection of information through the use of cookies. To learn more, view our [Privacy Policy.](https://www.academia.edu/privacy)\n\nAcademia.edu no longer supports Internet Explorer.\n\nTo browse Academia.edu and the wider internet faster and more securely, please take a few seconds to [upgrade your browser](https://www.academia.edu/upgrade-browser).\n\n* [Log In](https://www.academia.edu/login)\n* [Sign Up](https://www.academia.edu/signup)\n* + [About](https://www.academia.edu/about)\n  + [Press](https://www.academia.edu/press)\n  + [Papers](https://www.academia.edu/documents)\n  + [Terms](https://www.academia.edu/terms)\n  + [Privacy](https://www.academia.edu/privacy)\n  + [Copyright](https://www.academia.edu/copyright)\n  + [We're Hiring!](https://www.academia.edu/hiring)\n  + [Help Center](https://support.academia.edu/hc/en-us)\n\n[Key Takeaways](#key-takeaways)\n\n[Data Analysis](#outer_page_4)\n\n# Revised Motivated Strategies for Learning Questionnaire for Secondary School Students\n\n[Woon Chia LIU](https://nie-sg.academia.edu/WoonChiaLIU)\n\nvisibility\n\n4423 views\n\ndescription\n\n14 pages\n\n#### Sign up for access to the world's latest research\n\ncheckGet notified about relevant papers\n\ncheckSave papers to use in your research\n\ncheckJoin the discussion with peers\n\ncheckTrack your impact\n\n## Abstract\n\nThe purpose of the current study was to examine the psychometric properties of the MSLQ for junior high school students. The MSLQ for junior high students is a 44 item self-reported instrument consisting of three motivational beliefs subscales, one Cognitive Strategy subscale and one Self-regulation subscale. A total of 780 students from eight secondary schools in Singapore completed the MSLQ. In the first sample, there were 393 students who completed the junior high school version of the MSLQ. A second sample of 387 students completed the modified MSLQ. This study showed that the original junior high school version of the MSLQ measurement model needed to be revised. The modified MSLQ measurement model was confirmed via CFA with a second sample with two other competing models. Convergent and discriminant validity was supported. Multigroup analysis demonstrated invariance of the factor forms, factor loadings, factor variances and covariances, and error variances across gender. In sum...\n\n## Key takeaways AI\n\n1. The modified Motivated Strategies for Learning Questionnaire (MSLQ) contains 28 items across five factors.\n2. CFA confirmed the MSLQ's five-factor structure, demonstrating good fit indices (e.g., CFI = .939, RMSEA = .042).\n3. Convergent validity was established, though anxiety and lack of self-regulation subscales had AVE slightly below .50.\n4. The study included 780 junior high students, with 393 in the first sample and 387 in the modified version.\n5. The MSLQ shows measurement invariance across genders, supporting its applicability in diverse educational settings.\n\n## Related papers\n\n[Validation of Motivated Strategies for Learning Questionnaire: Comparison of Three Competing Models](https://www.academia.edu/73391229/Validation_of_Motivated_Strategies_for_Learning_Questionnaire_Comparison_of_Three_Competing_Models)\n\n[Buratin Khampirat](https://independent.academia.edu/BuratinKhampirat)\n\nInternational Journal of Instruction\n\nStudents who are self-regulated leaners have been reported to perform more successfully in higher education institutions (HEIs). Therefore, instruments that can monitor students' motivation and learning have been devised and implemented. The aims of this work were to investigate the dimensionality of the motivated strategies for learning questionnaire (MSLQ) and compare the validation of the three competing models. Three competing measurement models (1-factor, 2-factor, and second-order factor) were selected as candidates. To reveal which model explained the original MSLQ most effectively and meaningfully, the original 15 indicators and 81 items were used, for which data was gathered from 945 participating engineering students in Thailand. The results of confirmatory factor analysis revealed that all three of the competing models fitted the data quite well, as all standardized factor loadings of these models were statistically significant. It appeared that two-factor and second-order factor models yielded a better overall fit to the data in comparison to one-factor model. These results confirmed that the original MSLQ is a reliable and valid measurement instrument, particularly the second-order factor model, which was the best model.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/73391229/Validation_of_Motivated_Strategies_for_Learning_Questionnaire_Comparison_of_Three_Competing_Models)\n\n[THE TURKISH ADAPTATION STUDY OF MOTIVATED STRATEGIES FOR LEARNING QUESTIONNAIRE (MSLQ) FOR 12-18 YEAR OLD CHILDREN: RESULTS OF CONFIRMATORY FACTOR ANALYSIS 1](https://www.academia.edu/4681122/THE_TURKISH_ADAPTATION_STUDY_OF_MOTIVATED_STRATEGIES_FOR_LEARNING_QUESTIONNAIRE_MSLQ_FOR_12_18_YEAR_OLD_CHILDREN_RESULTS_OF_CONFIRMATORY_FACTOR_ANALYSIS_1)\n\n[Funda ÇAKMAK](https://ogu.academia.edu/Funda%C3%87AKMAK)\n\n2008\n\nThis study gives results of the first phase of the 12-18 year old Turkish students' norm study of The Motivated Strategies for Learning Questionnaire (MSLQ), which deveoped by Pintrich, Smith, . The scale was administrated to 1114 students from 3 primary schools and 3 high schools in Ankara in Turkish language, science, mathematics and social science courses. After eliminating the questionnaires which have missing and extreme values, the analyses were done on 762 valid questionnaires for motivation subscale and 1100 valid questionnaires for learning strategies subscale. Results of the confirmatory factor analyses show that the first subscale, Motivation, has six factors, and the second subscale, Learning Strategies, has nine factors according to original scale's factor structures. Depending on the results of the confirmatory factor analysis; 6 items from motivation subscale and 5 items from learning strategies subscale were removed due to their low factor loadings. The corrected item total correlations ranged 0.58 to 0.15 for motivation subscale, and 0.68 to 0.19 for learning strategies subscale.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/4681122/THE_TURKISH_ADAPTATION_STUDY_OF_MOTIVATED_STRATEGIES_FOR_LEARNING_QUESTIONNAIRE_MSLQ_FOR_12_18_YEAR_OLD_CHILDREN_RESULTS_OF_CONFIRMATORY_FACTOR_ANALYSIS_1)\n\n[[Motivated Strategies for Learning Questionnaire: MSLQ] The intricate relationship between motivation and achievement: Examining the mediating role of self-regulated learning and achievement-related classroom behaviors](https://www.academia.edu/1828646/_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_The_intricate_relationship_between_motivation_and_achievement_Examining_the_mediating_role_of_self_regulated_learning_and_achievement_related_classroom_behaviors) \n\n[Henk Schmidt](https://eur.academia.edu/HenkSchmidt), [Jerome I Rotgans](https://erasmusmc.academia.edu/JeromeRotgans)\n\nInternational Journal for Teaching and Learning in Higher Education\n\nThe objective of the present study was to examine how motivation is related to academic achievement. The Motivated Strategies for Learning Questionnaire was administered to 1,166 students at a polytechnic in Singapore as a measure for motivational beliefs and self-regulated learning strategies. In addition, students’ prior knowledge, achievement-related classroom behaviors and academic achievement were included in the analysis. Path analysis revealed that motivation is not directly related to achievement. Instead, the relationship was mediated by both learning strategies and achievement-related classroom behaviors. Prior achievement was a good predictor of subsequent achievement but had no influence on student motivation. Overall the results suggest that motivation as operationalized by self-report seems to be a construct with limited predictive validity for academic achievement.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/1828646/_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_The_intricate_relationship_between_motivation_and_achievement_Examining_the_mediating_role_of_self_regulated_learning_and_achievement_related_classroom_behaviors)\n\n[A Manual for the Use of the Motivated Strategies for Learning Questionnaire (MSLQ)](https://www.academia.edu/24744254/A_Manual_for_the_Use_of_the_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_)\n\n[Wilbert McKeachie](https://independent.academia.edu/WilbertMcKeachie)\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/24744254/A_Manual_for_the_Use_of_the_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_)\n\n[Construct Validity of the Motivated Strategies for Learning Questionnaire](https://www.academia.edu/34318797/Construct_Validity_of_the_Motivated_Strategies_for_Learning_Questionnaire)\n\n[Selina Akhter](https://independent.academia.edu/SelinaAkhter1)\n\nPsychological Reports, 2009\n\nthis study examined the construct validity of the motivational component of the motivated Strategies for learning Questionnaire using both exploratory factor analysis (eFa) and confirmatory factor analysis (cFa). 327 students enrolled in Bachelor of education and Graduate diploma education courses at the University of auckland participated in this study (278 women, 49 men). the results of the eFa did not generate support for either a six-factor or three-factor model. the cFa tested a six-factor correlated original model and a respecified model and found a good fit for the respecified model and a better fit of the original 31-item model in comparison with previous studies. in addition, alternative second-order and hierarchical models were tested, none of which showed better fit than the sixfactor correlated models. the reasons for the lack of fit of the original model are discussed in light of nonnormality condition, specification error, and latent variables. Finally, possible explanations for the slight variation in patterns of subscale correlations are discussed.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/34318797/Construct_Validity_of_the_Motivated_Strategies_for_Learning_Questionnaire)\n\n[The Making of the Motivated Strategies for Learning Questionnaire](https://www.academia.edu/24744194/The_Making_of_the_Motivated_Strategies_for_Learning_Questionnaire)\n\n[Wilbert McKeachie](https://independent.academia.edu/WilbertMcKeachie)\n\nEducational Psychologist, 2005\n\nThe goal of this article is to discuss one of Paul Pintrich's more enduring legacies: the Motivated Strategies for Learning Questionnaire (MSLQ), an 81-item, self-report instrument consisting of 6 motivation subscales and 9 learning strategies scales. The MSLQ has proven to be a reliable and useful tool that can be adapted for a number of different purposes for researchers, instructors, and students. The MSLQ has been translated into multiple languages and has been used by hundreds of researchers and instructors throughout the world. This article reviews the history of the MSLQ and discusses how it has been used to (a) address the nature of motivation and use of learning strategies in different types of content areas and target populations; (b) help refine our theoretical understanding of motivational constructs, how they are distinct from one another, and what individual differences exist in self-regulated learning; and (c) evaluate the motivational and cognitive effects of different aspects of instruction.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/24744194/The_Making_of_the_Motivated_Strategies_for_Learning_Questionnaire)\n\n[A Manual for the Use of the Motivated Strategies for Learning Questionnaire (MSLQ) Motivated Strategies for Learning Questionnaire Manual](https://www.academia.edu/29450717/A_Manual_for_the_Use_of_the_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_Motivated_Strategies_for_Learning_Questionnaire_Manual)\n\n[雯蔚 谭](https://independent.academia.edu/%E9%9B%AF%E8%94%9A%E8%B0%AD)\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/29450717/A_Manual_for_the_Use_of_the_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_Motivated_Strategies_for_Learning_Questionnaire_Manual)\n\n[The Effects of Motivated Strategies for Learning Questionnaire (MSLQ) on Students’ Cognitive and Meta-Cognitive Skills](https://www.academia.edu/104718033/The_Effects_of_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_on_Students_Cognitive_and_Meta_Cognitive_Skills)\n\n[Ahmad Khamesan](https://independent.academia.edu/AhmadKhamesan)\n\nNeuroQuantology, 2017\n\nThe aim of the present research is to identify the effect of teaching motivated strategies for learning on students' cognitive and metacognitive skills. This research is a semi-experimental study with pre-test and post-test procedures. 46 students who obtained less than 162.5 scores in motivated strategies for learning questionnaire (MSLQ) are selected in statistically matched experimental and monitored groups of the study (each groups constitute of 23 students). The experimental group is administered in eight 100 minutes long sessions under the motivated strategies of learning protocol (MSL). This protocol is the adaptation of a theoretical background, utilized in previous studies. The results of the study indicate that after utilization of MSL, students' cognitive and meta-cognitive skills are enhanced. Therefore, MSLQ is propounded as a learning facilitator.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/104718033/The_Effects_of_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_on_Students_Cognitive_and_Meta_Cognitive_Skills)\n\n[[Motivated Strategies for Learning Questionnaire: MSLQ] Examination of the context-specific nature of self-regulated learning](https://www.academia.edu/481748/_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_Examination_of_the_context_specific_nature_of_self_regulated_learning)\n\n[Henk Schmidt](https://eur.academia.edu/HenkSchmidt), [Jerome I Rotgans](https://erasmusmc.academia.edu/JeromeRotgans)\n\nEducational Studies, 2009\n\nThe purpose of the present study was to investigate to what extent self-regulated learning (SRL) is context-dependent. The Motivated Strategies for Learning Questionnaire (MSLQ) was repeatedly administered to 155 first-year students at a Singaporean polytechnic – a general version of the MSLQ before students entered the polytechnic and a course-specific version at the end of the first semester for mathematics, science and English courses. Data were analysed using structural equation modelling. The analyses included: (1) tests for invariance of factorial structures, (2) tests for invariance among latent means, and (3) a comparison of the predictive validity of the general and the course-specific versions of the MSLQ. The results showed that no significant differences could be found in the underlying structure of SRL between subject domains. In addition, average subscale responses were rather invariant across domains. Finally, course- specific measures of SRL were generally not more accurate in predicting academic achievements than the general version. These findings taken together do not support the notion that SRL is context-dependent. Rather, SRL as measured by the MSLQ appears to be a stable disposition of the learner.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/481748/_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_Examination_of_the_context_specific_nature_of_self_regulated_learning)\n\n[Learning Strategies Dimension of the MSLQ Questionnaire: A tool for researchers around the globe](https://www.academia.edu/142924615/Learning_Strategies_Dimension_of_the_MSLQ_Questionnaire_A_tool_for_researchers_around_the_globe)\n\n[Muhammad Kamran](https://universityofgujrat.academia.edu/MuhammadKamranKundi)\n\nInternational Research Journal of Multidisciplinary Scope, 2025\n\nThe Motivated Strategies for Learning Questionnaire (MSLQ) is the most vigorous scale that assesses self-regulated learning (SRL) strategies. The MSLQ is a detailed scale of 81 items with two major dimensions (i.e., the Motivation Dimension (MD) and the Learning Strategies (LS). Each major dimension has again sub-scales. However, its validation is a topic of debate for research experts. Previous researchers determined insufficient evidence to support the 81item version of the MSLQ theoretical framework. The present research aims to revalidate the brief version of the LS dimension within a distinct Pakistani university student setting (N = 811). The researchers also sought to understand how demographics affect different motivational strategies. This process aimed to derive a condensed version of the LS dimension, intending to dissuade researchers from employing the more extended version in Pakistan. In this study, researchers replicated the previous studies to conduct exploratory factor analysis (EFA) and confirmatory factor analysis (CFA) on the LS Dimension of the brief version of MSLQ using SPSS 27 and AMOS 20. The results indicate that the brief scale version aligns effectively with the model's five factors (elaboration, rehearsal, critical thinking, organization, and peer learning), affirming its suitability for use in this novel context. The results also indicate that there were no significant differences between male and female students from different regions and public or private universities in terms of employing strategies. However, it was found that research students use cognitive LS, like thinking critically and elaborating, more than other factors.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/142924615/Learning_Strategies_Dimension_of_the_MSLQ_Questionnaire_A_tool_for_researchers_around_the_globe)\n\nLoading Preview\n\nSorry, preview is currently unavailable. You can download the paper by clicking the button above.\n\n## References (25)\n\n1. Asparohov, T., & Muthén, B. (2009). Exploratory structural equation modeling. Structural Equation Modeling, 16, 397-438.\n2. Bagozzi, R. P. (1981). An examination of the validity of two models of attitude. Multivariate Behavioral Research, 16, 323-359.\n3. Bagozzi, R. P., & Yi, Y. (1988). Assessing method variance in multitrait- multimethod matrices: The case of self-reported affect and perceptions at work. Journal of Applied Psychology, 75, 547-560.\n4. Byrne, B. M. (1994). Structural equation modeling with EQS and EQS/Windows: Basic concepts, applications and programming. Newbury Park, CA: Sage.\n5. Cheung, G. W., & Rensvold, R. B. (2002). Evaluating goodness-of-fit indexes for testing measurement invariance. Structural Equation Modeling, 9, 233- 255.\n6. Cook, D. A., Thompson, W. G., & Thomas, K. G. (2011). The Motivated Strategies for Learning Questionnaire: Score validity among medicine residents. Medical Education, 45(12), 1230-1240.\n7. Credé, M., & Phillips, L. A. (2011). A meta-analytic review of the Motivated Strategies for Learning Questionnaire. Learning and Individual Differences, 21, 337-346.\n8. Davenport, M. A. (2003). Modeling motivation and learning strategy use in the classroom: An assessment of the factorial, structural, and predictive validity of the motivated strategies for learning questionnaire. Dissertation Abstracts International, 64(2-A), 394.\n9. Dillion, W. R., & Goldstein, M. (1984). Multivariate analysis: Methods and applications. New York: Wiley.\n10. Duncan, T. G., & McKeachie, W. J. (2005). The making of the Motivated Strategies for Learning Questionnaire. Educational Psychologist, 40, 117- 128.\n11. Dunn, K. E., Lo, W. J., Mulvenon, S. W., & Sutcliffe, R. (2011). Revisiting the Motivated Strategies for Learning Questionnaire: A theoretical and statistical reevaluation of the metacognitive self-regulation and effort regulation subscales. Educational and Psychological Measurement, Published online before print, doi: 10.1177/0013164411413461\n12. Fornell, C., & Larcker, D. (1981). Evaluating structural equation models with unobservable variables and measurement error. Journal of Marketing Research, 18, 39-50.\n13. Karadeniz, S., Büyüköztürk, S., Akgün, Ö, E., Cakmak, E. K., & Demirel, F. (2008). The Turkish adaptation study of Motivated Strategies for Learning Questionnaire (MSLQ) for 12-18 year old children: Results of confirmatory factor analysis. The Turkish Online Journal of Educational Technology, TOJET, 7(4), 108-117.\n14. Li, F., Harmer, P., Chi, L., & Vongjaturapat, N. (1996). Cross-cultural validation of the Task and Ego Orientation in Sport Questionnaire. Journal of Sport and Exercise Psychology, 18, 392-407.\n15. Marsh, H. W. (2007). Application of confirmatory factor analysis and structural equation modeling in sport/exercise psychology. In G. Tenenbaum & R. C. Eklund (Eds.), Handbook on sport psychology (3rd ed., pp. 774-798). New York: Wiley.\n16. Marsh, H. W., Muthén, B., Asparouhov, T., Lüdtke, O., Robitzsch, A., Morin, A. J. S., & Trautwein, U. (2009). Exploratory structural equation modeling, integrating CFA and EFA: Application to students' evaluations of university teaching. Structural Equation Modeling, 16, 439-476.\n17. Pintrich, P. R. (1988). A process-oriented view of student motivation and cognition. In J.S. Stark & L. Mets (Eds.), Improving teaching and learning through research. New directions for institutional research, (pp. 55-70). San Francisco: Jossey-Bass.\n18. Pintrich, P. R. (1989). The dynamic interplay of student motivation and cognition in the college classroom. In C. Ames & M. Maehr (Eds.), Advances in motivation and achievement: Vol. 6. Motivation enhancing environments (pp. 117-160). Greenwich, CT: JAI Press.\n19. Pintrich, P.R. (1999). The role of motivation in promoting and sustaining self- regulated learning. International Journal of Educational Research, 31, 459-470.\n20. Pintrich, P. R., & De Groot, E. (1990). Motivational and self-regulated learning components of classroom academic performance. Journal of Educational Psychology, 82, 33-40.\n21. Pintrich, P. R., Cross, D. R., Kozma, R. B., & McKeachie, W. J. (1986). Instructional psychology. Annual Review of Psychology, 37, 611-651.\n22. Pintrich, P. R., Smith, D. A. F., Garcia, T., & McKeachie, W. J. (1991). A manual for the use of the Motivated Strategies for Learning Questionnaire (MSLQ). Ann Arbor: University of Michigan, National Center for Research to Improve Postsecondary Teaching and Learning.\n23. Pintrich, P. R., Smith, D. A. F., Garcia, T., & McKeachie, W. J. (1993). Reliability and predictive validity of the Motivated Strategies for Learning Questionnaire (MSLQ). Educational and Psychological Measurement, 53, 801-813.\n24. Rao, N., & Sachs, J. (1999). Confirmatory factor analysis of the Chinese version of the Motivated Strategies for Learning Questionnaire. Educational and Psychological Measurement, 59, 1016-1029.\n25. Rotgans, J. I., & Schmidt, H. G. (2010). The Motivated Strategies for Learning\n\n## FAQs\n\nAI\n\nWhat psychometric properties were analyzed for the MSLQ's junior high school version?add\n\nThe study evaluated the validity and reliability, finding a five-factor model with acceptable internal consistency (α > .70). The modified version yielded an average variance extracted close to .50, supporting convergent validity.\n\nHow did the factor analysis modify the original MSLQ structure?add\n\nInitial exploratory factor analysis identified 16 poorly loading items, reducing the modified MSLQ to 28 items with five clear factors. This approach improved psychometric soundness compared to the original 44-item structure.\n\nWhat are the five factors identified in the modified MSLQ?add\n\nThe modified MSLQ includes intrinsic value, self-efficacy, anxiety, learning strategies, and lack of self-regulation. Notably, learning strategies integrate cognitive strategies with self-regulation methodologies.\n\nHow does gender invariance affect the MSLQ's measurement model?add\n\nThe study confirms gender invariance in the MSLQ measurement model, indicating consistent factor structures across genders. Both male and female students responded similarly to the modified questionnaire.\n\nWhy is the validation of the MSLQ critical for educational research?add\n\nValidating the MSLQ is crucial as it ensures reliable interpretations of student motivation and learning strategies across diverse populations. Accurate measures can significantly impact educational intervention designs and teaching methodologies.\n\n## Related papers\n\n[Construct Validation of the Motivated Strategies for Learning Questionnaire in a Singapore High School Sample](https://www.academia.edu/106642757/Construct_Validation_of_the_Motivated_Strategies_for_Learning_Questionnaire_in_a_Singapore_High_School_Sample)\n\n[Elaine Chapman](https://independent.academia.edu/ChapmanElaine)\n\nJournal of Educational and Developmental Psychology, 2017\n\nIn this study, the construct validity of the Motivated Strategies for Learning Questionnaire (MSLQ) was assessed. Participants were 441 Year 11 students in Singapore. Three separate confirmatory factor analyses were conducted for each section of the MSLQ (motivation and learning strategies). Results indicated that the original factor structures proposed by the instrument developers produced the best model fit. Cronbach α coefficients were also acceptable for all but one of the individual scales. Correlations with the Revised Learning Process Questionnaire—Two Factor and physics achievement scores also aligned with the theoretical basis of the MSLQ. These results confirmed the potential utility of this instrument for assessing the motivation and learning strategies of secondary students in Singapore.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/106642757/Construct_Validation_of_the_Motivated_Strategies_for_Learning_Questionnaire_in_a_Singapore_High_School_Sample)\n\n[The Motivated Strategies for Learning Questionnaire: A Measure for Students' General Motivational Beliefs and Learning Strategies?](https://www.academia.edu/481750/The_Motivated_Strategies_for_Learning_Questionnaire_A_Measure_for_Students_General_Motivational_Beliefs_and_Learning_Strategies)\n\n[Henk Schmidt](https://eur.academia.edu/HenkSchmidt), [Jerome I Rotgans](https://erasmusmc.academia.edu/JeromeRotgans)\n\nThe Asia-Pacific Education Researcher, 2010\n\nThe Motivated Strategies for Learning Questionnaire (MSLQ) is a widely used self-report instrument to measure student motivation and learning strategies at the course-specific level (i.e., an individual course or subject domain). The present study sought to explore the utility of the MSLQ in measuring student motivation and learning strategies pertaining to the general curriculum level (i.e., all courses and subjects taken together) rather than to the course-specific level. To that end, the instrument was slightly modified and administered to recently graduated secondary school students (N = 1,166) in Singapore. The construct and predictive validity of the instrument were determined using confirmatory factor analysis and by correlating the individual subscales of the instrument with the overall semester grades. Results showed that the modified MSLQ is a reliable and valid instrument to determine students’ motivational beliefs and learning strategies at the general curriculum level.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/481750/The_Motivated_Strategies_for_Learning_Questionnaire_A_Measure_for_Students_General_Motivational_Beliefs_and_Learning_Strategies)\n\n[Validity And Reliability Of The MSLQ Malay Version In Measuring The Level Of Motivation And Self-Regulated Learning](https://www.academia.edu/67451810/Validity_And_Reliability_Of_The_MSLQ_Malay_Version_In_Measuring_The_Level_Of_Motivation_And_Self_Regulated_Learning)\n\n[fakhruddin khosim](https://independent.academia.edu/fakhruddinkhosim)\n\nInternational Journal of Scientific & Technology Research, 2020\n\nMotivated Strategies for Learning Questionnaire [1] is a survey instrument that measures the dimensions of motivation and self-regulated learning. This research is conducted to determine the validity and reliability of the MSLQ-Bahasa Melayu version. The study sample consists of 395 Form Two Orang Asli students in the state of Perak, Malaysia. The statistics used is the Cronbach’s Alpha reliability analysis and the results of factor analysis are to confirm the factors that exist in the survey. The study findings for Cronbach’s Alpha reliability for all constructs are almost the same with that reported in the original version. Meanwhile, for the factor analysis, three factors were successfully extracted into the motivation dimension, while for the self-regulated learning dimension, only one factor was successfully extracted as compared to two factors in the original version. In conclusion, MSLQ-BM is an instrument that has high validity and reliability in measuring motivation and sel...\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/67451810/Validity_And_Reliability_Of_The_MSLQ_Malay_Version_In_Measuring_The_Level_Of_Motivation_And_Self_Regulated_Learning)\n\n[An Analysis of the Relationship Between the Motivated Strategies for Learning Questionnaire and the Learning Process Questionnaire](https://www.academia.edu/60943874/An_Analysis_of_the_Relationship_Between_the_Motivated_Strategies_for_Learning_Questionnaire_and_the_Learning_Process_Questionnaire)\n\n[Carol Chan](https://independent.academia.edu/CarolChan11)\n\nPSYCHOLOGIA -An International Journal of Psychology in the Orient, 2002\n\nThe relationship between the scales of the Motivated Strategies for Learning Questionnaire (MSLQ) and Learning Process Questionnaire (LPQ) was examined using an integrated data approach (Skinner, 1977, 1978) that combined features of multiple regression analysis, canonical correlation, and multiple-set factor analysis. Results based on a Hong Kong sample of upper primary and lower secondary students generally agreed with expectations of how the scales in these two instruments would be associated. The LPQ surface scale paired with the MSLQ test anxiety scale, while the LPQ deep scale paired with the MSLQ intrinsic value scale and the LPQ achieving scale paired with the self-efficacy scale. However, contrary to expectations, the MSLQ cognitive strategy-use scale paired with the LPQ deep scale, while the MSLQ self-regulation scale paired with the LPQ achieving scale. It is suggested that the MSLQ self-regulation scale is a measure of efficient study strategies characteristically used by achieving oriented students. In contrast, it is argued that students adopting a deep approach to learning need the requisite cognitive skills for this approach to be self-motivating.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/60943874/An_Analysis_of_the_Relationship_Between_the_Motivated_Strategies_for_Learning_Questionnaire_and_the_Learning_Process_Questionnaire)\n\n[Validation of the factor structure of the motivated strategies for learning questionnaire](https://www.academia.edu/128713638/Validation_of_the_factor_structure_of_the_motivated_strategies_for_learning_questionnaire)\n\n[International Journal of Evaluation and Research in Education (IJERE)](https://independent.academia.edu/NikoSaputra68)\n\nInternational Journal of Evaluation and Research in Education (IJERE), 2024\n\nIn recent years, the motivated strategies for learning questionnaire (MSLQ) has been used to assess students' motivational orientations and utilization of various learning strategies. Due to its significant effects on student outcomes such as academic performance and careers, research on the factor structure of motivated strategies for learning has received increasing attention. However, the existing literature indicates a dearth of studies focusing on the MSLQ dimensions in Vietnam. Therefore, this study aimed to ascertain the factor structure of the 31-item Student Motivation Scale (SMS), which is a subset of the larger 81-item MSLQ, in the context of Vietnam. The study utilized the Vietnamese version of the SMS to collect data from 317 high school students in Vietnam. The factorial analysis showed that the SMS has its original six-factor structure, which is made up of task value (TV), control beliefs, self-efficacy for learning and performance (SLP), test anxiety (TA), and intrinsic goal orientation (IGO). The present study recommended that school leaders and teachers should use the SMS to assess students' motivation in the context of Vietnamese education.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/128713638/Validation_of_the_factor_structure_of_the_motivated_strategies_for_learning_questionnaire)\n\n[A Validity and Reliability Study of the Motivated Strategies for Learning Questionnaire](https://www.academia.edu/7655143/A_Validity_and_Reliability_Study_of_the_Motivated_Strategies_for_Learning_Questionnaire)\n\n[Gokce Erturan](https://pamukkale.academia.edu/gokceerturanilker)\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/7655143/A_Validity_and_Reliability_Study_of_the_Motivated_Strategies_for_Learning_Questionnaire)\n\n[Adaptation and analysis of motivated strategies for learning questionnaire in the Chinese setting](https://www.academia.edu/9021885/Adaptation_and_analysis_of_motivated_strategies_for_learning_questionnaire_in_the_Chinese_setting)\n\n[Hongbiao Yin](https://cuhk.academia.edu/Yin)\n\n2010\n\nThis article reports the adaptation and analysis of Pintrich's Motivated Strategies for Learning Questionnaire (MSLQ) in Hong Kong. First, this study examined the psychometric qualities of the existing Chinese version of MSLQ (MSLQ-CV). Based on this examination, this study developed a revised Chinese version of MSLQ (MSLQ-RCV) for junior secondary students in Hong Kong. Confirmatory factor analysis and Graded Response Model (GRM) were used to examine the internal consistency, construct validity, differential item functioning (DIF), and differential test functioning (DTF) of the revised instrument, which contains six factors and 50 items. Compared with the existing MSLQ-CV, the factor structure of MSLQ-RCV was expanded to incorporate two new factors: extrinsic value and peer learning. The reasons for these amendments and implications of the findings are discussed.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/9021885/Adaptation_and_analysis_of_motivated_strategies_for_learning_questionnaire_in_the_Chinese_setting)\n\n[Validity of the motivated strategies for learning questionnaire in Saudi Arabia](https://www.academia.edu/53882885/Validity_of_the_motivated_strategies_for_learning_questionnaire_in_Saudi_Arabia)\n\n[Amira Farghaly](https://scuegypt.academia.edu/AmiraFarghaly)\n\nInternational Journal of Medical Education\n\nObjectives: To assess the construct validity and reliability of the motivation section of the Motivated Strategies for Learning Questionnaire in Saudi Arabia. Methods: A cross-sectional study using the Motivated Strategies for Learning Questionnaire (MSLQ) was conducted. The MSQL has essentially two sections: a motivation section and a learning strategies section. The motivation section, which consists of 31 items, was used. A total of 146 medical students who were all male completed the questionnaire. Confirmatory factor analysis was used to test the hypothesised factor structure, and to identify the validity and reliability of the motivation section of the MSQL. Results: A selected group of fit statistics showed that the hypothesised model did not fit the sample data fairly well. The Intrinsic Goal Orientation subscale consisted of 4 items (α = 0.75), the Extrinsic Goal Orientation subscale consisted of 4 items (α = 0.78), the Task Value subscale consisted of 6 items (α =0.86), the Control of Learning Beliefs consisted of 4 items (α =0.78), the Self-Efficacy for Learning and Performance consisted of 8 items (α =0.89), and the Test Anxiety consisted of 5 items (α =0.77). Conclusions: It is concluded that the hypothesised model did not fit the data well. This may suggest that the motivation section of the MSQL may not work for Saudi Arabian students. However, this could be due to the fact that the sample data available on this study did not represent female students. Further work is required to establish this. Limitations of the study are discussed.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/53882885/Validity_of_the_motivated_strategies_for_learning_questionnaire_in_Saudi_Arabia)\n\n[An Adaptation of the Motivated Strategies for Learning Questionnaire (MSLQ) for Postgraduate Students in Pakistan: Results of an Exploratory Factor Analysis](https://www.academia.edu/92881204/An_Adaptation_of_the_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_for_Postgraduate_Students_in_Pakistan_Results_of_an_Exploratory_Factor_Analysis)\n\n[Dr. Munaza Nausheen](https://independent.academia.edu/DrMunazaNausheen)\n\nThis paper presents the results of an exploratory factor analysis of the motivation scales of Motivated Strategies for Learning Questionnaire (MSLQ). This analysis was a part of my PhD research on motivational beliefs, course experiences and future plans of the postgraduate students in Pakistan. An exploratory factor analysis of motivational subscales was used to examine the factor structure and internal reliability of these scales with a sample of 368 postgraduate students in the context of Pakistan. The results of the study showed that the factor structure of the six motivation scales of the MSLQ was significantly modified with the current sample of postgraduate students in Pakistan. These results indicated that there was a need for further development and careful adaptation of MSLQ for use in other eastern contexts in general and in the context of Pakistani higher education in particular.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/92881204/An_Adaptation_of_the_Motivated_Strategies_for_Learning_Questionnaire_MSLQ_for_Postgraduate_Students_in_Pakistan_Results_of_an_Exploratory_Factor_Analysis)\n\n[A Confirmatory Factor Analysis of Motivated Self-regulated Learning Questionnaire in an EFL Context](https://www.academia.edu/15105244/A_Confirmatory_Factor_Analysis_of_Motivated_Self_regulated_Learning_Questionnaire_in_an_EFL_Context)\n\n[Mohammad ali ayatollahi](https://independent.academia.edu/Mohammadaliayatollahi)\n\nInternational Education Studies, 2011\n\nThe Motivated Strategies for Learning Questionnaire (MSLQ) is an instrument for measuring motivation and learning strategies in general education. This instrument is modular, consisting of motivation and learning strategies modules. This study sought to see whether the learning strategies module of this instrument can be applied to the context of English Language Learning (EFL). For this purpose, the instrument was administered to a group of Iranian EFL college students (n=190) as well as a group of Iranian computer science students (n=74). The validity of the learning strategies module of this instrument in the new context was studied by analyzing the factor structure of responses made to it. Confirmatory factor analysis was run to perform a factor analysis of the data. Confirmatory factor analysis revealed identical factor structures for EFL and general education contexts, suggesting that MSLQ is a valid measurement instrument in determining EFL college students' study strategies as well.\n\ndownloadDownload free PDF[View PDFchevron\\_right](https://www.academia.edu/15105244/A_Confirmatory_Factor_Analysis_of_Motivated_Self_regulated_Learning_Questionnaire_in_an_EFL_Context)\n\n* Explore\n* [Papers](https://www.academia.edu/documents)\n* [Topics](https://www.academia.edu/topics)\n\n* Features\n* [Mentions](https://www.academia.edu/login?post_login_redirect_url=https%3A%2F%2Fwww.academia.edu%2Fmentions)\n* [Analytics](https://www.academia.edu/login?post_login_redirect_url=https%3A%2F%2Fwww.academia.edu%2Fanalytics)\n* [PDF Packages](https://www.academia.edu/login?post_login_redirect_url=https%3A%2F%2Fwww.academia.edu%2Fresearch)\n* [Advanced Search](https://www.academia.edu/login?post_login_redirect_url=https%3A%2F%2Fwww.academia.edu%2Fsearch%2Fadvanced)\n* [Search Alerts](https://www.academia.edu/login?post_login_redirect_url=https%3A%2F%2Fwww.academia.edu%2Fsaved_searches)\n\n* Journals\n* [Academia.edu Journals](https://www.academia.edu/journals)\n* [My submissions](https://www.academia.edu/login?post_login_redirect_url=https%3A%2F%2Fwww.academia.edu%2Fjournals%2Fsubmissions)\n* [Reviewer Hub](https://www.academia.edu/login?post_login_redirect_url=https%3A%2F%2Fwww.academia.edu%2Fjournals%2Fsubmissions%23reviewer%2Finvitations)\n* [Why publish with us](https://www.academia.edu/journals/about/why-publish-with-us)\n* [Testimonials](https://www.academia.edu/journals/about/testimonials)\n\n* Company\n* [About](https://www.academia.edu/about)\n* [Careers](https://www.academia.edu/hiring)\n* [Press](https://www.academia.edu/press)\n* [Help Center](https://support.academia.edu/hc/en-us)\n* [Terms](https://www.academia.edu/terms)\n* [Privacy](https://www.academia.edu/privacy)\n* [Copyright](https://www.academia.edu/copyright)\n* [Content Policy](https://www.academia.edu/content_policy)\n\n580 California St., Suite 400\n\nSan Francisco, CA, 94104\n\n[© 2025 Academia. All rights reserved](https://www.academia.edu/copyright)\n\nTitle: The Motivated Strategies for Learning Questionnaire - Academia.edu\nURL: https://www.academia.edu/115467367/The_Motivated_Strategies_for_Learning_Questionnaire_A_Measure_for_Students_General_Motivational_Beliefs_and_Learning_Strategies\nContent: Download Free PDF. The Motivated Strategies for Learning Questionnaire: A ... A manual for the use of the Motivated Strategies for Learning Questionnaire\n\nTitle: [PDF] Revised Motivated Strategies for Learning Questionnaire for ...\nURL: https://www.semanticscholar.org/paper/Revised-Motivated-Strategies-for-Learning-for-Wang/3670ab25261d7ff21dbee350d0dcd925184fe1cc\nContent: The motivated strategies for learning questionnaire (MSLQ) is widely used as a self-report instrument to assess students’ motivation and self-regulation. This study gives results of the first phase of the 12-18 year old Turkish students’ norm study of The Motivated Strategies for Learning Questionnaire (MSLQ), which deveoped by Pintrich, Smith, Garcia… Confirmatory factor analysis was used to evaluate the factor structure of a Chinese version of Pintrich and De Groot’s Motivated Strategies for Learning Questionnaire (MSLQ). The Motivated Strategies for Learning Questionnaire (MSLQ) has dominated self-regulated learning research since the early 1990s. This paper reports on a new self-report, Likert-scaled instrument that was designed to assess motivation and use of learning strategies by college students.\nRaw Content: [Skip to search form](#search-form)[Skip to account menu](#account-menu)\n\n* Corpus ID: 197467971\n\n# Revised Motivated Strategies for Learning Questionnaire for Secondary School Students\n\n```\n@inproceedings{Wang2012RevisedMS, title={Revised Motivated Strategies for Learning Questionnaire for Secondary School Students}, author={C. K. John Wang}, year={2012}, url={https://api.semanticscholar.org/CorpusID:197467971} }\n```\n\n* [C. K. John Wang](/author/C.-K.-John-Wang/29391046)\n* Published 2012\n* Education, Psychology\n\nThe purpose of the current study was to examine the psychometric properties of the MSLQ for junior high school students. The MSLQ for junior high students is a 44 item self-reported instrument consisting of three motivational beliefs subscales, one Cognitive Strategy subscale and one Selfregulation subscale. A total of 780 students from eight secondary schools in Singapore completed the MSLQ. In the first sample, there were 393 students who completed the junior high school version of the MSLQ…\n\n11 Citations\n\n[Background Citations](#citing-papers)\n\n[Methods Citations](#citing-papers)\n\n[Results Citations](#citing-papers)\n\n2\n\n## Tables from this paper\n\n## 11 Citations\n\n[### Self-regulated learning in Singaporean context: a congeneric approach of confirmatory factor analysis](/paper/Self-regulated-learning-in-Singaporean-context%3A-a-Ng-Wang/e2b4be00e67ca7ee73713b8d056861c7a80b8ae4)\n\n[B. Ng](/author/B.-Ng/145580419)[C. K. John Wang](/author/C.-K.-John-Wang/29391046)[W. C. Liu](/author/W.-C.-Liu/2109541785)\n\nEducation, Psychology\n\n* 2017\n\nThe motivated strategies for learning questionnaire (MSLQ) is widely used as a self-report instrument to assess students’ motivation and self-regulation. This study utilized the MSLQ Junior High to…\n\n* [9](/paper/e2b4be00e67ca7ee73713b8d056861c7a80b8ae4#citing-papers)\n* [Highly Influenced](/paper/e2b4be00e67ca7ee73713b8d056861c7a80b8ae4?sort=is-influential#citing-papers)\n* [PDF](/paper/e2b4be00e67ca7ee73713b8d056861c7a80b8ae4)\n\n[### International Journal of Instruction](/paper/International-Journal-of-Instruction-Khampirat/430bfcbd7ae0529ec4624a61585bdec2c497646b)\n\n[B. Khampirat](/author/B.-Khampirat/8875391)\n\nEducation, Psychology\n\n* 2021\n\nStudents who are self-regulated leaners have been reported to perform more successfully in higher education institutions (HEIs). Therefore, instruments that can monitor students’ motivation and…\n\n* [PDF](/paper/430bfcbd7ae0529ec4624a61585bdec2c497646b)\n\n[### High level cognitive strategies scale for middle school students: A psychometric evaluation](/paper/High-level-cognitive-strategies-scale-for-middle-A-Xu/3fffe856a664cc4a8cfb437f9535d38f71d9f7e5)\n\n[Jianzhong Xu](/author/Jianzhong-Xu/49395019)\n\nPsychology, Education\n\nCurrent Psychology\n\n* 2020\n\nThe aim of the current investigation was to validate High Level Cognitive Strategies Scale (HLCSS) using the data from 3018 8th graders in China. The factorial results revealed that the HLCSS…\n\n* [2](/paper/3fffe856a664cc4a8cfb437f9535d38f71d9f7e5#citing-papers)\n\n[### Validity and reliability of an English translation of the Teacher Metacognition Inventory (TMI) with mathematics teachers in Singapore](/paper/Validity-and-reliability-of-an-English-translation-Tay-Tan/4210715b5148820a24f1491fbf41ec347dc97761)\n\n[L. Tay](/author/L.-Tay/1841447)[L. Tan](/author/L.-Tan/46816607) [Puay Huat Chua](/author/Puay-Huat-Chua/102465930)\n\nEducation, Mathematics\n\nCurrent Psychology\n\n* 2021\n\nThe purpose of the study was to examine the validity of an English translation of the Teacher Metacognition Inventory (TMI) originally developed by Jiang et al. Teaching and Teacher Education, 59 ,…\n\n* [3](/paper/4210715b5148820a24f1491fbf41ec347dc97761#citing-papers)\n\n[### Predictors of Engagement and Success in a Flipped EFL Classroom in China](/paper/Predictors-of-Engagement-and-Success-in-a-Flipped-Nicholes/ff602c7568f039d2a59cea67a42820321bd8f50f)\n\n[Justin Nicholes](/author/Justin-Nicholes/2258191725)\n\nEducation, Linguistics\n\nElectronic Journal of Foreign Language Teaching\n\n* 2020\n\nThe present study adopted a predictive-correlational design to explore whether self-reported motivated strategies for learning and language-learning strategies of Chinese EFL learners ( N = 97) were…\n\n* [9](/paper/ff602c7568f039d2a59cea67a42820321bd8f50f#citing-papers)\n[PDF]\n\n[### Self-Regulated Learning as a Critical Attribute for Successful Teaching and Learning.](/paper/Self-Regulated-Learning-as-a-Critical-Attribute-for-Iwamoto-Hargis/cf760f66cea8f26a0104379aa8b9c139384f10a0)\n\n[Darren H Iwamoto](/author/Darren-H-Iwamoto/66302070)[J. Hargis](/author/J.-Hargis/1713685)[R. Bordner](/author/R.-Bordner/95505904)[P. Chandler](/author/P.-Chandler/87091099)\n\nEducation, Psychology\n\n* 2017\n\nThe purpose of this scholarship of teaching and learning was to define and assess the level of self-regulation skills undergraduate students possess. Participants completed the Motivated Strategies…\n\n* [20](/paper/cf760f66cea8f26a0104379aa8b9c139384f10a0#citing-papers)\n* [PDF](/paper/cf760f66cea8f26a0104379aa8b9c139384f10a0)\n\n[### Study efforts, learning strategies and test anxiety when striving for language competence: the role of utility value, self-efficacy, and reasons for learning English](/paper/Study-efforts%2C-learning-strategies-and-test-anxiety-%C3%9Cner-Mouratidis/d7029c8e4f20c10e8b9a67704abebc9bc80e07cb)\n\n[Ayça Üner](/author/Ay%C3%A7a-%C3%9Cner/1659052128)[Athanasios Mouratidis](/author/Athanasios-Mouratidis/113107037)[İlker Kalender](/author/%C4%B0lker-Kalender/71324495)\n\nEducation, Linguistics\n\n[Educational Psychology](/venue?name=Educational%20Psychology)\n\n* 2020\n\nAbstract Previous research has shown that utility value and expectancy for success, as well as the reasons for academic striving, could partly explain academic engagement. Yet, their joint role in…\n\n* [20](/paper/d7029c8e4f20c10e8b9a67704abebc9bc80e07cb#citing-papers)\n* [PDF](/paper/d7029c8e4f20c10e8b9a67704abebc9bc80e07cb)\n\n[### The use of Hamburger paragraph and selfregulated learning on student’s writing recount text (A Quasi-experimental study at the tenth grade students of Perguruan Rakyat 2 vocational high school)](/paper/The-use-of-Hamburger-paragraph-and-selfregulated-on-Kurniasih/a09d61837062fe7ba48a06c2d622b848e43f7e4e)\n\n[I. Kurniasih](/author/I.-Kurniasih/104807975)\n\nEducation\n\n* 2018\n\nIka Kurniasih. The Use of Hamburger Paragraph and Self-Regulated Learning on Writing Recount Text (A Quasi-Experimental Study at the Tenth Grade Students of Perguruan Rakyat Vocational High School),…\n\n* [PDF](/paper/a09d61837062fe7ba48a06c2d622b848e43f7e4e)\n\n[### Examining Flow Antecedents in Game-Based Learning to promote Self-Regulated Learning and Acceptance](/paper/Examining-Flow-Antecedents-in-Game-Based-Learning-Wan-King/e3cfa2bc5a02650dacf9f2d2e1727660f305aceb)\n\n[K. Wan](/author/K.-Wan/97239013)[V. King](/author/V.-King/2067864906)[K. Chan](/author/K.-Chan/2110193973)\n\nEducation, Computer Science\n\n* 2021\n\nThe findings revealed that learners place a higher value on GBL with flow antecedents like concentration and challenge, which is linked to their learning motivation and metacognitive outcomes.\n\n* [9](/paper/e3cfa2bc5a02650dacf9f2d2e1727660f305aceb#citing-papers)\n\n[### Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses](/paper/Delving-Into-the-Psychology-of-Machines%3A-Exploring-Vogelsmeier-Oliveira/4751940fade64e98f77b83570335d8d808b8a77c)\n\n[L. Vogelsmeier](/author/L.-Vogelsmeier/123648376)[E. Oliveira](/author/E.-Oliveira/2361905845)[Kamila Misiejuk](/author/Kamila-Misiejuk/2306064924)[Sonsoles L'opez-Pernas](/author/Sonsoles-L'opez-Pernas/2341330230)[M. Saqr](/author/M.-Saqr/2295001534)\n\nPsychology\n\n[Comput. Hum. Behav.](/venue?name=Comput.%20Hum.%20Behav.)\n\n* 2025\n\n[PDF]\n\n...\n\n...\n\n## 27 References\n\n[### THE TURKISH ADAPTATION STUDY OF MOTIVATED STRATEGIES FOR LEARNING QUESTIONNAIRE (MSLQ) FOR 12-18 YEAR OLD CHILDREN: RESULTS OF CONFIRMATORY FACTOR ANALYSIS 1](/paper/THE-TURKISH-ADAPTATION-STUDY-OF-MOTIVATED-FOR-FOR-1-Akg%C3%BCn-%C3%87akmak/377713fee0a6d38be5ebde5f6cf8127075e4b36c)\n\n[Özcan Erkan Akgün](/author/%C3%96zcan-Erkan-Akg%C3%BCn/2103895177)[E. Çakmak](/author/E.-%C3%87akmak/70331438)[Funda Demirel](/author/Funda-Demirel/79351019)\n\nEducation, Psychology\n\n* 2008\n\nThis study gives results of the first phase of the 12-18 year old Turkish students’ norm study of The Motivated Strategies for Learning Questionnaire (MSLQ), which deveoped by Pintrich, Smith, Garcia…\n\n* [86](/paper/377713fee0a6d38be5ebde5f6cf8127075e4b36c#citing-papers)\n* [PDF](/paper/377713fee0a6d38be5ebde5f6cf8127075e4b36c)\n\n[### A meta-analytic review of the Motivated Strategies for Learning Questionnaire](/paper/A-meta-analytic-review-of-the-Motivated-Strategies-Cred%C3%A9-Phillips/db41fc705c05d2a578902c68b1cd851528f416c9)\n\n[M. Credé](/author/M.-Cred%C3%A9/3286182)[L. Phillips](/author/L.-Phillips/2055627368)\n\nEducation, Psychology\n\n* 2011\n\n* [452](/paper/db41fc705c05d2a578902c68b1cd851528f416c9#citing-papers)\n\n[### Confirmatory Factor Analysis of the Chinese Version of the Motivated Strategies for Learning Questionnaire](/paper/Confirmatory-Factor-Analysis-of-the-Chinese-Version-Rao-Sachs/c797dc6200a76b137c118e409f4cb622a429f808)\n\n[N. Rao](/author/N.-Rao/144395318)[J. Sachs](/author/J.-Sachs/97285402)\n\nEducation, Psychology\n\n* 1999\n\nConfirmatory factor analysis was used to evaluate the factor structure of a Chinese version of Pintrich and De Groot’s Motivated Strategies for Learning Questionnaire (MSLQ). Data were gathered from…\n\n* [117](/paper/c797dc6200a76b137c118e409f4cb622a429f808#citing-papers)\n\n[### The Making of the Motivated Strategies for Learning Questionnaire](/paper/The-Making-of-the-Motivated-Strategies-for-Learning-Duncan-McKeachie/0cffdd0aef9ab3b7ba0f5eae610efbb52da733a3)\n\n[Teresa Duncan](/author/Teresa-Duncan/46521460)[W. McKeachie](/author/W.-McKeachie/2711129)\n\nEducation, Psychology\n\n* 2005\n\nThe goal of this article is to discuss one of Paul Pintrich's more enduring legacies: the Motivated Strategies for Learning Questionnaire (MSLQ), an 81-item, self-report instrument consisting of 6…\n\n* [1,072](/paper/0cffdd0aef9ab3b7ba0f5eae610efbb52da733a3#citing-papers)\n* [Highly Influential](/paper/0cffdd0aef9ab3b7ba0f5eae610efbb52da733a3?sort=is-influential#citing-papers)\n* [PDF](/paper/0cffdd0aef9ab3b7ba0f5eae610efbb52da733a3)\n\n[### Revisiting the Motivated Strategies for Learning Questionnaire](/paper/Revisiting-the-Motivated-Strategies-for-Learning-Dunn-Lo/3ab5728f9ef540c8602217dc3b6dae5550dc8e9a)\n\n[Karee E. Dunn](/author/Karee-E.-Dunn/34183110)[Wen‐Juo Lo](/author/Wen%E2%80%90Juo-Lo/13862470)[Sean W. Mulvenon](/author/Sean-W.-Mulvenon/2992475)[Rachel A. Sutcliffe](/author/Rachel-A.-Sutcliffe/2067184408)\n\nEducation, Psychology\n\n* 2012\n\nThe Motivated Strategies for Learning Questionnaire (MSLQ) has dominated self-regulated learning research since the early 1990s. In this study, the two MSLQ subscales specifically designed to assess…\n\n* [74](/paper/3ab5728f9ef540c8602217dc3b6dae5550dc8e9a#citing-papers)\n\n[### A NONPARAMETRIC ITEM ANALYSIS OF THE MOTIVATED STRATEGIES FOR LEARNING QUESTIONNAIRE—CHINESE VERSION](/paper/A-NONPARAMETRIC-ITEM-ANALYSIS-OF-THE-MOTIVATED-FOR-Sachs-Law/45b1335454316fc6f2f6b2a3b95b15a1e91ce507)\n\n[J. Sachs](/author/J.-Sachs/97285402)[Yin-kum Law](/author/Yin-kum-Law/47843922)[Carol K. K. Chan](/author/Carol-K.-K.-Chan/40259779)[N. Rao](/author/N.-Rao/144395318)\n\nEducation, Psychology\n\n* 2001\n\nThe quality of the Motivational Strategies for Learning Questionnaire-Chinese Version (MSLQ-CV) items was assessed with a nonparametric item analysis on a sample of 1292 Hong Kong primary and…\n\n* [30](/paper/45b1335454316fc6f2f6b2a3b95b15a1e91ce507#citing-papers)\n* [PDF](/paper/45b1335454316fc6f2f6b2a3b95b15a1e91ce507)\n\n[### Reliability and Predictive Validity of the Motivated Strategies for Learning Questionnaire (Mslq)](/paper/Reliability-and-Predictive-Validity-of-the-for-Pintrich-Smith/9e540537ea223d0849ac450b79178f8c1ad58d45)\n\n[P. Pintrich](/author/P.-Pintrich/6817062)[David A. Smith](/author/David-A.-Smith/2153149600)[T. García](/author/T.-Garc%C3%ADa/5457174)[W. McKeachie](/author/W.-McKeachie/2711129)\n\nEducation, Psychology\n\n* 1993\n\nThis paper reports on a new self-report, Likert-scaled instrument that was designed to assess motivation and use of learning strategies by college students. The motivation scales tap into three broad…\n\n* [3,747](/paper/9e540537ea223d0849ac450b79178f8c1ad58d45#citing-papers)\n\n[### Motivational and self-regulated learning components of classroom academic performance.](/paper/Motivational-and-self-regulated-learning-components-Pintrich-Groot/aa39a6a7a67f1bfbb7109f783e72d65b26692d21)\n\n[P. Pintrich](/author/P.-Pintrich/6817062)[E. D. Groot](/author/E.-D.-Groot/145807204)\n\nEducation, Psychology\n\n* 1990\n\nA correlational study examined relationships between motivational orientation, self-regulated learning, and classroom academic performance for 173 seventh graders from eight science and seven English…\n\n* [8,627](/paper/aa39a6a7a67f1bfbb7109f783e72d65b26692d21#citing-papers)\n* [Highly Influential](/paper/aa39a6a7a67f1bfbb7109f783e72d65b26692d21?sort=is-influential#citing-papers)\n* [PDF](/paper/aa39a6a7a67f1bfbb7109f783e72d65b26692d21)\n\n[### Cross-cultural validation of the task and ego orientation in sport questionnaire](/paper/Cross-cultural-validation-of-the-task-and-ego-in-Li-Harmer/c68655ad4eaa7d83a96769d204370147ce64a763)\n\n[Fuzhong Li](/author/Fuzhong-Li/39374341)[P. Harmer](/author/P.-Harmer/145102765)[Likang Chi](/author/Likang-Chi/10339253)[Naruepon Vongjaturapat](/author/Naruepon-Vongjaturapat/10168462)\n\nPsychology, Sociology\n\n* 1996\n\nIt is becoming increasingly important to determine whether structural models of measures of sport and activity behavior developed in North America are invarant across different populations. This…\n\n* [52](/paper/c68655ad4eaa7d83a96769d204370147ce64a763#citing-papers)\n* [PDF](/paper/c68655ad4eaa7d83a96769d204370147ce64a763)\n\n[### Motivational and Self-Regulated Learning Components of Musical Practice](/paper/Motivational-and-Self-Regulated-Learning-Components-McPherson-McCormick/a2a48ae39c5b2180d4028cb8035e79e99fbfa0ce)\n\n[G. McPherson](/author/G.-McPherson/66820517)[John McCormick](/author/John-McCormick/144777877)\n\nPsychology, Education\n\n* 1999\n\nA self-report questionnaire was administered to I 90 pianists immediately before they undertook a graded, externally assessed music performance examination in order to examine possible relationships…\n\n...\n\n...\n\n## Related Papers\n\nShowing 1 through 3 of 0 Related Papers\n\nBy clicking accept or continuing to use the site, you agree to the terms outlined in our [Privacy Policy (opens in a new tab)](https://allenai.org/privacy-policy.html), [Terms of Service (opens in a new tab)](https://allenai.org/terms), and [Dataset License (opens in a new tab)](http://api.semanticscholar.org/corpus/legal)\n\n \n\nTitle: MSL Questionnaire | PDF | Lecture | Reading (Process) - Scribd\nURL: https://www.scribd.com/document/134852913/Msl-Questionnaire\nContent: The document introduces the Motivated Strategies for Learning Questionnaire (MSLQ), which measures students' learning strategies and academic motivation.\nRaw Content: ![Scribd](data:image/svg+xml;base64,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)\n\n# MSLQ: Learning Strategies Assessment\n\nMSLQ: Learning Strategies Assessment\n\n## Uploaded by\n\nAI-enhanced title and description\n\n# MSLQ: Learning Strategies Assessment\n\nThe document introduces the Motivated Strategies for Learning Questionnaire (MSLQ), which measures students' learning strategies and academic motivation. It contains several sections that provide scores to help students and instructors identify strengths and weaknesses. The MSLQ asks students to rate statements about their study habits, motivation, and self-efficacy on a scale from \"not at all true of me\" to \"very true of me.\"\n\n# MSLQ: Learning Strategies Assessment\n\nMSLQ: Learning Strategies Assessment\n\n## Uploaded by\n\nAI-enhanced title and description\n\n## Share this document\n\n![]()\n\n## Footer menu\n\nAbout\n\nSupport\n\nLegal\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nAbout\n\nLegal\n\nSupport\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nTitle: [PDF] Motivated Strategies for Learning Questionnaire - ERIC\nURL: https://files.eric.ed.gov/fulltext/ED338122.pdf\nContent: ABSTRACT. This manual 13 a guide to the \"Motivated Strategies for Learning Questionnaire\" (MSLQ) for assessing college students'.\nRaw Content: DOCUMENT RESUME ED 338 122 HE 024 935 AUTHOR Pintrich, Paul R.; And Others TITLE A Manual for the Use of the Motivated Strategies for Learning Questionnaire (MSLQ).\nINSTITUTION National Center for Research to Improve Postsecondary Teaching and Learning, Ann Arbor, MI.\nSPONS AGENCY Office of Educational Research and Improvement (ED), Washington, DC.\nREPORT NO NCRIPTAL-91-B-004 PUB DATE 91 CONTRACT OERI-86-0010 NOTE 76p.; From the National Center for Research to Improve Postsecondary Teaching and Learning Project on Instructional Processes and Edrcational Outcomes.\nFor a related document, see HE 024 936.\nPUB TYPE Guides - Non-Classroom Use (055) -- Tests/Evaluation Instruments (160) EDRS PRICE MF01/PC04 Plus Postage.\nDESCRIPTORS College Students; Higher Education; *Learning Motivation; *Learning Strategies; *Questionnaires; Research Methodology; Scientific and Technical Information; *Student Educational Objectives; *Student Motivation IDENTIFIERS *Motivated Strategies for Learning Questionnaire ABSTRACT This manual 13 a guide to the \"Motivated Strategies for Learning Questionnaire\" (MSLQ) for assessing college students' motivational orientations and their use of different learning strategies for a college ccurse. The MSLQ, based on a general cognitive view of motivation and learning strategies, contains two sections. The motivation section consists of 31 items that assess students' goals and value beliefs for a course. The learning strategies section includes 31 items regarding students' use of different cognitive and metacognitive strategies and 19 items concerning student management of different resources. The guide contains an introduction that details the survey's development, scoring, organization, and administration suggestions. Two sections explain the two components of the instrument in detail, listing the items, explaining their significance, and offering descriptive statistics. Also included in other sections are a sample fact sheet; a sample demographic sheet; a copy of the questionnaire itself; a sample feedback form; 11 references; and an appendix listing demographic information, scale correlations, and confirmatory factor analysis results.\n(JB) **** *********** ******************************* ******** ****** ** Reproductions supplied by EDRS are the best that can be made from the original document.\n*********************************************************************** Selected publications available from NCRIPTAL Approaches to Research on the Improvement of Postsecondszy Teaching and Learning: A Working Paper Patricia J. Green and Joan S. Stark Postsecoadary Teaching and Learning Issues in Search of Reser rchers: A Working Paper Carol D. Vogel and Joan S. Stark Classroom Assessment Techniques: A Handbook for K. Patricia Crass and Thomas A. Angelo Psychological Medals ot the Impact of College on Students Harold A. Korn Teaching sad Learning in the College Classroom A PAVkire of the Research Literature. Second Edition Wilbert J. Mc/Coach*. Paid R. Pfntrich, Yl-Guarig Let.\nDatrid A. F. Smith. and Rajeeu Sharma Designing the Learning Plan: A Review of Research and Theory Related to College Canicula Joan S. Stark and MaZeolrn A. Lowther. with assistance from Sally Smith Reflections on Course Planning: Faculty and Students Consider Influences and Goals Joan S. Stark. Makolnt A. Lowther. Michael P. Ryan.\nSally Smith &mai, Michele L Genthon. Gretchen G. Martens.\nand C. Lynne Hauen Planning Introductory College Courses: Influences on Faculty Joan S. Stark. Malcolm A. I..owther. Richard J. Bentley, Michael P. Ryan.\nGretchen G. Martens. Michele 1.. Genthon. Patricia Wren. and Kathleen M. Shaw Planning a College Course: A Guidebook for the Graduate Ter:clam' Assistant Michael P. Ryan and Gretchen G. Martens Preparing Course Syllabi for Improved Communication Malcolm A. Lowther. Joan S. Stark. and Gretchen G. Martens Faculty as a Key Resource: A Review of the Research Literature Robert T. Blackburn. Janet H. Lawrence. Steuen Ross. Virptraci Polk °kaiak°.\nJeffery P. Bieber. Rosalie Meilarci. and Thrry Street Performance Appraisal fee Faculty: Implicatleas for Higher gdoeation Robert T. Blackburn and Judith A. Pitney no Organisational Contest far Teaching aad Learning: A Review of Os Research Literstrao Martnn W. Peterson. Ken S. Cameron. LisaA. Meta, Philip Jones. and Deborah Ettlngton Electronic Informatioul Mersey SUM for a Computer Age Jerome Johnstort Design in Context: A Conceptual Framework for the Study of Computer Sorrow-a in Higher Lducation Robert B. Kovna and Robert L. Bangs:It-Drowns The Slectrenio Classroom ia Higher Sducation: A Case for Change Jerome Johnvort and Swan Gardner A Manual for the Use of the Motivated Strategies for Learning Questionnaire (MSLQ) Paul R. Pintrich, David A. F. Smith, Teresa Garcia, and Wilbert J. McKeachie Grant Number OEM-86-0010 Joan S. Stark. Director Wilbert J. McKeachie. Associate director Suite 2400 School of Education Building The University of Michigan Ann Arbor, Michigan 48109-1259 (313)936-2741 Acknowledgements The Motivated Strategies for Learning Questionnaire (MSLQ) was designed and devloped by a team of researchers from the National Center for Research to Improve Postsecondary Teaching and Learning (NCRIFFAL) and the School of Education at the University of Michigan. Besides the four authors, the team of researchers included Yi-Guang Lin, Moshe Naveh-Benjamin, Stuart Karaberack.\nDonna Kempf, Terry Crooks, Susan Reiter. Carol Weiss, and Robert Doljanac.\nThe development of the MSLQ could noi have been completed without their help.\nTechnical Report No. 91-8-004 ©1991 The Regents of The University of Michigan. All rights reserved.\nThe project presented, or reported herein, was performed pursuant to a grant from the Office of Educatioral Research and Improvement/ Deportment of Education (OERI/ED).\nHowever, the opinions expressed herein do not necessarily reflect the position or policy of the OERI/ED or the Regents of The University of Michigan, and no official endorsement should be inferred Contents I. Introduction 1 IL Listing of Motivation Scales 1. Value Components a. Intrinsic Goal Orientation b. Extrinsic Goal Orientation C. Task Value 2. Expectancy Components a. Control Beliefs b. Self-Efficacy for Learning and Performance 3. Affective Components a. Test Anxiety 7 9 9 10 11 12 12 13 15 15 III. Listing of Learning Strategies Scales 17 1. Cognittve and Metacognitive Strategies 19 a. Rehearsal 19 b. Elaboration 20 C. Organization 21 d. Critical Thinking 22 C.\nMetacognitive Self-Regulation 23 2. Resource Management Strategies 25 a. Time and Study Environment 25 b. Effort Regulation 27 c. Peer Learning 28 d. Help Seeking 29 IV. Sample Face Sheet V. Sample Demographic Sheet VI. The Motivated Strategies for Learning Questionnaire VII. Sampie Feedback Form VIII.\nReferences t; 31 35 39 49 61 Appendices A Demographic Information B.\nScale Correlations -C. Confirmatory Factor Analyses Results v i Motivated Strategies for Learning Questionnaire Manual I. INTRODUCTION 1 Motivated Strategies for Learning Questionnaire Manual General Description The Motivated Strategies for Learning Questionnaire (MSLQ) is a self-report instrument designed to assess college students' motivational orientations and their use of different learning strategies for a college course. The MSLQ is based on a general cognitive view of motivation and learning strategies.\nMcKeachie, Pintrich, Lin, & Smith (1986) present the general theoretical framework that underlies the MSLQ.\nOther articles that discuss the theoretical framework include Pintrich (1988a,b; 1989), Pintrich & Garcia (1991), and Pintrich and De Groot (1990).\nThere are essentially two sections to the MSLQ, a motivation section, and a learning strategies section. The motivation section consists of 31 items that assess students' goals and value beliefs for a course, their beliefs about their skill to succeed in a course, and their anxiety about tests in a course. The learning strategy section includes 31 items regarding students' use of different cognitive and metacognitive strategies. In addition, the learning strategies section includes 19 items concerning student management of differmt resources. There are 81 items on the 1991 version of the MSLQ.\nAdministering the mu The fifteen different scales on the MSLQ can be used together or singly. The scales are designed to be modular and can be used to fit the needs of the researcher or instructor. The instrument is designed to be given in class and takes approximately 20-30 minutes to administer.\nA sample cover sheet (p. 33) and demographic sheet (p. 37) are included in this manual. The cover sheet requests the student's voluntary participation and briefly describes the MSLQ. The demographic sheet is an optional form the researcher can include to gather students' background data.\nBoth the sample cover sheet and demographic sheet can be adapted to the individual researcher's needs. The questionnaire itself is located on pages 41-48.\nDevelopment of the MSLQ The MSLQ has been under development formally since 1986 when NCRIPTAL was founded and informally since 1982 when we undertook our research on college student learning and teaching.\nThe years 1982-1986 involved using a self-report instrument to assess students' motivation and use of learning strategies that varied from 50 to 140 items. We used these early instruments to evaluate the effectiveness of our \"Learning to Learn\" class here at the University of Michigan (see McKeachie, Pintrich, & Lin, 1985; Pintrich, McKeachie, & Lin, 1987). These instruments were used with over 1000 University of Michigan undergraduates enrolled in our course. These early instruments were subjected to the usual statistical and psychometric 3 Motivated Strategies for Learning Questionnaire Mantta .\nanalyses, including internal reliability coefficient computation, factor analyses, and correlations with academic performance and aptitude measures (e.g., SAT scores). We continually revised items on the basis of these results.\nWe began the formal development of the MSLQ when NCRIPTAL was founded in 1986. NCRIPTAL was funded for research on college populations excluding major research ins itutions like Michigan. We began using the MSLQ at three collaborating Institutions in the Midwest, a four-year, public, comprehensive university; a small liberal arts college; and a community college.\nThere were three major waves of data collection with previous versions of the MSLQ with students from these three institutions: 1986, 1987, and 1988. The items on these previous versions of the MSLQ were subjected to the usual statistical and psychometric analyses including int?rnal reliability coefficient computation, factor analyses, and correlations with academic performance measures. The first wave of data collected in 1986 included 326 students; the second wave in 1987 included 687 students; and the third wave in 1988 included 758 students. After each of these waves we analyzed the data and rewrote items, and refined the conceptual model underlying our instrument.\nTherefore, based on both theoretical and empirical analyses, we revised items and constructed scales.\nThe final version of the MSLQ presented in this manual represents the past five years of work on these various waves of data.\nCharacteristics of thg Sample The data presented in this document were gathered from a sarnpie of 380 Midwesterr college students.\nMost of these students (N=356) attended a public, four-year university; the remaining students (N=24) attended a community college. This version of the MSLQ was administered towards the end of the Winter 1990 (January to May) semester. Thirty seven classrooms were sampled, spanning fourteen subject domains and five disciplines (natural science, humanities, social science, computer science, and foreign language).\nAdditional demographic information about this sampk can be found in Appendix A (pp. 67-71).\nItem and Scale Stati§tics The MSLQ scales are detailed on pages 9-29.\nThis manual includes descriptions of each scale, as well as relevant statistics such as internal reliability coefficients, means, standard deviations, and zero order correlations with final course grade kr each item and scale. Scale correlations are presented in Appendix B (p. 75). The scale correlations with final grade are significant, albeit moderate, demonstrating predictive validity. The Cronbach's alphas are robust, ranging from .52 to .93. Additionally, we have 4 Motivated Strategies for Learning Questionnaire Manual included results from confirmatory factor analyses in Appendix C (pp. 79-87).\nThese indicate that the MSLQ shows reasonable factor validity.\n5coring the MSLO Students rate themselves on a seven point Likert scale from \"not at all true of me\" to \"very true of me.\" Scales are constructed by taking the mean of the items that make up that scale.\nFor example, intrinsic goal orientation (see page 9) has four items. An individual's score for intrinsic goal orientation would be computed by summing the four items and taking the average.\nItems marked as \"reversed\" are reverse coded items and must be reflected before scale construction.\nThese negatively worded items and the ratings have to be reversed before an individual's score can be computed. If an item has to be reversed, a person who has circled 1 for that item now receives a score of 7 and so on.\nAccordingly, a I becomes a 7, a 2 becomes a 6, a 3 becomes a 5, a 4 remains a 4, a 5 becomes a 3, a 6 becomes a 2, and a 7 becomes a I. The simplest way to reflect a reverse coded item is to subtract the original score from 8.\nFor example, if the original score was 2 to the negatively worded item, one would compute 8 - 2 = 6; 6 being the score for the positively worded version of that question. The statistics reported in this manual all represent the positively worded versions of the items.\nSp_sient Feedback It has been our policy at NCRIPTAL to provide students feedback on the MSLQ as a form of compensation for their participation in our studies. We have chosen nine scales of the MSLQ (Task Value, Self-Efficacy for Learning and Performance, Test Anxiety, Rehearsal, Elaboration, Organization, Metacognition, Time and Study Environment Management, and Effort Regulation) on which to give students feedback. The student's individual scores, the class' scale means, and quartile information are included in the feedback form.\nWe provide descriptions of each scale and also offer suggest is to students on how to increase their levels of motivation and strateg ase. Our feedback form is duplicated in this manual on pages 51-60.\nAgain, the feedback form may be adapted to the researcher's or instructor's needs.\nWe have not provided norms for the MSLQ. It is designed to be used at the course level. We assume that students' responses to the questions might vary as a function of different courses, so that the same individual might report different levels of motivation or strategy use depending on the course.\nIf the user desires norms for comparative purposes over time, we suggest the development of local norms for the different courses or instructors at the local institution.\nMotivated Strategies for Learning Questionnaire Manual H. MOTIVATION SCALES 7 Motivated Strategies for Learning Questionnaire Manual I 1 I Goal orientation refers to the student's perception of the reasons why she is engaging in a learning task. On the MSLQ, goal orientation refers to student's general goals or orientation to the course as a whole.\nIntrinsic goal orientation concerns the degree to which the student perceives herself to be participating in a task for reasons such as challenge, curiosity, mastery.\nHaving an intrinsic goal orientation towards an academic task indicates that the student's participation in the task is an end all to itself, rather than participation being a means to an end.\nItem 1.\nIn a class like this, I prefer course material that really challenges me so I can learn new things.\n16.\nIn a class like this, I prefer course material that arouses my curiosity, even if it is difficult to learn.\n22.\nThe most satisfying thing for me in this course is trying to understand the content as thoroughly as possible.\n24.\nWhen I have the opportunity in this dass, I choose course assignments that I can learn from even if they don't guarantee a good grade.\nAlpha: .74 Descriptive Statistics Standard Correlation Mean Deviation with Final Grade Item 1 5.05 1.41 .22 16 5.68 1.38 .21 22 5.23 1.41 .17 24 4.14 1.58 .16 Scale 5.03 1.09 .25 9 Motivated Strategies for Learning Questionnaire Manual YalucCompantaLLExtrinsis_CLilalnzientatilm Extrinsic goal orientation complements intrinsic goal orientation, and concerns the degree to which the student perceives herself to be participating in a task for reasons such as grades, rewards, performance, evaluation by others, and competition. When one is high in extrinsic goal orientation, engaging in a learning task is the means to an end. The main concern the student has is related to issues that are not directly related to participating in the task itself (such as grades, rewards, comparing one's performance to that of others). Again, this refers to the general orientation to the course as a whole.\nItem 7.\nGetting a good grade in this class is the most satisfying thing for me right now.\n11.\nThe most important thing for me right now is improving my overall grade point average, so my main concern in this class is getting a good grade.\n13.\nIf I can, I want to get better grades in this class than most of the other students.\n30.\nI want to do well in this class because it is important to show my ability to my family, friends, employer, or others.\nAlpha: .62 Descriptive Statistics Item Mea:1 Standard Correlation Deviation with Final Grade 7 5.07 1.62 .10 11 5.32 1.71 -.09 13 5.31 1.73 .10 30 4.43 2.07 -.04 Scale 5.03 1.23 .02 10 Motivated Strategies for Learning Questionnaire Manual Value Component: Task Value Task value differs from goal orientation in that task value refers to the student's evaluation of the how interesting, how important, and how useful the talk is (\"What do I think of this taskr). Goal orientation refers to the reasons why, the student is participating in the task (\"Why am I doing this?\").\nHigh task value should lead to more involvement in one's learning. On the MSLQ, task value refers to students' perceptions of the course material in terms of interest, importance, and utility.\nItem 4.\nI think I will be able to use what I learn in this course in other courses.\n10.\nIt is important for me to learn the course material in this class.\n17.\nI am very interested in the content area of this course.\n23.\nI think the course material in this class is useful for me to learn.\n26.\nI like the subject matter of this course.\n27.\nUnderstanding the subject matter of this course is very important to me.\nAlpha: .90 Descriptive Stalis&s Item Standard Correlation Mean Deviation with Final Grade 4 5.33 1.72 .15 10 5.87 1.24 .15 17 5.32 1.64 .21 23 5.72 1.38 .18 26 5.46 1.66 .19 27 5.54 1.40 .22 Scale 5.54 1.25 .22 1 k 1 Motivated Strategies for Learning Questionnaire Manual Earstancy..Component: Control of Learning Beliefs Control of learning refers to students' beliefs that their efforts to learn will result in positive outcomes.\nIt concerns the belief that outcomes are contingent on one's own effort, in contrast to external factors such as the teacher. If students believe that their efforts to study make a difference in their learning, they should be more likely to study more strategically and effectively. That is, if the student feels that she can control her academic performance, she is more likely to put forth what is needed strategically to effect the desired changes.\nItem 2.\nIf I study in appropriate ways, then I will be able to learn the material in this course.\n9.\nIt is my own fault if I don't learn the material in this course.\n18.\nIf I try hard enough, then I will understand the course material.\n25.\nIf I don't understand the course material, it is because I didn't try hard enough.\nAlpha: .68 Descriptive Statistics Standard Correlation Mean Deviation with Final Grade Item 2 6.12 1.14 .21 9 5.60 1.62 .06 18 6.14 1.02 .15 25 5.09 1.62 .01 Scale 5.74 .98 .13 12 !\n; *I Motivated Strategies for Learning Questionnaire Manual 1,1 I) I I -01 I .16 -0041,11 The items comprising this scale assess two aspects of expectancy: expectancy for success and self-efficacy. Expectancy for success refers to performance expectations, and relates specifically to task performance. Self-efficacy is a self-appraisal of one's ability to master a task. Self-efficacy includes judgments about one's ability to accomplish a task as well as one's confidence in one's skills to perform that task.\nItem 5.\nI believe I will receive an excellent grade in this class.\n6.\nI'm certain I can understand the most difficult material presented in the readings for this course.\n12.\nI'm confident I can understand the basic concepts taught in this course.\n15.\nI'm confident I can understand the most complex material presented by the instructor in this course.\n20.\nI'm confident I can do an excellent job on the assignments and tests in this course.\n21.\nI expect to do well in this class.\n29.\nI'm certain I can master the skills being taught in this class.\n31.\nConsidering the difficulty of this course, the teacher, and my skills, I think I will do well in this class.\nAlpha: .93 Motivated Strategies for Learning Questionnaire Manual .10 M I 14 S II I øI4. .\nO 011 1 Descriptive Statistics Item 5 6 12 15 20 21 29 31 Scale Standard Correlation Mean Deviatioq with Final Grade 4.95 1.59 .49 5.18 1.62 .19 6.36 .% .23 5.36 1.48 .22 5.24 1.47 .39 5.55 1.39 .46 5.57 1.30 .28 5.55 1.34 .44 5.47 1.14 .41 14 I Motivated Strategies for Learning Questionnaire Manual Affediy.t..Cam Test anxiety has been found to be negatively related to expectancies as well as academic performance. Test anxiety Li thought to have two components: a worry, or cognitive component, and an emotionality component. The worry component reiers to students' negative thoughts that disrupt performance, while the emotionality component refers to affective and physiological arousal aspects of anxiety.\nCognitive concern and preoccupation with performance have been found to be the greatest sources of performance deaement. Training in the use of effective learning strategies and test-taking skills should help reduce the degree of anxiety.\nItem 3.\nWhen I take a test I think about ki,.w poorly I am doing compared with other students.\n8.\nWhen I take a test I think about items on other parts of the test I can't answer.\n14.\nWhen I take tests I think of the consequences of failing.\n19.\nI have an uneasy, upset feeling when I take an exam.\n28.\nI feel my heart beating fast when I take an exam.\nAlpha: .80 Descriptive Statistics Item Scale Standard Correlation Mean Deviation with Final Grade 3 2.98 1.90 -.29 8 3.83 1.86 -.13 14 3.84 2.04 -.24 19 3.89 1.98 -.22 28 3.59 1.95 -.13 3.63 1.45 -.27 15 Motivated Strategies for Learning Questionnaire Manual -III. LEARNING STRATEGIES SCALES 17 0 i )k.....\nMotivated Strategies for Learning Questionnaire Manual Basic rehearsal strategies involve reciting or naming items from a list to be learned. These strategies are best used for simple tasks and activation of information in working memory rather than acquisition of new information in long-term memory.\nThese strategies are assumed to influence the attention and encoding processes, but they do not appear to help students construct internal connections among the information or integrate the information with prior knowledge.\nItem 39.\nWhen I study for this class, I practice saying the material to myself over and over.\n46.\nWhen studying for this dass, I read my class notes and the course readings over and over again.\n59.\nI memorize key words to remind me of important concepts in this class.\n72.\nI make lists of important terms for this course and memorize the lists.\nAlpha: .69 Descriptive Statistics Standard Correlation Mean Deviation with Final Grade Item 39 4.30 2.01 -.04 46 4.80 1.84 .06 59 5.31 1.50 .07 72 3.68 2.10 .06 Scale 4.53 1.35 .05 Motivated Strategies for Learning Questionnaire Manual Cognitiye..andlipjawsnitiyiatzategks: Elaboration Elaboration strategies help students store information into long-term memory by building internal connections between items to be learned.\nElaboration strategies incluae paraphrasing, summarizing, creating analogies, and generative note-taking. These help the learner integrate and connect new information with prior knowledge.\nItem 53.\nWhen I study for this class, I pull together information from different sources, such as lectures, readings, and discussions.\n62.\nI try to relate ideas in this subject to those in other courses whenever possible.\n64.\nWhen reading for this class, I try to relate the material to what I already know.\n67.\nWhen I study for this course, I write brief summaries of the main ideas from the readings and the concepts from the lectures.\n69.\nI try to understand the material in this class by making connections between the readings and the concepts from the lectures.\n81.\nI try to apply ideas from course readings in other class activities such as lecture and discussion.\nAlpha: .76 Descriptive $tatistics Item Scale Standard Correlation Mean Deviation with Final Grade 53 5.29 1.65 .09 62 5.07 1.59 .21 64 5.56 1.28 .13 67 3.23 2.02 .15 69 5.35 1.50 .19 81 4.91 1.56 .13 4.91 1.08 .22 20 .41 Motivated Strategies for Learning Questionnaire Manual 11 I 'AI Organization strategies help the learner select appropriate information and also construct connections among the information to be learned. Examples of an organizing strategies are clustering, outlining, and selecting the main idea in reading passages. Organizing is an active, effortful endeavor, and results in the learner being closely involved in the task. This should result in better performance.\nItem 32.\nWhen I study the readings for this course, I outline the material to help me organize my thoughts.\n42.\nWhen I study for this course, I go through the readings and my class notes and try to find the most important ideas.\n49.\nI make simple charts, diagrams, or tables to help me organize course material.\n63.\nWhen I study for this course, I go over my class notes and make an outline of important concepts.\nAlpha: .64 Descriptive Statistics Item Scale Standard Correlation Mean Deviation with Final Grady 32 3.70 2.17 .06 42 5.93 1.31 .21 49 3.04 1.94 .13 63 3.90 2.11 .12 4.14 1.33 .17 21 Motivated Strategies for Learning Questionnaire Manual Critical thinking refers to the degree to which students report applying previous knowledge to new situations in order to solve problems, reach decisions, or make critical evaluations with_respect to standards of excellence.\nItem 38.\nI often find myself questioning things I hear or read in this course to decide if I find them convincing.\n47.\nWhen a theory, interpretation, or conclusion is presented in class or in the readings, I try to decide if there is good supporting evidence.\n51.\nI treat the course material as a starting point and ery to develop my own ideas about it.\n66.\nI try to play around with ideas of my own related to what I am learning in this course.\n71.\nWhenever I read or hear an assertion or conclusion in this class, I think about possible alternatives.\nAlpha: .80 Descriptive Statistics Item Scale Standard Correlation Mean Dzyjalion 38 3.83 1.77 .04 47 4.36 1.68 .13 51 3.81 1.85 .08 66 4.66 1.74 .17 71 4.15 1.49 .13 4.16 1.28 .15 22 I ) , Motivated Strategies for Learning Questionnaire Manual 41 1 1/ 1 I U S \"41 '4 I Metacognition refers to the awareness, knowledge, and control of cognition.\nWe have focused on the control and self-regulation aspects of metacognition on the MSLQ, not the knowledge aspect. There are three general processes that make up metacognitive self-regulatory activities: plarming, monitoring, and regulating. Planning activities such as goal setting and task analysis help to activate, or prime, relevant aspects of prior knowledge that make organizing and comprehending the material easier.\nMonitoring activities include tracking of one's attention as one reads, and self-testing and questioning: these assist the learner in understanding the material and integrating it with prior knowledge. Regulating refers to the fine-tuning and continuous adjustment of one's cognitive activities. Regulating activities are assumed to improve performance by assisting learners in checking and correcting their behavior as they proceed on a task.\nItem 33.\nDuring class time I often miss important points because I'm thinking of other things. (REVERSED) 36.\nWhen reading for this course, I make up questions to help focus my reading.\n41.\nWhen I become confused about something I'm reading for this class, I go back and try to figure it out.\n44.\nIf course materials are difficult to understand, I change the way I read the material.\n54.\nBefore I study new course material thoroughly, I often skim it to see how it is organized.\n55.\nI ask myself questions to make sure I understand the material I have been studying in this class.\n56.\nI try to change the way I study in order to fit the course requirements and instructor's teaching style.\n57.\nI often find that I have been reading for class but don't know what it was all about. (REVERSED) 61.\nI try to think through a topic and decide what I am supposed to learn from it rather than just reading it over when studying.\n76.\nWhen studying for this course I try to determine which concepts I don't understand well.\n78.\nWhen I study for this class, I set goals for myself in order to direct my activities in each study period.\n79.\nIf I get confused taking notes in class, I make sure I sort it out afterwards.\nMotivated Strategies for Learning Questionnaire Manua!\nDietaffignitimSelidlegulationlontinuesil Alpha: .79 12tactiain_asitiattira Item 33 36 41 44 54 55 56 57 61 76 78 79 Scale Mean Standard neviatign Correlation with Final Grade 4.92 1.68 .25 2.98 1.75 .03 5.79 1.19 .23 4.07 1.61 12 4.51 1.80 .17 4.12 1.78 .05 4.61 1.68 .16 4.81 1.66 .27 4.50 1.60 .21 5.12 1.31 .19 4.53 1.67 .19 4.55 1.73 .16 4.54 .90 .30 24 Motivated Strategies for Learning Questionnaire Manual I 11, I II Besides self-regulation of cognition, students must be able to manage and regulate their time and their study environments. Time management involves acheduling, planning, and managing one's study time.\nThis includes not only setting aside blocks of time to study, but the effective use of that study time, and setting realistic goals. Time management varies in level, from an evening of studying to weekly and monthly scheduling. Study environment management refers to the setting where the student does her class work. Ideally, the learner's study environment should be organized, quiet, and relatively free of visual and auditory distractions.\nItem 35.\nI usually study in a place where I car, concentrate on my course work.\n43.\nI make good use of my study time for this course.\n52.\nI find it hard to stick to a study schedule. (REVERSED) 65.\nI have a regular place set aside for studying.\n70.\nI make sure I keep up with the weekly readings and assignments for this course.\n73.\nI attend class regularly.\n77.\nI often find that I don't spend very much time oi. this course because of other activities. (REVERSEP) 80.\nI rarely find time to review my notes or readings before an exam.\n(REVERSED) Alpha: .76 25 0 I Motivated Strategies for Learning Questio:Lnaire Manual Descriptys Statistics Item II I I I e II I Standard Correlation Mean Deviation with Final Grade 35 5.51 1.53 .2.3 43 4.46 1.65 .26 52 3.73 2.01 .23 65 4.58 2.03 .15 70 4.50 1.91 .12 73 6.49 .98 .17 77 3.89 1.80 .07 80 5.80 1.48 .20 Scale 4.87 1.05 .28 26 Motivated Strategics for Learning Questionnaire Manual Self-regulation also includes students' ability to control their effort and attention in the face of distractions and uninteresting tasks. Effort management is self-management, and reflects a commitment to completing one's study goals, even when there are difficulties or distractions. Effort management is important to academic success because it not only signifies goal commitment, but also regulates the continued use of learning strategies.\nItem 37.\nI often feel so lazy or bored when I study for this class that I quit before I finish what I planned to do. (REVERSED) 48.\nI work hard to do well in this class even if I don't like what we are doing.\n60.\nWhen course work is difficult, I give up or only study the easy parts. (REVERSED) 74.\nEven when course materials are dull and uninteresting, I manage to keep working until I finish.\nAlpha: .69 Descriptive Statistics Item Scale Standard Correlation Mean Deviation with Final Grade 37 4.87 1.73 .15 48 5.26 1.45 .28 60 5.52 1.42 .29 74 5.36 1.47 .23 5.25 1.10 .32 27 Motivated Strategies for Learning Questionnaire Manual Collaborating with one's peers has been found to have positive effects on achievement. Dialogue with peers can help a learner clarify course material and reach insights one may not have attained on one's own.\nItem 34.\nWhen studying for this course, I often try to explain the material to a classmate or a friend.\n45.\nI try to work with other students from this class to complete the course assignments.\n50.\nWhen studying for this course, I often set aside time to discuss the course material with a group of students from the class.\nAlpha: .76 Descriptive Statistics Standard Correlation Mean Deviation with Final Grade Item 34 3.48 1.92 .07 45 2.94 1.97 -.15 50 2.24 1.64 -.07 :kale 2.89 1.53 -.06 28 Motivated Strategies for Learning Questionnaire Manuai Another aspect of the environment that the student must learn to manage is the support of others.\nThis includes both peers and instructors. Good students know when they don't know something and are able to identify someone to provide them with some assistance. There is a large body of research that indicates that peer help, peer tutoring, and individual teacher assistance facilitate student achievement.\nItem 40.\nEven if I have trouble learning the material in this class, I try to do the work on my own, without help from anyune.\n(REVERSED) 58.\nI ask the instructor to clarify concepts I don't understand well.\n68.\nWhen I can't understand the material in this course, I ask another student in this class for help.\n75.\nI try to identify students in this class whom I can ask for help if necessary.\nAlpha: .52 Descriptive Statistics Standard Correlation Mean Deviation wiih Final Grade Item 40 3.26 1.80 -.05 58 4.21 1.89 .24 68 3.73 1.99 -.06 75 4.15 2.00 -.08 Scale 3.84 1.23 .02 29 Motivated Strategies for Learning Questiotutaire Manual -IV. SAMPLE FACE SHEET Motivated Strategies for Learning Questionnaire Manual MOTIVATED STRATEGIES FOR LEARNING QUESTIONNAIRE (MSLQ) National Center for Research to Improve Postsecondary Teaching and Learning (NCRIPTAL) School of Education, The University of Michigan Ann Arbor, Michigan Your instructor is participating in a study of college teaching and learning, in cooperation with the University of Michigan. We would like to ask for your participation in the study.\nAs part of the study, over the course of the semester you will be asked to fill out several questionnaires related to your motivation and learning in this "
      },
      {
        "type": "text",
        "text": "\n\n[OUTPUT TRUNCATED - exceeded 25000 token limit]\n\nThe tool output was truncated. If this MCP server provides pagination or filtering tools, use them to retrieve specific portions of the data. If pagination is not available, inform the user that you are working with truncated output and results may be incomplete."
      }
    ]
  }
]

---

### User
> 11/30/2025, 3:48:30 PM

[
  {
    "tool_use_id": "toolu_01BPoRj46rjw7y9No2yqPqxw",
    "type": "tool_result",
    "content": [
      {
        "type": "text",
        "text": "Detailed Results:\n\nTitle: Rubric for assessing metacognitive reflections - SERC (Carleton)\nURL: https://serc.carleton.edu/details/files/8654.html\nContent: Rubric for metacognitive reflection assessment for Anderson teacher prep activity. File 8654 is a 146kB Acrobat (PDF)\nRaw Content: ![SERC Media](/images/serc/serc_media_banner_2020.png)\n\n[![](https://serc.carleton.edu/images/icons/pdf.gif)](https://cdn.serc.carleton.edu/files/teacherprep/resources/activities/rubric_fall05.pdf) [Rubric for assessing metacognitive reflections](https://cdn.serc.carleton.edu/files/teacherprep/resources/activities/rubric_fall05.pdf)  \nRubric for metacognitive reflection assessment for Anderson teacher prep activity.\n\n![](https://serc.carleton.edu/images/icons/pdf.gif)\n\nFile 8654 is a 146kB Acrobat (PDF)   \nUploaded:\nMay7 07  \nhttps://serc.carleton.edu/download/files/8654/rubric\\_fall05.pdf\n\n![SERC](https://cdn.serc.carleton.edu/images/serc/serc_standard_footer_logo_2020.v3.webp)\n\n### About\n\n### Reuse\n\n[Citing and Terms of Use](https://serc.carleton.edu/serc/terms_of_use.html)\n\nMaterial on this page is offered under a\n[Creative Commons license](https://creativecommons.org/licenses/by-nc-sa/4.0/) unless otherwise noted below.\n\n[Show terms of use for text on this page »](javascript:void(0);)\n\n#### Page Text\n\n[Show terms of use for media on this page »](javascript:void(0);)\n\nTitle: [PDF] The reliability characteristics of the REFLECT rubric for assessing ...\nURL: https://pmejournal.org/articles/239/files/636bb018c9a71.pdf\nContent: Among the most widely published of these is the Reflection Evaluation for Learners' Enhanced. Competencies Tool (REFLECT), which presents a ma-.\n\nTitle: [PDF] A Self-Reflection Rubric for Inclusive Teaching | Vanderbilt University\nURL: https://cdn.vanderbilt.edu/vu-cas/wp-content/uploads/sites/37/2025/08/18204830/Self-Reflection-Rubric-for-Inclusive-Teaching-Bandy-Clayton-2025-V5.pdf\nContent: How to Use the Rubric. 1. As a tool for reflection and formative assessment. We intend it to serve a reflective, formative function in your self-assessment, not.\nRaw Content: preencoded.png A Self-Reflection Rubric for Inclusive Teaching Joe Bandy | joe.bandy@vanderbilt.edu Associate Professor of the Practice in Sociology, Climate & Environmental Studies, and Culture, Advocacy & Leadership at Vanderbilt University Patti H. Clayton | patti.clayton@curricularengagement.com Practitioner-Scholar-in-Residence, NC Campus Engagement and UNC Greensboro Practitioner-Scholar & Consultant, PHC Ventures, Cary, North Carolina Introduction Higher education and K-12 are replete with efforts to better understand and apply the myriad of teaching practices that help educators to become more inclusive, equitable, and accessible while promoting student belonging and empowerment. These efforts encompass a wide array of pedagogies, design principles, and instructional techniques. We henceforth will refer to all of these as \"inclusive teaching,\" taking a very, well, inclusive approach to the many discourses that frame these efforts – from critical pedagogy to more institutionalized models for DEI applied to the classroom. What follows is a document that we hope synthesizes much of the wisdom of these efforts into a rubric for self-reflection and improvement.\nIt is necessary to acknowledge at the outset that rubrics in general can be problematic, since they can be too rigid, linear, vague, incomplete, or otherwise inadequate to the tasks of critical reflection and assessment. We have attempted to overcome these limitations here by being as thorough, clear, and nuanced as we can, yet undoubtedly challenges remain. Therefore, like the work of inclusion and equity itself, we see what follows as a work in process that can adapt to meet the ever-changing challenges of, and inquiry into, inclusive teaching.\nVersion 5.0 | August 2025 Image created using Canva PLEASE CITE: Bandy, Joe and Patti Clayton. 2025. A Self-Reflection Rubric for Inclusive Teaching. Version 5. preencoded.png Structure of the Rubric Regarding its organization, the rubric is structured into four domains of inclusive teaching: beginning with instructor values and core commitments and then the basic labor of course design and teaching practice - course design and learning goals, learning assessment, and lastly, learning experiences and interactions.\nWithin each of these domains we list several teaching orientations or practices, each accompanied by text describing six levels of inclusion: beginning, emergent, deliberate, integrated, engaged with educational systems, and engaged with community and society (see next page). While we have structured the six levels of the rubric to encourage thorough reflection on ways you might extend your inclusive practices, level six does not represent the “best” or “highest” level of achievement. Nor do we intend any implicit judgment if you find yourself at level one. Instructor values and core commitments Course design and learning goals Learning assessment Learning experiences and interactions NOTE: Throughout this document we frequently refer to “instructor.” By \"instructor\" we refer to anyone who shares responsibility for design and implementation of courses, e.g., faculty, graduate instructors, undergraduate educators, staff, community partners, or instructional designers.\n2 preencoded.png Structure of the Rubric All of us start at different places in our journeys to be inclusive educators, and we have unique teaching contexts that may challenge the application of one or more inclusive teaching techniques – institutions, enrollments, courses, and our disciplines’ “signature pedagogies” (Shulman, 2005), just to name a few. These, along with educators’ positions in gender, race, or other social hierarchies, may limit our labor, autonomy, or power to fully embrace inclusive practices. As an example, the fifth and sixth levels of the rubric tend to focus on the co-creation of our courses and instruction with student, institutional, community, or public partners. Their inclusion may not be possible in all teaching contexts and for all educators, and indeed may involve tradeoffs in teaching (more preparation and planning, for example) that one cannot afford at this moment. Yet, we discuss them here since the practice of inclusion is, in principle, an ever-expanding circle that extends beyond our courses to our disciplines, institutions, and communities. While these and other practices of highly inclusive teaching may take considerable time and effort, they do become easier with time and experience, and their benefits for student learning are well documented. Moreover, it is our hope that, with greater co-creative inclusion of all stakeholders and partners across our educational and social systems, we may realize the transformative potential of education for our students, ourselves and our broader society.\nEngaged with Community and Society Engaged with Educational Systems Integrated Deliberate Emergent Beginning 3 preencoded.png How to Use the Rubric 1 As a tool for reflection and formative assessment We intend it to serve a reflective, formative function in your self-assessment, not a summative one as a part of any formal peer or institutional review of your teaching. We hope it will help you to reflect upon where you think your teaching is now and where you might like it to grow.\n2 As a beginning, not an end We hope this is not the end of any data gathering or reflection on your inclusive practices, but merely the beginning, to be supplemented by other inquiry into your teaching such as student evaluations, student performance, peer review, and assessment with a Center for Teaching and Learning as well as other colleagues, stakeholders, or \"critical friends\" (Curry, 2022).\n3 Not as a checkbox activity We do not wish anyone to treat this or any such reflection exercise as merely a check-box activity, after which no further vigilance or self-critique is necessary, since this is likely to be counter-productive. Indeed, the work of inclusion is never finished, and mastery is never perfect among the ever-shifting identities and power relations of our educational and social contexts.\n4 As a collaborative, generative process We do not intend for you to use this in some highly individualized reflection. To be sure, you may begin by using the rubric to prompt your own private and very personal self-reflection, but ultimately, we hope that it will be part of a generative, collaborative engagement with others in your institution, community, and broader society. 5 To consider where your teaching currently is versus where you desire it to be We hope you can use this tool to consider where your teaching is versus where you want it to be. For each practice below, you might make a check next to the level that best represents your current teaching (“current” in the tables below), and a check next to the level that best describes your desired level of practice (“desired”). In this way the rubric can help you to focus attention on developing particular practices. The descriptions of the levels that fall between your current and desired levels can offer some ideas for improvement and spark further investigation and experimentation. 4 preencoded.png Getting Started Where to begin?\nWhile you may start with any domain in the rubric, but we do suggest working through the domains sequentially. This is because the first domains ask you to consider pedagogical orientations and core commitments that are likely to provide a strong foundation that supports multiple areas of teaching, and without which the latter, more practical domains may make less sense. This said, if you have limited time and would rather start with practical skills that help you to find some efficacy before digging deeper, the latter three domains may be the place to begin, and you can return to the first two when you are ready. Take it at your own pace We know the rubric is large and detailed because, we hope, it begins to approximate the difficult and complex work of inclusive teaching. You may choose to focus on one domain at a time. We urge you to work through it at whatever pace is comfortable. Use it to reflect, inquire, experiment, develop, and iterate your courses or instruction over time. Be comfortable with discomfort As you consider the rubric and where you find yourself in it, know that the work of reflecting upon and improving our inclusive practices can be uncomfortable, time-consuming, and frustratingly slow since it can involve confrontations with our own limitations. More, the development of knowledge and skills can be iterative and take time to nurture, following a path that is circuitous, not linear, as we experiment, fail, and improve. Change in inclusive teaching may involve practices and teaching techniques that are visible in the classroom, but it also requires challenging work that often goes unseen – work on our values, our pedagogies, and our institutions. This deep work can provoke discomfort and conflict – whether it is internal or shared - but it also can set us on a path to become more effective and just educators, benefitting our students, colleagues, universities, and communities.\n5 preencoded.png Turning Your Assessment into Action James looks over his responses to each of the practices in this Domain 1: Values and Commitments and finds that he has mixed ratings. For some practices, he rated himself as currently having a deliberate orientation, specifically, his values of inclusion and equity and his efforts to be transparent about his teaching goals and student assignments; and he indicated that, at least for now, his desired status is the same on these 2 practices (i.e., deliberate). For others, however, he rated his current practice as emergent; for instance, he tends to take a deficit-based rather than asset-based orientation to his students’ learning and, relatedly, is somewhat less student-centered in his instruction. For each of these 2 practices, he marked his desired status as integrated, two levels up from his current status. What patterns do you see in your responses? Notes in response: I didn’t mark myself as a beginner on any of the practices. None of my desired statuses are higher than “integrated.” I’m fine where I am on 2 of the practices What do your responses reveal about your current inclusive teaching orientations or strategies, and where do you have room for growth? Notes in response: I’ve got something to build on for each practice - I don’t see myself as beginner on any of them, which surprises me a bit. I don’t need to be too concerned about my values of inclusion and equity or how transparent I am when it comes to my goals and assignments. I’ve got some work to do on some of the practices though: I am too deficit-based in the way I think about students’ learning and also too teacher-centered Prioritize the top 2 to 3 practices in this domain that you would like to investigate and improve. Notes in response: The ones that I ranked farthest apart: deficit-based rather than asset-based orientation to students’ learning and teacher-centered rather than student-centered instruction What concrete steps might you like to take to grow toward where you want to be in these 2 or 3 priority practices? Notes in response: Consult with the Center for Teaching and Learning to get a list of readings and delve into them to learn about the philosophies and practicalities of student-centered approaches. Meet with Juan and Sandra in my department who are known to take more asset-oriented and student-centered approaches; ask what motivated them and how they implement these approaches in their daily teaching practices Each of the four domains below concludes with an “Action Assessment,” a set of 4 prompts to help you traverse the gap between where your teaching currently is and where you would like it to be. The following example scenario might elicit the italicized responses to the 4 prompts.\nExample Scenario 6 Example Action Assessment Responses preencoded.png Example 1: A New Faculty Member's Journey A new faculty member at a research-intensive institution of higher education who has limited experience and no formal training in teaching. He is asked by his chair to teach an introductory course of nearly 100 students. He is excited to get into the classroom and to share his knowledge and passion for his discipline with all his students, and he wants all of them to feel welcome in his classroom and capable of succeeding.\nThat said, his experience as a student in a heavily enrolled, technical field means he has seen a lot of courses with extensive lecturing and limited student collaboration, and assessment focused on high-stakes multiple choice tests. Midway through his course, after implementing this familiar teaching model, he notices some of his students – predominantly but not always women and people of color – are less participatory in Q&A and have consistently lower grades than their male and white counterparts. As an instructor in a gateway course to his major, he wants to address this inequality and ensure that all students, regardless of background or identity, have the same opportunity to succeed. He decided to take the following steps: Initial Assessment When he works through this rubric, he finds that his teaching orientation and practices fit most cleanly within the beginning or emergent categories, since, despite his deep commitment to inclusion and some deliberate or integrated practices he intuited, he simply has not had much professional development in teaching.\nPlanning for Change He therefore uses the rubric in combination with a thorough assessment of his students' work, their evaluations, and consultations with his Center for Teaching and Learning to develop a plan for implementing small changes in his teaching that would make the largest impacts.\nImplementation He implements more collaborative and active learning in class, mandatory study groups for all students, and an assessment strategy that entails more low-stakes formative assessments with supportive feedback.\nLong-term Growth After years of teaching, there is no longer any evidence of opportunity gaps among his students, and there is consistently high student engagement and success in his classes. He continues to use the rubric to reflect on his teaching and finds that he now identifies more with the integrated and engaged levels.\n7 preencoded.png Example 2: A Graduate Instructor's Experience A graduate instructor in a history department typically structures her seminar classes around participatory, student-centered analyses of historical events such as segregation and its contemporary legacies. She engages students in discussions about the history of segregation and its lived, human experience, particularly those related to structures of housing and schooling, and what impacts it has had on urban systems today.\nShe has spent much of her professional career developing an interdisciplinary understanding of social histories of racial inequality for multiple groups and is herself someone who has experienced marginalization due to her race and gender. Therefore, she feels committed and well-equipped to teach inclusively and empower students, regardless of background, to be thoughtful advocates for equality and to dismantle systems of oppression.\nHowever, despite her commitments to the critical study of difference and inequality, she feels she has a hard time connecting with her students. Sure, her students learn many social histories and theories of inequality and seem empathetic with the experiences of marginalized groups, but engagement is limited.\nFor instance, in discussing racial injustices, her white students can either be quietly deferential to her or their peers of color, or engage merely at an intellectual level around theory and history, rarely venturing into the course's implications for their own personal identity, emotions, or ethics. Meanwhile, students of color display personal interest in the learning goals, but at times will remain on the sidelines of the discussion, possibly (she speculates) due to trauma, \"battle fatigue\" educating white peers, or simply the limited depth of race discussions at a predominantly white institution.\nShe also wonders if she is part of the problem since she may tend to select less motivating lesson plans and she might be able to do more to build trust in the classroom, especially given she has less experience. She is frustrated since she puts a lot of work into her teaching and truly wants to empower her students to be good thinkers and citizens, but there is something missing.\nCredit: Eric Haynes, The Oracle 8 preencoded.png Example 2: A Graduate Instructor's Experience (continued) Therefore, she turns to this rubric and finds that she identifies her teaching orientation and practices as deliberate or integrated. Intentionally integrating these assignments into in-class dialogues with students she hopes will empower them to engage more deeply and holistically about social inequalities and how we confront them in our private and public lives. She even experiments with community engagement, helping students develop community partnerships with local racial justice organizations working on housing, reorganizing entire units to better inform students with critical knowledge about issues, methods, and ethics.\nShe implements these changes as she feels comfortable, and experiences challenges as she cedes some power to her students and community partners, while ensuring mutually beneficial pursuit of learning goals and community development. Nonetheless, after implementing these changes, she finds students to be much more motivated, engaged, and to develop far more trust in their peers and her, discussing the subject matter in a way that involves greater personalization, vulnerability, criticality, and public purpose.\nThese are only two hypothetical examples of instructors who use this rubric in very different contexts to reflect upon, experiment, and improve – never perfect – their teaching. As you use the rubric, you, like them, may experience this work to be uncomfortable, painstaking, and slow, but know that even small changes can set you on a path to make meaningful differences in your students' learning and bring greater success and joy to your teaching. We hope this rubric can be of some help along the way.\nYet, in reading through the rubric's themes of co-creation she sees that there may be opportunities to learn more about, and motivate, her students by being more student-centered and by engaging them in collaborative dialogues that redefine course goals, assignments, and learning experiences. She sees ways she can co-construct class cultural commitments and principles for addressing potential conflict that would raise the level of trust and belonging in class. Lastly, she sees ways she might help students to personalize course content in written assignments that tie readings to personal experiences, identities, attitudes, well-being, and ethics.\nInitial Assessment Planning for Change Implementation and Growth 9 preencoded.png Acknowledgements We would like to express our deepest gratitude for the keen and generative insights of many kind colleagues who have provided constructive critiques of the earliest versions of this rubric, including (in alphabetical order) Anna Bartel, Wesley Bishop, Laura Carter-Stone, Karen Enyedy, Emily Hall, Jackie Hansom, Kristy Howell, Stacey Johnson, Melissa Mallon, Janice McMillan, Julia Metzker, Cheryl Siemers, Sarah Stanlick, LaShawnda Crowe Storm, Jade Vergara, Meredyth Wegener, and Michelle Young.\nWe also wish to acknowledge the dozens of participants at several conferences in 2023 who offered their reflections on its usefulness and improvements – the Pathways to Achieving Civic Engagement (PACE) conference, the Elon Conference on Engaged Learning, and the International Association for Research in Service Learning and Community Engagement (IARSLCE) meetings. All of these amazing collaborators have added their voices to the spirit and letter of this effort, helping it to become what you see here. We are grateful to have everyone of them, and you, as colleagues and fellow travelers in this challenging work and we encourage you to connect with us if you see ways to further its growth. - Joe Bandy (joe.bandy@vanderbilt.edu) and Patti H. Clayton (patti.clayton@curricularengagement.com) 10 preencoded.png Table of Contents Domain 1: Values and Core Commitments • Inclusion and equity • Personalization • Transparency • Student-centeredness • Supporting Student self-efficacy • Growth orientation • Asset orientation • Accessibility Domain 2: Learning Goals • Knowledge goals • Skill goals • Value goals • Social and emotional goals Domain 3: Learning Assessment • Rigor • Diversity of assignments • Scaffolding • Examinations • Feedback • Grading • Course and teaching assessment Domain 4: Learning Experiences and Interactions • Class norms • Sources of knowledge • Supporting students who struggle • Communication with students • Inclusive facilitation • Engagement with difference via culturally responsive teaching • Supporting belonging and community 11 Domain 1: Values & Core Commitments Inclusion and equity What do I see as the importance of inclusion, equity, belonging, and accessibility in education and in society?\nWhat is my understanding of the research on inclusive teaching and its impacts on teaching and learning?\nWhat is my commitment to inclusion in teaching and learning, in educational institutions, in my society?\nHere, we focus on foundational commitments. Stay focused on your educational values and how they affect inclusion, access, equity, and belonging across all phases of your students’ learning.\nCurrent Desired Beginning I view inclusion and equity as relevant to teaching and learning but have many uncertainties about the research or the practice.\nEmergent I have an emergent understanding of the evidence and importance of inclusion and equity in teaching and learning and how they may be incorporated into my teaching practice.\nDeliberate I am committed to the benefits and ideals of inclusion and equity and to developing related competencies and practices in teaching and learning.\nIntegrated I am committed to inclusion and equity as both means and ends in teaching and learning, and to honing instructional practices via scholarship to center equity concerns throughout multiple areas of teaching, from design to implementation to assessment.\nEngaged with educational systems I challenge educational systems that render concerns regarding inclusion and equity invisible or that contribute to systemic inequities, and I seek to root inclusion and equity throughout the curriculum and the institution.\nEngaged with community and society I challenge educational and social systems that render concerns regarding inclusion and equity invisible or that contribute to systemic inequities, and I seek to realize inclusion and equity throughout the institution, my discipline, and in society more broadly.\n12 Domain 1: Values & Core Commitments Personalization How do I help my students to make the course material and assignments more personally meaningful?\nHow do I help my students to see their own experiences and histories as relevant in my courses?\nCurrent Desired Beginning Students have limited opportunities to personalize goals, assessment, or learning experiences (e.g., examples in class discussions), minimizing the possibility for students to make the course relevant to their own interests, values, and lives.\nEmergent Students have some opportunities to personalize goals, assessment, or learning experiences via instructor-defined choices (e.g., of topics for class dialogue, writing assignments, or optional test questions).\nDeliberate Students are encouraged to seize opportunities for the personalization of goals, assessment, or learning experiences via a mixture of instructor-defined and open-ended choices (e.g., for both the topic and format of discussions, writing assignments, testing, and culminating projects).\nIntegrated Students have a high number of opportunities for the personalization of goals, assessment, or learning experiences, reflecting their interests or lives, and additionally they contribute to the course instruction (e.g., peer review of assignments or student-led discussions).\nEngaged with educational systems Students fully design and conduct the course in collaboration with me via a constructivist model, co-creating goals, assignments, and learning experiences that are empowering for their personal, professional, and academic development and co-leading lesson plans and learning assessments.\nEngaged with community and society Students have all the previous opportunities and support and are encouraged to develop goals, assessment, and learning experiences with me, peers, and community members who co-create new knowledge and contribute to social change.\n13 Domain 1: Values & Core Commitments Transparency How can I be as clear as possible in the goals, methods, criteria, and evaluation of my course?\nHow can I support my students’ self-efficacy in navigating the requirements of the course? Current Desired Beginning Minimal explanations of teaching philosophies, goals, methods, criteria of assessment, what students will need to do to succeed, and instead limiting communications to brief evaluations of student work.\nEmergent Some explanation of teaching philosophies, goals (e.g., general introductions), methods, criteria of assessment (e.g., general assignments listed in the syllabus), what students will need to do to succeed, or evaluations of student work.\nDeliberate A moderate amount of explanation of teaching philosophies, goals, and methods (e.g., syllabus statements, policies), what students will need to do to succeed (e.g., handouts on assignments), what criteria will be used to assess student learning (e.g., basic rubrics), and evaluations of student work with significant feedback.\nIntegrated A high level of transparency about teaching philosophies, goals, methods (e.g., providing teaching statements and regular discussions about the purpose and function of activities and assignments), what students will need to do to succeed (e.g., handouts and strategies for skill development), what criteria will be used to assess student learning (e.g., elaborate rubrics and models), and evaluations of student work (e.g., extensive feedback).\nEngaged with educational systems Full transparency through collaborative construction of teaching methods (e.g., students and I collaborate on devising collaborative teaching & learning), assignments (e.g., student co-creation of assignments), and criteria for assessment of student learning (e.g., student- and instructor-generated rubrics for assessment), and evaluations of student work.\nEngaged with community and society Full transparency through collaborative construction of teaching philosophies, goals, methods (e.g., students, instructor, and community members collaborate on devising collaborative teaching & learning), assignments (e.g., student, instructor, and community member co-creation of assignments), criteria for assessment of student learning (e.g., student-, instructor-, and community member generated rubrics for assessment), and evaluations of student work.\n14 Domain 1: Values & Core Commitments Student-centeredness To what degree do I orient and calibrate my instruction to students’ existing interests, experience, and skills?\nHow might I more accurately and collaboratively incorporate students’ experience, knowledge, and skills in the development of course goals, learning experiences, and assessment? Current Desired Beginning Minimal attention to students’ experience, knowledge, skills, interests, and identities in the development of course goals, assessment, and learning experiences, other than general age and prerequisites.\nEmergent Some general effort to learn about students’ prior experience, knowledge, skills, interests, and identities (e.g., via course roster information such as majors and year) and to calibrate the difficulty and progression of course goals, assessment, and learning experiences.\nDeliberate Moderate attention to learn students’ prior experience, knowledge, skills, interests, and identities (e.g., via pre-course surveys, personal dialogues, office hour discussions) and to use it to empower their participation in some aspects of developing course goals, assessment, and learning experiences.\nIntegrated Thoroughgoing efforts to incorporate students’ prior experience, knowledge, skills, interests, and identities to empower their participation in most aspects of developing course goals, assessment, and learning experiences.\nEngaged with educational systems All students’ prior experience, knowledge, skills, interests, and identities inform the co-construction of course goals, assessment, and learning experiences by myself and students.\nEngaged with community and society All students’ prior experience, knowledge, skills, interests, and identities, as well as those of community members, inform the co-construction of course goals, assessment, and learning experiences by myself, students, and community members.\n15 Domain 1: Values & Core Commitments Supporting Student Self-efficacy How might I maximize students’ self-efficacy in navigating the content and requirements of my courses?\nHow might I empower students’ self-efficacy in navigating their education and a broader social world? Current Desired Beginning Limited efforts to encourage student self-efficacy, except that achieved by general growth in knowledge and skills via course completion.\nEmergent Some efforts to encourage students and offer some scaffolding of learning experiences to promote growing confidence and ability.\nDeliberate Some efforts to encourage students and offer some scaffolding of learning experiences to promote growing confidence and ability, and more formative, consistent, timely evaluations to support knowledge and skill development and self-awareness about areas for improvement.\nIntegrated Previous row + student-directed learning goals and peer education/mentorship to develop capacities for metacognition, self-knowledge, and growth opportunities.\nEngaged with educational systems Previous row + learning experiences that support students’ holistic development of social, career, ethical, and other knowledge, skills, and attitudes.\nEngaged with community and society Previous row + students’ holistic development also oriented toward public citizenship and social change work.\n16 Domain 1: Values & Core Commitments Growth Orientation To what extent do I value and support my own and my students’ growth? Do I see my or my students’ growth holistically, involving intellectual, ethical, social, and emotional growth?\nHow do I support my own and my students’ growth as part of a broader institutional or social change process? Current Desired Beginning I do not see my own identity or growth as an instructor at stake in teaching and learning, beyond general professional productivity and a deepening of disciplinary knowledge.\nEmergent I recognize that teaching can stimulate my own ongoing self-understanding, at least as an educator, in addition to intellectual growth.\nDeliberate I seek to develop some knowledge, skills, and self-awareness through teaching, not just as an educator but as a whole person.\nIntegrated I value my own identity and growth, as an educator and as a whole person, as equally important to students’ growth.\nEngaged with educational systems I value my own holistic growth and that of students as interdependent and as part of the maturation of the institution that makes human flourishing available to all members of the campus community.\nEngaged with community and society I value my own holistic growth, that of students, and that of community members as interdependent and as part of the maturation of both institutional systems and social systems that make human flourishing available to all.\n17 Domain 1: Values & Core Commitments Asset Orientation Do I tend to think of my students more in terms of what they need/lack or in terms of what they bring/have?\nWhat knowledge and skills do my students need, and what assets do they bring to the learning process?\nHow might I understand and internalize asset-based ways of teaching? Current Desired Beginning My orientation to students tends to be deficit-based (explicitly defining students in terms of what they do not know and cannot do), possibly reflecting institutional or social biases.\nEmergent My orientation to students is somewhat deficit-based (attending mostly to what students do not know and cannot do) and somewhat asset-based (acknowledging what students do know and can do).\nDeliberate My orientation to students is largely asset-based (acknowledging what students do know and can do, with some incorporation of active and collaborative learning).\nIntegrated My orientation to students is thoroughly asset-based (defining students in terms of what they know and can do; supporting students in actively using and developing their strengths, and realizing this through collaborative, active learning models).\nEngaged with educational systems I internalize asset-based ways of thinking and being throughout all domains of my work as an educator and as a member of the campus community (beyond teaching and learning), challenging deficit-based ways of thinking and being throughout the institution.\nEngaged with community and society I internalize asset-based ways of thinking and being throughout all domains of my work as a member of the campus community (beyond teaching and learning) and a member of broader communities, challenging deficit-based ways of thinking throughout the institution and throughout society.\n18 Domain 1: Values & Core Commitments Accessibility How can I ensure all course materials, communications, activities, and assignments are accessible to all students, regardless of their cognitive or physical abilities?\nHow can I ensure that students have multiple ways to access materials, to engage course content, and to express themselves fully?\nHow might greater accessibility for any one student group enhance accessibility for others? Current Desired Beginning Course materials, communications, activities, and assignments are accessible but in only one format or method determined solely by me and potentially not readily accessible by some or many students.\nEmergent Course materials, communications, activities, and assignments are accessible in more than one format or method determined by me and in compliance with required accommodations of some students.\nDeliberate Course materials, communications, activities, and assignments are accessible in more than one format or method, informed by me and by recommendations of disability services offices.\nIntegrated Course materials, communications, activities, and assignments are accessible in multiple formats and methods, determined by me and by recommendations of disability services offices as well as students together considering students’ particular opportunities and challenges.\nEngaged with educational systems Course materials, communications, activities, and assignments are accessible in multiple formats and methods, determined by students, myself, and campus offices together to ensure access for all.\nEngaged with community and society Course materials, communications, activities, and assignments are accessible in multiple formats and methods, determined by students, myself, campus offices, and community members together to ensure access for all and to further accessibility throughout society.\n19 Domain 1: Values & Core Commitments Action Assessment Now that you have completed this domain, take a look at your responses to the domain’s questions above.\nWhat patterns do you see in your responses? (For example, do you tend to rate your current teaching practices at the same level, or are they varied? On which practices are your current and desired ratings the closest? The farthest apart?) What do your responses reveal about your current inclusive teaching orientations or strategies, and where do you have room for growth?\nPrioritize the top 2 to 3 practices in this domain that you would like to investigate and improve.\n(Note: You might select a particular practice because your current and desired responses are the farthest apart, revealing a significant area for growth. Conversely, you might focus on a practice for which your current and desired responses are close, perhaps making it easier to see change in the short term [i.e., “low hanging fruit”]. Remember there is no right or wrong choice and you can always come back later to focus on the others.) What concrete steps might you like to take to grow toward where you want to be in these 2 or 3 priority practices? (Note: You will find it most helpful if these concrete steps are relevant, specific, and achievable.) 20 Domain 2: Learning Goals Knowledge Goals How can I make the knowledge goals more explicit, developed, achievable, accessible, measurable, assessed, and supported?\nHow can I ensure the knowledge goals are relevant to students and my discipline, and promote deep learning?\nHow can I develop knowledge goals that empower students to understand and expand the epistemic diversity of the subject matter? In this domain, we ask you to consider learning goals, the basis of inclusive course design. Stay focused on your and your students’ growth opportunities.\nCurrent Desired Beginning Knowledge goals are only implied in course content, not explicit.\nEmergent Knowledge goals are explicit but may be general, underdeveloped, unachievable, inaccessible, unmeasurable, unassessed, and centered upon me, disciplinary coverage, or basic student comprehension and application goals.\nDeliberate Knowledge goals are more specific, clear, achievable, accessible, measurable, assessed, and somewhat focused upon deeper learning (e.g., analysis or critique), upon student interests and needs, and upon diverse content (e.g., authors, guest speakers, examples from diverse perspectives).\nIntegrated Knowledge goals are co-created with students to be highly specific, clear, achievable, accessible, measurable, and assessed; they are focused upon deep learning (synthesis, innovation, knowledge creation), upon student interests and needs, and upon diverse content that empower students’ critical understandings of the epistemic diversity of the subject matter.\nEngaged with educational systems Knowledge goals are co-created with students and other institutional partners to be highly specific, clear, achievable, accessible, measurable, and assessed; they thoroughly promote deep learning; they meet student and my own interests and needs; they empower students’ and my own understanding; and they expand the epistemic diversity of the subject matter.\nEngaged with community and society Knowledge goals are co-created with students, institutional, and public/community stakeholders to be highly specific, clear, achievable, accessible, measurable, and assessed; they thoroughly promote deep learning; they meet student, my own, and public interests and needs; they empower students’, my own, and all stakeholders to understand and expand the epistemic diversity of the subject matter.\n21 Domain 2: Learning Goals Skills Goals How can I make the course’s skills goals more explicit, developed, achievable, accessible, measurable, assessed, and supported?\nHow can I incorporate skills goals that empower, not merely academic or career success but also social, leadership, and citizenship development? Current Desired Beginning Skills goals (e.g., writing, quantitative reasoning, inquiry, study or learning habits, technology proficiencies) are only implied in course assignments, not explicit.\nEmergent Skills goals are explicit but may be general, unclear, underdeveloped, unachievable, inaccessible, unmeasurable, unassessed, and under-supported by me and/or campus resources.\nDeliberate Skills goals are more specific, clear, developed, achievable, accessible, measurable, assessed, and supported by me or campus support offices (e.g., writing & tutoring centers, librarians, technology centers, career centers, etc.) to help students develop foundational capacities for academic and career success.\nIntegrated Skills goals are highly specific, clear, developed, achievable. accessible, measurable, assessed, and supported by me and campus support offices to help students succeed and find greater autonomy in developing the capacities and habits for academic, career, and life success.\nEngaged with educational systems Skills goals are highly specific, clear, developed, achievable, accessible, measurable, assessed, supported, and co-constructed with students and institutional stakeholders; they empower students and me to succeed and find autonomy via self- and peer-support and to develop academic, career, life, and citizenship skills (e.g., inclusive and equitable leadership within the class or institution).\nEngaged with community and society Skills goals are highly specific, clear, developed, achievable, accessible, measurable, assessed, supported, and co-constructed with students, institutional stakeholders, and community/public interests; they empower students and all stakeholders in developing academic, career, life, and citizenship skills to advance collective interests.\n22 Domain 2: Learning Goals Values Goals How can the values goals be more explicit, developed, achievable, accessible, measurable, assessed, and supported?\nHow can I develop value goals that enhance students’ ethical self-awareness, professional practice, and capacities for leadership and social change work? Current Desired Beginning Values goals (e.g., maturation through moral or ethical self-awareness, integrity, integration of personal and professional or public ethics) are only implied in course assignments, not explicit.\nEmergent Values goals are explicit but may be general, unclear, underdeveloped, unachievable, inaccessible, unassessed, and under supported by me and/or campus resources.\nDeliberate Values goals are more specific, clear, developed, achievable, accessible, assessed, and supported by me or campus offices around common broad ideals (e.g., academic integrity, civility, and inclusion).\nIntegrated Values goals are highly specific, clear, achievable, accessible, measurable, assessed, and supported by me and campus offices and there is intentional, critical inquiry or dialogue about relevant academic and professional ethics and opportunities for greater student moral/ethical self-awareness.\nEngaged with educational systems Values goals are co-constructed with students and other institutional stakeholders; they are highly specific, clear, achievable, accessible, measurable, assessed, and supported by critical inquiry and application of relevant academic and professional ethics as well as by opportunities for moral and ethical growth for students and me.\nEngaged with community and society Values goals are co-constructed with students as well as other institutional and community stakeholders to ensure that they are highly specific, clear, achievable, accessible, measurable, assessed, and supported by critical inquiry and application of relevant academic, professional, and social ethics as well as by opportunities for moral and ethical growth for all.\n23 Domain 2: Learning Goals Social and Emotional Goals How can the course’s social and emotional goals be more explicit, developed, achievable, accessible, measurable, assessed, and supported?\nHow can I better develop social and emotional goals that enhance students’ self-awareness, well-being, connectedness, cultural competence, conflict resolution, and social development? Current Desired Beginning Social and emotional goals (e.g., maturation of emotional self-awareness, emotional intelligence, empathy, cultural competencies of living in diverse communities, compassion, relationship building, conflict transformation, etc.) may be absent or merely implicit.\nEmergent Social and emotional goals are explicit but may be general, unclear, underdeveloped, unachievable, inaccessible, unassessed, and under supported by me and/or campus resources.\nDeliberate Social and emotional goals are more specific, clear, developed, achievable, accessible, assessed, and supported by me or campus offices around common broad ideals (e.g., self-awareness, cultural competence, conflict resolution).\nIntegrated Social and emotional goals are highly specific, clear, achievable, accessible, measurable, assessed, and supported by me and campus offices around common broad ideals (e.g., self-awareness, cultural competence, conflict resolution). There is an intentional, holistic understanding of the interdependencies of social-emotional and cognitive development, permitting inquiry and debate around affective and social skills or philosophies, attention to student well-being, and opportunities for greater student self-awareness and growth.\nEngaged with educational systems Social and emotional goals are co-created with students and other institutional stakeholders to ensure that they are highly specific, clear, achievable, accessible, measurable, assessed, and supported by faculty and campus offices. There is a holistic, integrative, and critical inquiry into social-emotional learning, presenting opportunities for greater student and instructor self-awareness and growth, attention to instructor and student well-being, and developing social-emotional skills necessary for navigating the complexities of campus and social life.\nEngaged with community and society Social and emotional goals are co-created with students and other institutional and community stakeholders to ensure that they are highly specific, clear, achievable, accessible, measurable, assessed, and supported by all. There is a holistic, integrative, and critical inquiry into social-emotional learning, presenting opportunities for greater self-awareness and growth for all, attention to collective well-being, and developing social-emotional skills necessary for navigating the complexities of campus and social life as well as community and public life.\n24 Domain 2: Learning Goals Action Assessment Now that you have completed this domain, take a look at your responses to the domain’s questions above.\nWhat patterns do you see in your responses? (For example, do you tend to rate your current teaching practices at the same level, or are they varied? On which practices are your current and desired ratings the closest? The farthest apart?) What do your responses reveal about your current inclusive teaching orientations or strategies, and where do you have room for growth?\nPrioritize the top 2 to 3 practices in this domain that you would like to investigate and improve.\n(Note: You might select a particular practice because your current and desired responses are the farthest apart, revealing a significant area for growth. Conversely, you might focus on a practice for which your current and desired responses are close, perhaps making it easier to see change in the short term [i.e., “low hanging fruit”]. Remember there is no right or wrong choice and you can always come back later to focus on the others.) What concrete steps might you like to take to grow toward where you want to be in these 2 or 3 priority practices? (Note: You will find it most helpful if these concrete steps are relevant, specific, and achievable.) 25 Domain 3: Learning Assessment Rigor How can I define rigor in clear, transparent forms for students and calibrate it to the appropriate level for my students’ ages and experience?\nHow can I be sure not to confuse higher order learning with high logistical difficulty or workload?\nHow can I take an asset-based approach to assessing and supporting student learning and well-being? Now, we turn to assessment, a focal point of all accessibility and equity in teaching. Attend to how your assessments are engaging, fair, and rigorous while promoting self-efficacy, metacognition, and meaningful growth for all learners.\nCurrent Desired Beginning Presumed or limited definition of rigor, leading to poor measurement (e.g., I see failing grades as evidence of rigor); an effort to make assignments difficult without purpose or clarity, leading to conflation of higher order learning with high workloads; and a deficit approach to student knowledge, possibly due to “survivor bias” (i.e., if I survived this education, students can too).\nEmergent Some definition of rigor, with some transparency and connection to learning goals; some development of a distinction between higher order learning and high workloads; somewhat less deficit-based with a more asset-based approach to student knowledge evident in, for example, greater student autonomy.\nDeliberate Moderate clarity in the definition of, and transparency about, rigor appropriate to the learning goals and teaching context (i.e., prior student experiences, a course’s purpose in the curriculum); moderate recognition of the distinction between higher order learning and workload, with some scaffolding of learning; asset-based approach to student knowledge, with some effort to support student learning and well-being.\nIntegrated High degree of clarity in the definition of rigor and full transparency about its connection to learning goals defined in part through collaboration with students; very clear distinction between higher order learning and workload, with scaffolded support for student learning; dedicated asset-based approach to student knowledge with extensive support for student learning and well-being.\nEngaged with educational systems High degree of clarity in the definition of rigor and full transparency through a co-construction of learning goals and assessment strategies with students and institutional stakeholders (e.g., departments, schools, student affairs); very clear distinction between higher order learning and workload, with scaffolding and assessment processes collaboratively defined with students and other institutional stakeholders; thorough asset based orientation via the institutional co-construction of assessment goals and processes, attentive to student autonomy, self-efficacy, and well-being, with campus support offices as resources (e.g., writing centers, tutoring, mental health resources).\nEngaged with community and society High degree of clarity in the definition of rigor and full transparency through a co-construction of learning goals and assessment strategies with students and other course stakeholders institutionally and in the community (e.g., community partners); very clear distinction between higher order learning and workload, with scaffolding and assessment processes collaboratively defined with students, institutional stakeholders, and community partners; thorough asset-based orientation via the institutional and community-centered co-construction of assessment goals and processes, attentive to collective, shared autonomy, efficacy, and well-being. 26 Domain 3: Learning Assessment Diversity of Assignments How can I offer a diversity of assignments, formative and summative, that assess a wide range of learning goals?\nHow can I offer assessments that are accessible to, and encourage engagement of, a diversity of students?\nHow can I support collaborative assessment with students that ensures meaningful and holistic learning? Current Desired Beginning A small number and low diversity of high-stakes, summative assignments that assess a limited range of student learning goals. Assignments may also suffer from limitations of accessibility, flexibility, and opportunities for higher order learning (e.g., synthesis, creativity).\nEmergent Some diversity of assignments with somewhat greater quantity and form of assignments (e.g., more formative assignments), with some accessibility (e.g., clearer guidance on multiple platforms), flexibility (e.g., more than one testing format), and opportunities for higher order learning.\nDeliberate Moderate diversity of assignments with significantly greater quantity and form of assignments (e.g., multiple types/genres of writing), with more accessibility (e.g., written and oral assessment), flexibility (e.g., more autonomy in selection of assessment options), and opportunities for higher order learning (e.g., creative writing or multimedia reports).\nIntegrated High diversity of assignments with high quantity and multiple forms of assignments (e.g., collaborative assignment design with students), high accessibility (e.g., all learning goals and assessment criteria are easily available), flexibility (e.g., more thorough personalization), and opportunities for higher order learning (e.g., portfolios with multiple analytical, synthetic, and creative components).\nEngaged with educational systems Assignments designed in collaboration with students to ensure a high diversity of assignments in multiple forms with high accessibility, flexibility, and opportunities for meaningful higher order learning, including more opportunities for self- and peer-assessment, metacognition, and holistic reflection on individual or shared learning (academic personal, ethical, professional, leadership).\nEngaged with community and society Assignments designed in collaboration with students and community partners to ensure a high diversity of assignments in multiple forms with high accessibility, flexibility, and opportunities for meaningful higher order learning, including more opportunities for self- and peer-assessment, metacognition, and holistic reflection on social learning (academic, personal, ethical, professional, and citizenship capacities).\n27 Domain 3: Learning Assessment Scaffolding How can I build an assessment strategy that introduces greater complexity, difficulty, and autonomy?\nHow can I support the gradual growth of student confidence and self-efficacy in the learning process? Current Desired Beginning Limited scaffolding of assignment difficulty or complexity.\nEmergent Some scaffolding across assignments throughout the semester, with some gradual introduction of more difficult or complex concepts or tasks towards somewhat clear learning goals.\nDeliberate Moderate scaffolding within and across assignments explicitly designed to help students develop knowledge and skills via more complex tasks, achieve clearly defined learning goals, grow in confidence and self-efficacy, as well as lead to smaller performance and persistence gaps Integrated High degree of scaffolding within and across assignments designed to empower students to become confident, self-directed, and autonomous learners with clear learning goals and processes for reaching them.\nEngaged with educational systems Consistent, well-developed scaffolding designed in collaboration with students to ensure growth within and across assignments that empowers learning via confidence, self-direction, autonomy, clear goals, and self- and peer-assessment.\nEngaged with community and society Consistent, well-developed scaffolding designed in collaboration with students and community partners to ensure growth within and across assignments that empowers mutual growth towards clear learning goals for all stakeholders.\n28 Domain 3: Learning Assessment Examinations How can I evaluate students fairly?\nHow can examination processes provide students with needed support?\nHow can examination processes best be designed to enable students’ ongoing learning and growth? Current Desired Beginning High-stakes examination process only, designed solely by me/department/school/external organization without formative or preparatory testing, including complexities that may be too advanced to “weed out” less prepared students.\nEmergent High-stakes examination process only, designed solely by me/department/school/external organization but in a form that fairly tests students’ knowledge, prepares them with study sessions or guides, and is designed to support students in their learning process.\nDeliberate A mixture of low-stakes and high-stakes examination processes that fairly test students, prepare them with practice exercises and examinations, and both identify student challenges and support their efforts to meet them.\nIntegrated A process with a higher number of low-stakes examinations combined with high-stakes examinations, each with preparatory exercises or guides and each including student-generated questions; response options that allow students to explain their responses.\nEngaged with educational systems Examination processes that draw from student-generated questions and allow for students to explain and, later, reflect on and correct their answers (perhaps for partial credit); may include self- or peer- assessment; may include personalized learning goals and plans constructed in collaboration with instructor(s), departments, or schools.\nEngaged with community and society Examination processes that draw their design from a collaboration of me, students, and community partners, include preparatory exercises and guides and allow students to explain, reflect upon, and correct their answers; may include self- or peer-assessment; may include personalized learning goals and plans constructed in collaboration with institutional and community partners. 29 Domain 3: Learning Assessment Feedback How can I develop and share criteria for evaluation in ways that empower students to succeed?\nHow can I communicate feedback in the most frequent, thorough, meaningful, and timely process for my teaching context?\nHow can I create collaborative feedback processes that support student metacognition, empowerment, and success? Current Desired Beginning Little feedback, not frequent, meaningful, or timely; may be limited to grades.\nEmergent Some meaningful, frequent, and timely feedback, including some clear criteria for assessment and rationale for evaluations and grades.\nDeliberate Moderately meaningful, frequent, and timely feedback, including clear criteria and rationale for evaluations and grades (e.g., rubrics) that entails affirmation, critique, and resources or strategies for improvement.\nIntegrated High degree of meaningful, frequent, and timely feedback, including clear criteria and rationale for evaluations and grades (e.g., rubrics and models) that entails affirmation, critique, resources, strategies for improvement as well as possibilities for revision and retesting.\nEngaged with educational systems High degree of meaningful, frequent, and timely feedback designed in collaboration with students, including co-created processes of assessment and evaluation; includes clear criteria, self- and peer assessment, shared resources, and strategies for improvement as well as possibilities for revision and retesting.\nEngaged with community and society High degree of meaningful, frequent, and timely feedback designed in collaboration with students and community stakeholders, including co-created processes of assessment and evaluation; includes clear criteria, self- and peer and community assessment, shared resources, and strategies for improvement as well as possibilities for revision and retesting.\n30 Domain 3: Learning Assessment Grading How can I ensure that qualitative evaluation, not grades, are the focal point of student learning?\nHow can I support students' understanding of and contributions to evaluation to support metacognition and engagement in the learning process? How can I ensure grades are not an obstacle to student learning and growth? Current Desired Beginning Grades represent the only form of communication about student performance, leading to less guidance, grade fixation, limited learning and performance, and persistence gaps.\nEmergent Grades are the most important form of communication but are accompanied by some qualitative assessment of student performance according to somewhat clear learning goals and criteria for performance.\nDeliberate Grades are moderately important but accompanied by moderate qualitative assessment of student performance according to moderately clear learning goals and criteria for performance.\nIntegrated Grades are less important than thorough qualitative assessment of student performance according to well-developed learning goals and criteria for student performance.\nEngaged with educational systems Grading has minimal importance (e.g., final marks for transcript only) as defined by an assessment strategy designed in collaboration with students to provide thorough qualitative assessment, self- and peer-evaluation, and clear goals and criteria for student performance.\nEngaged with community and society Grading has minimal importance (e.g., final marks for transcript only) as defined by an assessment strategy designed in collaboration with students and community partners to provide thorough qualitative assessment; self-, peer-, and community partner-evaluation; and clear goals and criteria for student performance and shared learning.\n31 Domain 3: Learning Assessment Course and Teaching Assessment How can I best learn how to improve my course and my teaching?\nWho can I best engage with to improve my course and my teaching?\nHow can I inquire with others via scholarship of teaching and learning to study and improve my own and others’ teaching processes? Current Desired Beginning Course/teaching assessment is limited to institutional student evaluations of teaching, with minimal or inconsistent application of the results to future improvements.\nEmergent There is some course/teaching assessment (e.g., institutional surveys and reflection), with some intentional use of the results to improve course design and instruction.\nDeliberate There is moderate course/teaching assessment (e.g., institutional surveys and peer review), with moderate use of the results to improve course design and instruction (e.g., course redesign and research into pedagogies and practices of instruction).\nIntegrated There is a high degree of course/teaching assessment (e.g., pre-/post- testing of student learning, close examination of student products via scholarship of teaching and learning) with extensive use of the results to improve course design and instruction (e.g., consultations and participation in programs with a Center for Teaching & Learning).\nEngaged with educational systems There is a high degree of course/teaching assessment in collaboration with students (e.g., student focus groups, students as co-inquirers in scholarship of teaching and learning) with an extensive collaboration with students to improve course design and instruction (e.g., students as partners or learning assistants to support course and instructional design), in addition to support from institutional Centers and stakeholders to use evidence to improve curricula beyond the course in question (e.g., department chairs or deans).\nEngaged with community and society There is a high degree of course/teaching assessment in collaboration with students and community partners (e.g., student/community focus groups) with an extensive collaboration among all stakeholders to improve participatory course design and instruction processes, in addition to support from institutional and community stakeholders to improve curricula and processes of co-teaching with community members.\n32 Domain 3: Learning Assessment Action Assessment Now that you have completed this domain, take a look at your responses to the domain’s questions above.\nWhat patterns do you see in your responses? (For example, do you tend to rate your current teaching practices at the same level, or are they varied? On which practices are your current and desired ratings the closest? The farthest apart?) What do your responses reveal about your current inclusive teaching orientations or strategies, and where do you have room for growth?\nPrioritize the top 2 to 3 practices in this domain that you would like to investigate and improve. (Note: You might select a particular practice because your current and desired responses are the farthest apart, revealing a significant area for growth. Conversely, you might focus on a practice for which your current and desired responses are close, perhaps making it easier to see change in the short term [i.e., “low hanging fruit”]. Remember there is no right or wrong choice and you can always come back later to focus on the others.) What concrete steps might you like to take to grow toward where you want to be in these 2 or 3 priority practices? (Note: You will find it most helpful if these concrete steps are relevant, specific, and achievable.) 33 Domain 4: Learning Experiences and Interactions Class Norms How can I create a classroom culture that supports integrity, diversity, inclusion, and belonging?\nHow can I co-create norms that encourage community-building, not merely compliance?\nHow can I co-create processes that honor civility and productive forms of conflict for learning? Here, we ask you to consider how you can create a classroom culture that fosters informed, dynamic, diverse, just, and critical dialogue while supporting all students’ trust and belonging in the educational process.\nCurrent Desired Beginning Norms for the course are implied or established and articulated by the institution.\nEmergent Norms are minimal or established by me and/or campus policy; framing may be in terms of compliance; focus may be largely on academic integrity.\nDeliberate Norms determined with student feedback; framing may be in terms of compliance; focus is on basics of civility and honesty as well as academic integrity.\nIntegrated Norms co-created by me and students; framing is in terms of community building not only compliance; focus is on ideals of inclusion, equity, and empowerment as well as civility, honesty, and academic integrity Engaged with educational systems Norms co-created by me and students; framing is in terms of community building and negotiating difference, not only compliance; focus is on ideals of inclusion, equity, and empowerment as well as civility, honesty, and academic integrity; attention to transforming unproductive conflict to productive conflict as a model for campus life.\nEngaged with community and society Norms co-created by me, students, and community partners; framing is in terms of community building and negotiating difference, not only compliance; focus is on ideals of inclusion, equity, empowerment, and ethics of community engagement as well as civility, honesty, and academic integrity; attention to transforming unproductive conflict to productive conflict as a model for community and social change.\n34 Domain 4: Learning Experiences and Interactions Sources of Knowledge How can I ensure the course includes diverse voices as sources of knowledge and learning?\nHow can I help students to understand the (limited) diversity of voices that shape my (sub)discipline?\nHow can my students and I make new contributions to my (sub)discipline and foster epistemic justice? Current Desired Beginning Voices in the course (i.e., authors, lecturers, examples, case studies, students, etc.) represent a limited range of perspectives, experiences, cultures, or identities. Emergent Voices in the course represent a somewhat more diverse set of perspectives, experiences, cultures, or identities (e.g., a greater diversity of authors or examples).\nDeliberate Voices in the course represent a significant range of perspectives, experiences, cultures, or identities (e.g., guest instructors, co-teachers).\nIntegrated Voices in the course represent a highly diverse range of perspectives, experiences, cultures, or identities; they help students better understand the epistemic limitations of existing scholarship in a (sub)discipline, the revival or creation of new theories and methods, the application to new contexts, etc.\nEngaged with educational systems Voices in the course represent a highly diverse range of perspectives, experiences, cultures, or identities; they help students, me, and other stakeholders in the (sub)discipline co-create new contributions to the (sub)discipline and foster epistemic justice.\nEngaged with community and society Voices in the course represent a highly diverse range of perspectives, experiences, cultures, or identities – including community members; they help all stakeholders co-create new contributions to the (sub)discipline, to epistemic justice, and to more just social systems.\n35 Domain 4: Learning Experiences and Interactions Supporting Students Who Struggle How can I assess effectively and better support students who underperform?\nHow can I best provide struggling students with the resources they need to succeed? Current Desired Beginning There is little attempt to reach out or give special support to students who underperform beyond what is required by institutional policy.\nEmergent There are some efforts to assess students, identify students who underperform, and provide feedback about needed growth. Deliberate There are consistent efforts to assess students, identify students who underperform, communicate with them about their struggles, and support their intellectual development by providing academic resources in and outside of class.\nIntegrated There are thoroughgoing efforts to assess students, identify students who underperform, communicate with them about their struggles, clarify learning goals, and support their holistic development by providing resources for their academic and personal growth.\nEngaged with educational systems There are thoroughgoing efforts to assess students, identify students who underperform, communicate with them about their struggles, identify academic and personal challenges, clarify learning goals, develop learning plans, and provide student- and instructor-based mentorship for academic and personal growth.\nEngaged with community and society There are thoroughgoing efforts to assess students, identify students who underperform, communicate with them about their struggles, identify academic and personal challenges, clarify learning goals, develop learning plans, and provide student-, instructor-, and community-based mentorship for academic, personal, and civic growth.\n36 Domain 4: Learning Experiences and Interactions Communication with Students How can I provide all students with the direction and feedback they need to succeed?\nHow can I make sure all students, regardless of differences, can access and receive meaningful guidance?\nHow can I co-create a culture of open and productive communication about course material and assignments? Current Desired Beginning Minimal communications via syllabus, learning management system (LMS), or in-person meetings focused on clarifying requirements and course content and on providing feedback and grades.\nEmergent Some communications via syllabus, LMS, email, or in-person meetings focused on the learning goals and policies of the course, clarifying requirements and content, and providing feedback and grades.\nDeliberate Moderate communications across all platforms focused on learning goals and policies of the course, clarifying requirements and content, sharing assessment criteria via rubrics, providing assessment feedback and grades that are timely and fair.\nIntegrated Highly transparent and participatory dialogue across all platforms focused on learning goals, policies, requirements, content, assessment criteria via rubrics, assessment feedback that is timely and fair, as well as pedagogies or methods of instruction and efforts to define and build a learning community.\nEngaged with educational systems Fully transparent and co-constructed communications among me, students, and other institutional stakeholders (departments, schools, and other units) about learning goals, policies, requirements, content, assessment criteria via rubrics, assessment feedback that is timely and fair, self- and peer-assessment, as well as pedagogies or methods of collective efforts to build a learning community – all for the sake of shared learning.\nEngaged with community and society Fully transparent and co-constructed communications among institutional and community stakeholders about learning goals, policies, requirements, content, assessment criteria via rubrics, assessment feedback that is timely and fair, self- and peer-assessment, as well as pedagogies or methods of collective efforts to build a learning community – all for the sake of shared learning and social transformation.\n37 Domain 4: Learning Experiences and Interactions Inclusive Facilitation How can be more attentive to, and supportive of, all student voices in classroom discussions?\nHow can I ensure all students have the belonging, preparation, and readiness to contribute to classroom discussions? How can I model acceptance and inclusion of a diversity of student identities and perspectives?\nCurrent Desired Beginning Limited attention to how inclusive or equitable class discussions may be, and limited effort to enhance the belonging, preparation, or readiness less engaged students may bring to the dialogue (e.g., asking for all students to provide comments and ask questions).\nEmergent Some attention to how inclusive or equitable class discussions may be, and some effort to enhance the belonging, preparation, or readiness less engaged students may need to contribute to the dialogue (e.g., encouragement of less engaged students, asking for new voices to contribute).\nDeliberate Considerable attention to tracking how inclusive or equitable class discussions may be, and considerable effort to enhance the belonging, preparation, or readiness less engaged students may need to contribute to the dialogue (e.g., checking in with less engaged students to ensure they have the preparation and support they need, and encouraging more vocal students to step back).\nIntegrated Regular and thorough attention to how inclusive or equitable class discussions may be, and thorough efforts to enhance the belonging, preparation, or readiness less engaged students may need to contribute to the dialogue (e.g., norming and modeling inclusion, using check-in or small group presentations to structure more inclusive participation).\nEngaged with educational systems Regular and thorough attention to how inclusive or equitable class discussions may be; thorough efforts to enhance the belonging, preparation, or readiness less engaged students may need to contribute to the dialogue; and endeavors to support inclusion and equity across academic affairs and student life in the institution.\nEngaged with community and society Regular and thorough attention to how inclusive or equitable class discussions may be; thorough efforts to enhance the belonging, preparation, or readiness less engaged students or community members may need to contribute to the dialogue; and endeavors to support inclusion and equity across the institution as well as in community and public life.\n38 Domain 4: Learning Experiences and Interactions Engagement with Difference via Culturally Responsive Teaching How can I be sure to include and fully engage the diverse range of student voices in my course?\nHow can I be sure all student voices contribute to a dynamic and critical learning environment?\nHow can I be culturally responsive to the histories, identities, and contributions of all students, or engage students in just and equitable ways, including under-represented and marginalized students? Current Desired Beginning Limited acknowledgement of the diversity of perspectives, experiences, or backgrounds among students, instructor(s), or others who inform the course (authors, guest lecturers), and limited efforts to incorporate them into the learning process.\nEmergent Some acknowledgements of the diversity of perspectives, experiences, or backgrounds among students, instructor(s), or others who inform the course (e.g., syllabus diversity statements) and some effort to incorporate them into the learning process (e.g., my personal interest in student dialogue outside of class).\nDeliberate Moderate acknowledgement of the diversity of perspectives, experiences, or backgrounds among students, instructor(s), or others who inform the course (e.g., class dialogues about the learning benefits of diversity) and moderate effort to incorporate them into the learning process (e.g., my efforts to be inclusive of diverse perspectives in class dialogue and being culturally responsive to different students’ learning process).\nIntegrated Consistent and thorough acknowledgement of the diversity of perspectives, experiences, or backgrounds among students, instructor(s), or others who inform the course (e.g., efforts to diversify content) and consistent efforts to incorporate them into a just and engaging learning process (e.g., dialogue that helps students achieve greater self-awareness and personalize course content, assignments, and learning goals). Engaged with educational systems Highly collaborative acknowledgement among all institutional stakeholders of the diversity of perspectives, experiences, or backgrounds among students, instructor(s), or others who inform the course (e.g., co-constructed norms for honoring diversity and equity) and collaborative efforts to realize them in a just and engaging learning process (e.g., collaborative learning strategies, assignments that build cultural competencies).\nEngaged with community and society Highly collaborative acknowledgement among all institutional and community stakeholders of the diversity of perspectives, experiences, or backgrounds among all who inform the course (e.g., co-constructed norms for honoring diversity and equity in class and in the community) and collaborative efforts to realize them in the a just and engaging learning process as well as in community or public life (e.g., developing cultural competencies to foster greater inclusion and equity in community or public action).\n39 Domain 4: Learning Experiences and Interactions Supporting Belonging and Community How can I ensure all students find belonging and community in my course through trust and common purpose?\nHow can I co-create a classroom culture in which all students support one another in the learning process?\nHow can I expand the classroom community to campus and community stakeholders in the course? Current Desired Beginning Beyond general niceties and responsiveness, there is limited effort to support student belonging or community Emergent Some efforts to support student belonging and build community through trust and common purpose. For example, building rapport and welcoming students with openness, friendliness, broad accessibility, and explicit commitments to student well-being.\nDeliberate Moderate efforts to support belonging and build community. For example, through syllabus or in-class statements in support of diversity, inclusion, and equity in the course, in addition to intentional work to include diverse voices in the readings, examples/cases, guest speakers, and among the student participants.\nIntegrated Thoroughgoing efforts to support belonging and build community among myself and students. For example, adopting a “growth mindset” (Dweck, 2007) or asset-based approach in all communications with students, ensuring they have the encouragement and support to participate fully and in diverse, personally relevant ways.\nEngaged with educational systems Highly collaborative efforts among myself and students and other institutional stakeholders in co-creating a culture of belonging and community in the course. For example, using highly collaborative and inclusive dialogue across differences that explicitly honors everyone’s contributions, supporting personalized and meaningful learning plans, or fostering a sense of epistemic justice in the (sub)disciplinary focus of the course.\nEngaged with community and society Highly collaborative efforts among all stakeholders, including community partners, in co-creating a culture of belonging and community in the course. For example, honoring the mutual contributions of community partners, students, and myself in the co-creation of knowledge and skills of social change work.\n40 Domain 4: Learning Experiences and Interactions Action Assessment Now that you have completed this domain, take a look at your responses to the domain’s questions above.\nWhat patterns do you see in your responses? (For example, do you tend to rate your current teaching practices at the same level, or are they varied? On which practices are your current and desired ratings the closest? The farthest apart?) What do your responses reveal about your current inclusive teaching orientations or strategies, and where do you have room for growth?\nPrioritize the top 2 to 3 practices in this domain that you would like to investigate and improve.\n(Note: You might select a particular practice because your current and desired responses are the farthest apart, revealing a significant area for growth. Conversely, you might focus on a practice for which your current and desired responses are close, perhaps making it easier to see change in the short term [i.e., “low hanging fruit”]. Remember there is no right or wrong choice and you can always come back later to focus on the others.) What concrete steps might you like to take to grow toward where you want to be in these 2 or 3 priority practices? (Note: You will find it most helpful if these concrete steps are relevant, specific, and achievable.) 41 preencoded.png Conclusion Congratulations, you have completed the rubric! We hope it has helped you move along your path towards greater inclusive and equitable teaching, and that it will promote the engagement and growth of you and your students. We invite you to return to the rubric periodically as you cycle through new phases of reflection, assessment, and implementation in your inclusive teaching.\nThank you again for your commitments to this work and all that it may mean to you, your students, and our broader world.\nTransform Implement Plan Assess Reflect 42 preencoded.png Bibliography ACE & AAUP. (2000). Does Diversity Make a Difference? Three Research Studies on Diversity in College Classrooms. ACE & AAUP.\nAddy, T.M., Dube, D., Mitchell, K.A., & SoRelle, M.E. (2022). What Inclusive Instructors Do: Principles and Practices for Excellence in College Teaching. Stylus.\nApplebaum, Barbara. (2007). Engaging Student Disengagement: Resistance or Disagreement? Philosophy of Education. 2007: 335–45. https://www.semanticscholar.org/paper/Engaging-Student-Disengagement%3A-Resistance-or-Applebaum/4fb20b9729933e7804123657dd657043384e93e4 Armstrong, P. (2010). Bloom’s Taxonomy. Vanderbilt University Center for Teaching. Retrieved 2/7/23 from https://cft.vanderbilt.edu/guides-sub-pages/blooms-taxonomy/.\nAssociation of College and University Educators. (2020). Inclusive Teaching Practices Toolkit. ACUE.\nBain, K. (2004). What the Best College Teachers Do. Harvard University Press.\nBerlak, Ann. (1999). Teaching and Testimony: Witnessing and Bearing Witness to Racisms in Culturally Diverse Classrooms. Curriculum Inquiry 29, no. 1: 99–127. https://doi.org/10.1111/0362-6784.00115 Bertrand, Marianne and Sendhil Mullainathan. (2004). Are Emily and Greg More Employable than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination. The American Economic Review. 94(4): 991-1013.\nBoice, R. (2002). Advice for new faculty members . Boston, MA: Allyn and Bacon.\nBonilla-Silva, Eduardo. (2017). Racism without Racists: Color-Blind Racism and the Persistence of Racial Inequality in America. Lanham: Rowman & Littlefield.\nBoyer 2030 Commission. (2022). The Equity-Excellence Imperative: A 2030 Blueprint for Undergraduate Education at U.S. Research Universities. The Association for Undergraduate Education at Research Universities.\nBozalek, Vivienne, Ronelle Carolissen, Brenda Leibowitz, Lindsey Nicholls, Poul Rohleder and Leslie Swartz. 2010. Engaging with Difference in Higher Education through Collaborative Inter-institutional Pedagogical Practices. South African journal of higher education 24 (2010): 1023–37. https://www.semanticscholar.org/paper/Engaging-with-difference-in-higher-education-Bozalek-Carolissen/f2556d794dac8790685bf6c62e01d4e6eea0999b Brooks, J., & McGurk, J. (2022). Rigor as Inclusive Practice: Improving Equitable Outcomes in Teaching. Teaching and Learning Lab, MIT.\nBrown-Jeffy, S., & Cooper, J. E. (2011). Toward a Conceptual Framework of Culturally Relevant Pedagogy: An Overview of the Conceptual and Theoretical Literature. Teacher Education Quarterly, 38(1), 65–84. http://www.jstor.org/stable/23479642 Brown, B. A., Boda, P., Lemmi, C., & Monroe, X. (2019). Moving Culturally Relevant Pedagogy From Theory to Practice: Exploring Teachers’ Application of Culturally Relevant Education in Science and Mathematics. Urban Education, 54(6), 775–803. https://doi.org/10.1177/0042085918794802 Cahill, J. (Ed.). (2023). The Norton Guide to Equity-Minded Teaching. WW Norton & Company.\nCampusLabs. (2020). Equity-Centered Assessment: Embedding Equity throughout the Assessment Cycle. IUPUI Assessment Institute Canning, E.A., Muenks, K., Green, D.J., & Murphy, M.C. (2019). “STEM faculty who believe ability is fixed have larger racial achievement gaps and inspire less student motivation in their classes.” Science Advances. 5(2).\nCenter for Teaching. (2020). Reflecting on Your Practice: Inclusive Teaching Principles. Nashville: Vanderbilt University Center for Teaching.\nChandler-Ward, J., & Denevi, E. (2022). Learning and Teaching while White: Antiracist Strategies for School Communities. Norton Professional Books.\nChick, Nancy, Terri Karis, and Cyndi Kemahan. (2009). Learning from Their Own Learning: How Metacognitive and Meta-affective Reflection Enhance Learning in Race-related Courses. International Journal for Scholarship of Teaching and Learning 3 no 1.: 1-28. https://doi.org/10.20429/ijsotl.2009.030116 Cohen, J.E., Raynor, S.D., & Mack, D.A. (Eds.) (2021). Teaching Race in Perilous Times. Albany: SUNY Press.\nCook-Sather, A. (2020). Respecting Voices: How the Co-creation of Teaching and Learning Can Support Academic Staff, Underrepresented Students, and Equitable Practices. Higher Education 79 (5), 885-901.\nCook-Sather, A. (2021). Responding to Twin Pandemics: Reconceptualizing Assessment Practices for Equity and Justice. Research & Practice in Assessment, 16(2), 5-16.\nCook-Sather, A. (2022). Co-Creating Equitable Teaching and Learning: Structuring Student Voice into Higher Education. Cambridge: Harvard Education Press.\n43 preencoded.png Bibliography Crenshaw, Kimberle. (1988). Race, Reform, and Retrenchment: Transformation and Legitimation in Antidiscrimination Law. Harvard Law Review 101, no. 7: 1331–87. https://www.jstor.org/stable/1341398. Crossroads Antiracism Organizing and Training. (2020). Continuum on Becoming an Antiracist Multicultural Institution. Vineburg: Crossroads.\nCurry, M. (2022). Critical Friends Groups: The Possibilities and Limitations Embedded in Teacher Professional Communities Aimed at Instructional Improvement and School Reform. Teachers College Record, 110(4).\nDanowitz, Mary Ann and Frank Tuitt. (2011). “Enacting Inclusivity through Engaged Pedagogy: A Higher Education Perspective.” Equity & Excellence in Education 44, no. 1: 40–56. https://doi.org/10.1080/10665684.2011.539474 Delano-Oriaran, Omobolade and Marguerite W. Parks. (2105). One Black, One White: Power, White Privilege, & Creating Safe Spaces. Multicultural Education 22, no. 3/4: 15–19. https://www.semanticscholar.org/paper/One-Black%2C-One-White%3A-Power%2C-White-Privilege%2C-%26-Delano-Oriaran-Parks/2204090b2307702c8258e3d854b43aed8dc19aed DiAngelo, Robin, and Özlem Sensoy. (2014). Leaning in: A Student’s Guide to Engaging Constructively with Social Justice Content. Radical Pedagogy 11(1): 1–15. https://robindiangelo.com/wp-content/articles/rad-ped-leaning-in.pdf DiAngelo, Robin. (2011). White Fragility. International Journal of Critical Pedagogy 3, no. 3: 54–70. https://libjournal.uncg.edu/ijcp/article/view/249 Dixson, Adrienne D. and Celia K. Rousseau. (2005). And We are Still not Saved: Critical Race Theory in Education Ten Years Later. Race Ethnicity and Education 8, no. 1: 7–27. https://doi.org/10.1080/1361332052000340971 Dweck, C.S. (2007). Mindset: The New Psychology of Success. Updated Edition. Ballantine Books.\nFelten, P., & Lambert, L.M. (2020). Relationship-Rich Education: How Human Connections Drive Success in College. Johns Hopkins University Press.\nFischer, M.R., Jr., & Bandy, J. (2019). Assessing Student Learning. Vanderbilt University Center for Teaching. Retrieved 2/7/23 from https://cft.vanderbilt.edu/assessing-student-learning/ Ford, K.A. (2012). Shifting White Ideological Scripts: The Educational Benefits of Inter- and Intraracial Curricular Dialogues on the Experiences of White College Students. Journal of Diversity in Higher Education 5, no. 3: 138–58. https://doi.org/10.1037/a0028917 Freire, Paulo. (1968). Pedagogy of the Oppressed. Continuum.\nHarbin, Myra Brielle, Amie Thurber, and Joe Bandy. (2019). Teaching Race, Racism, and Racial Justice: Pedagogical Principles and Classroom Strategies for Course Instructors. Race and Pedagogy Journal 4, no. 1: 1–37. https://soundideas.pugetsound.edu/cgi/viewcontent.cgi?article=1044&context=rpj Heifetz, Ronald. (1994). Leadership without easy answers. Cambridge: Harvard University Press.\nhooks, bell. (1994). Teaching to Transgress: Education as the Practice of Freedom. Routledge.\nhooks, bell. (2003). Teaching Community: A Pedagogy of Hope. Routledge.\nHousee, Shirin. (2008). Should Ethnicity Matter When Teaching about ‘Race’ and Racism in the Classroom? Race, Ethnicity and Education 11, no. 4: 415–28. https://doi.org/10.1080/13613320802478960 Hurney, C., Glazer, F., & Grooters, S. (2022). The State of Diversity, Equity, and Inclusion in The POD Network. POD Network Conference, Seattle, November 18, 2022.\nImmordino-Yang, Mary Helen and Antonio Demasio. (2007). We Feel, Therefore We Learn: The Relevance of Affective and Social Neuroscience to Education. Mind, Brain & Education 1, no. 1: 3–10. https://doi.org/10.1111/j.1751-228X.2007.00004.x Indiana University-Purdue University Indianapolis. (2023). Engaged learning Taxonomies: Sustaining the Quality of High-Impact Experiences. Indianapolis: IUPUI Kandaswamy, Priya. (2007). Beyond Colorblindness and Multiculturalism: Rethinking Anti-Racist Pedagogy in the University Classroom. Radical Teacher 80, Winter: 6–11. https://www.jstor.org/stable/20710420 Khalifa, M. A., Gooden, M. A., & Davis, J. E. (2016). Culturally Responsive School Leadership: A Synthesis of the Literature. Review of Educational Research, 86(4), 1272–1311. https://doi.org/10.3102/0034654316630383 44 preencoded.png Bibliography Kishimoto, Kyoko. (2018). Anti-racist Pedagogy: From Faculty’s Self-reflection to Organizing within and beyond the Classroom. Race Ethnicity and Education 21, no. 4: 540–54. https://doi.org/10.1080/13613324.2016.1248824 Kohlberg, L. (1958). The Development of Modes of Thinking and Choices in Years 10 to 16. Ph. D. Dissertation, University of Chicago.\nKohlberg, L. (1984). The Psychology of Moral Development: The Nature and Validity of Moral Stages (Essays on Moral Development, Volume 2). Harper & Row.\nKumashiro, Kevin K. (2000). Teaching and Learning through Desire, Crisis, and Difference: Perverted Reflections on Anti-oppressive Education. The Radical Teacher 58, Fall: 6–11. https://www.jstor.org/stable/20710047 Ladson-Billings, G. (1995). Toward a Theory of Culturally Relevant Pedagogy. American Educational Research Journal, 32(3), 465–491. https://doi.org/10.3102/00028312032003465 Leibowitz, Brenda, Vivienne Bozalek, Poul Rohleder, Ronelle Carolissen, and Leslie Swartz. (2010). ‘Ah, but the Whiteys Love to Talk about themselves’: Discomfort as a Pedagogy for Change. Race, Ethnicity and Education 13, no. 1: 83–100. https://doi.org/10.1080/13613320903364523 Leonardo, Zeus and Ronald K. Porter. (2010). Pedagogy of Fear: Toward a Fanonian Theory of ‘Safety’ in Race Dialogue. Race Ethnicity and Education 13, no. 2: 139–57. https://doi.org/10.1080/13613324.2010.482898 Levine-Rasky, Catherine. (2015). Research For/About/With the Community: A Montage. Cultural Studies–Critical Methodologies 15, no. 6: 455–67. https://doi.org/10.1177%2F1532708615572359 Lichty, Lauren F. and Eylin Palamaro-Munsell. (2017). Pursuing an Ethical, Socially Just Classroom: Searching for Community Psychology Pedagogy. American journal of community psychology 60, no. 3–4: 316–26. https://doi.org/10.1002/ajcp.12199 Locks, Angela M., Sylvia Hurtado, Nicholas Bowman, & Letecia Oseguera. (2008). Extending Notions of Campus Climate and Diversity to Students’ Transition to College. Review of Higher Education. 31(3): 257-85.\nLundquist, A.E., & Henning, G. (2020). From Avoiding Bias to Social Justice: A Continuum of Assessment Practices to Advance Diversity, Equity, and Inclusion. Ch. 4 in Spicer-Runnels, A.D., & Simpson, T.E. (Eds.) Developing an Intercultural Responsive Leadership Style for Faculty and Administrators (pp. 47-61). IGI Global.\nMatias, Cheryl E. and Janiece Mackey. (2015). Breakin’ Down Whiteness in Antiracist Teaching: Introducing Critical Whiteness Pedagogy. The Urban Review: Issues and Ideas in Public Education 48, no. 1: 32–50. https://eric.ed.gov/?id=EJ1091197 Milkman, K.L., Akinola, M., and Chugh, D. (2014). What Happens Before? A Field Experiment Exploring How Pay and Representation Differentially Shape Bias on the Pathway into Organizations. Social Science Research Network. Milner, H.R. (2017). Where’s the Race in Culturally Relevant Pedagogy? Teachers College Record, 119(1), 1–32. https://doi.org/10.1177/016146811711900109 Milner, Rich. (2012). Beyond a Test Score: Explaining Opportunity Gaps in Educational Practice. Journal of Black Studies. 43(6).\nMontenegro, E., & Jankowski, N.A. (2020). A New Decade for Assessment: Embedding Equity into Assessment Praxis. NILOA.\nNational Equity Project. (2023). Introduction to Liberatory Design. Oakland: NEP.\nNational Institute for Learning Outcomes Assessment. (2023). Equity in Assessment. Champaign: NILOA.\nNieto, L. (2010). Beyond Inclusion, Beyond Empowerment: A Developmental Strategy to Liberate Everyone. Cuetzpalin.\nPipe, L., & Stephens, J.T. (2021). Toward a Liberated Learning Spirit: A Model for Developing Critical Consciousness. Journal of Scholarship of Teaching and Learning, 21(2), 121-139.\nPortman, Joel, Tuyen Trisa Bui, Javier Ogaz, and Jesus Trevino. (2015). “Microaggressions in the Classroom.” University of Denver.\nReid, E.S., & Weinstein, A. (2022). Embedding Inclusive Teaching in College Policies. POD Network Conference, Seattle, November 18, 2022.\nSathy, V., & Hogan, K. (2021). How to Make Your Teaching More Inclusive: Advice Guide. The Chronicle of Higher Education. Downloaded 10/1/21.\nShulman, L. S. (2005). Signature pedagogies in the professions. Daedalus, 134(3), 52-59. doi:10.1162/0011526054622015 Steele, Claude. (2011). Whistling Vivaldi: How Stereotypes Affect Us and What We Can Do. WW Norton.\nStudent Affairs Assessment Leaders. (2022). Equity-Minded Assessment: The Time is Now. SAAL: Kent State University.\n45 preencoded.png Bibliography Sue, Derald Wing. (2010). Microaggressive Impact on Education and Teaching: Facilitating Difficult Dialogues on Race in the Classroom. Ch 11 in Microaggressions in Everyday Life: Race, Gender, and Sexual Orientation. John Wiley & Sons.\nSuoranta, Juha and Olli-Pekka Moisio. (2006). “Critical Pedagogy as Collective Social Expertise in Higher Education.” International Journal of Progressive Education 2, no. 3: 47–64. https://eric.ed.gov/?id=EJ1067920 Thurber, Amie and Robin DiAngelo. (2018). Microaggressions: Intervening in Three Acts. Journal of Ethnic & Cultural Diversity in Social Work 27, no. 1: 17–27. https://www.tandfonline.com/doi/abs/10.1080/15313204.2017.1417941 Tuitt, F., Haynes, C., & Stewart, S. (Eds.) (2016). Race, Equity, and the Learning Environment: The Global Relevance of Critical and Inclusive Pedagogies in Higher Education. San Francisco: Stylus.\nUniversity of California. (2022). Advancing Inclusion and Anti-Racism in the College Classroom: A Rubric and Resource Guide for Instructors. Berkeley: Department of Environmental Science, Policy, and Management. University of California, Berkeley. January.\nVo, L.T. (2012). Navigating the Academic Terrain: The Racial and Gender Politics of Elusive Belonging. in Gutierrez y Muhs, G., Niemann, Y.F., Gonzalez, C.G., & Harris, A.P. (Eds.) Presumed Incompetent: The Intersections of Race and Class for Women in Academia. Utah State University Press.\nWilliams, Bianca C. (2016). Radical Honesty: Truth-telling as Pedagogy for Working Through Shame in Academic Spaces in Race, Equity, and the Learning Environment: The Global Relevance of Inclusive Pedagogies for Higher Education edited by Frank Tuitt, Chayla Haynes, and Saran Stewart. Sterling: Stylus.\nWilliams, John A. (1994). Classroom in conflict: Teaching controversial subjects in a diverse society. Albany: State University of New York Press. Young, E. (2010). Challenges to Conceptualizing and Actualizing Culturally Relevant Pedagogy: How Viable Is the Theory in Classroom Practice? Journal of Teacher Education, 61(3), 248–260. https://doi.org/10.1177/0022487109359775 Zehnder, C., Alby, C., Kleine, K., & Metzker, J. (2020). Learning that Matters: A Field Guide to Course Design for Transformative Education. Myers Education Press.\nZembylas, Michalinos. (2012). Pedagogies of Strategic Empathy: Navigating through the Emotional Complexities of Anti-racism in Higher Education. Teaching in Higher Education 17, no. 2: 113–25. https:"
      },
      {
        "type": "text",
        "text": "\n\n[OUTPUT TRUNCATED - exceeded 25000 token limit]\n\nThe tool output was truncated. If this MCP server provides pagination or filtering tools, use them to retrieve specific portions of the data. If pagination is not available, inform the user that you are working with truncated output and results may be incomplete."
      }
    ]
  }
]

---

### User
> 11/30/2025, 3:48:36 PM

[
  {
    "tool_use_id": "toolu_018Lt3pzcpeZmiwwNpyjg8AM",
    "type": "tool_result",
    "content": [
      {
        "type": "text",
        "text": "Detailed Results:\n\nTitle: Have you heard of the DIEP Framework for Reflection? It ... - Facebook\nURL: https://www.facebook.com/SustainabilityLiteracyTest/videos/-have-you-heard-of-the-diep-framework-for-reflectionit-is-a-four-step-method-you/615742049391969/\nContent: TASK™ is the first assessment tool to provide a standardized... Oct 25, 2023 · 2 views. 00:20. MORE THAN 1000 PEOPLE HAVE ALREADY REGISTERED\n\nTitle: How to use DIEP (Describe Interpret Evaluate Plan) - Learning Lab\nURL: https://learninglab.rmit.edu.au/assessments/reflective-writing/how-use-diep/\nContent: DIEP is a framework that can be used to guide your academic reflections. This page takes you through the different sections of the DIEP framework.\nRaw Content: ## [Learning Lab Learning Lab homepage](/)\n\n## University essentials\n\n## Writing fundamentals\n\n## Assessments\n\n## Referencing\n\n## Digital skills\n\n## Subject support\n\n## [Assessments](/assessments/)\n\n### [Academic reflection](/assessments/reflective-writing/)\n\n# How to use DIEP (Describe Interpret Evaluate Plan)\n\nDIEP is a framework that can be used to guide your academic reflections. This page takes you through the different sections of the DIEP framework.\n\n## Describe\n\n### 1. Describe the insight\n\nAn insight is something new that you learned or realised. The insight must be relevant to the course and ideally could change your thinking or behaviour in the future. Your insight may apply to your studies, your professional practice, or your future goals.\n\n#### Examples\n\n> The most important thing I realised this week is the role of questioning in project management.\n\n> A reading technique that I have learned recently that I find valuable for my study is pre-reading, especially skimming and scanning.\n\n### 2. Describe the circumstances\n\nProvide brief and relevant details of the situation from which you gained the insight. Say what was happening when this learning occurred.\n\n* What was the context? (e.g. on placement, during reading)\n* What was the particular trigger? (e.g. a comment from a patient, a concept in the readings, a particular question or activity in class)\n\n#### Examples\n\n> I learned this from the lecture in Project Management Techniques by guest lecturer, Dr Liu. She started her presentation by asking us to build a tower from straws...\n\n> I learned about these techniques for efficient reading from an exercise using a chapter from Anstey (2022) about the four resources model. We used the skimming technique, which involves noting full details about the text and what it contains before reading it. We had to look at the whole chapter to identify the main ideas through the headings. I realised I can get a lot of information about the main ideas in a text without actually reading it in full.\n\n### 1. Describe the insight\n\nAn insight is something new that you learned or realised. The insight must be relevant to the course and ideally could change your thinking or behaviour in the future. Your insight may apply to your studies, your professional practice, or your future goals.\n\n#### Examples\n\nThe most important thing I realised this week is the role of questioning in project management.\n\nA reading technique that I have learned recently that I find valuable for my study is pre-reading, especially skimming and scanning.\n\n### 2. Describe the circumstances\n\nProvide brief and relevant details of the situation from which you gained the insight. Say what was happening when this learning occurred.\n\n#### Examples\n\nI learned this from the lecture in Project Management Techniques by guest lecturer, Dr Liu. She started her presentation by asking us to build a tower from straws...\n\nI learned about these techniques for efficient reading from an exercise using a chapter from Anstey (2022) about the four resources model. We used the skimming technique, which involves noting full details about the text and what it contains before reading it. We had to look at the whole chapter to identify the main ideas through the headings. I realised I can get a lot of information about the main ideas in a text without actually reading it in full.\n\n## Interpret\n\nAfter describing your insight and the circumstances, you need to discuss its meaning. In other words, you should interpret what the insight means. You can:\n\nNow go deeper to analyse your insight by exploring such aspects as:\n\n#### Examples\n\nUnderstanding the importance of questions for clarification is central to my understanding of project management. This new emphasis underpins my use…\n\nSkimming and scanning a text is a very new approach to reading for me. It is not something that I had previously practised when reading in my native language. I now understand that reading quickly is not negative, but rather it is more efficient, as Anders (2023) explains...\n\n## Evaluate\n\nOnce you have considered the meaning of the insight, you can discuss its value. What relevance does it have? How does it benefit your:\n\n#### Examples\n\nOne benefit of understanding the critical role of questioning in project management is that it might give me more confidence. This experience has changed my perception of my role as an active participant in project management and not just as a passive receiver of a brief. This changes my view of questioning government authorities. In my job as a …\n\nA significant benefit of understanding the technique of efficient reading is that I have much more confidence in locating important information in a text. Skimming and scanning a text allows me to locate information more efficiently. I used to read every line very carefully. This made academic reading slow and burdensome and I did not always understand the main idea.\n\n## Plan and transfer new learning\n\nFinally, say how you might apply this new insight in the future.\n\nYou may use the new insight in:\n\nYou may find you need to:\n\n#### Example\n\nClarifying the requirements of a brief is important and I will need to schedule time to identify and prepare the relevant questions early in the project timeline.\n\nMy new understanding of efficient reading techniques will be important for me in many areas - in this course, in the Bachelor of Education degree, for my future primary teaching career, and in my life generally. Pre-reading, especially skimming and scanning, is an efficient way to approach a new text in this Teaching Reading course and for all the other subjects in my degree. In my professional development as a primary school teacher, I will need to keep up with theory and developments throughout my career so I need to be observant when I approach new texts to identify the useful studies.\n\n## [Academic reflection Previous page: Academic reflection](/assessments/reflective-writing/)\n\n## [Sample reflection Next page: Sample reflection](/assessments/reflective-writing/sample-reflection/)\n\n## Keywords\n\n## Embed this page\n\nHow to embed in Canvas LMS\n\nNote: Ensure that your permissions allow embedding external content in your Canvas LMS instance.\n\n![](https://rmitlibrary.github.io/cdn/footer/ask-library-icon-round.svg)\n\n## Ask the Library\n\nGet help with finding information, referencing, and using the Library.\n\n![aboriginal flag](https://www.rmit.edu.au/content/dam/rmit/au/en/news/homepage/flag-red.png)\n![torres strait flag](https://www.rmit.edu.au/content/dam/rmit/au/en/news/homepage/flag-green.png)\n\n## Acknowledgement of Country\n\nRMIT University acknowledges the people of the Woi wurrung and Boon wurrung language groups of the eastern Kulin Nation on whose unceded lands we conduct the business of the University. RMIT University respectfully acknowledges their Ancestors and Elders, past and present. RMIT also acknowledges the Traditional Custodians and their Ancestors of the lands and waters across Australia where we conduct our business - Artwork 'Sentient' by Hollie Johnson, Gunaikurnai and Monero Ngarigo.\n\n![Abstract artwork titled 'Sentient' by Hollie Johnson, features a complex pattern of intersecting blue, green, and yellow lines over a white background showing the journeys of life starting, finishing and intersecting. The colouring of the line work illustrates the evolution of nature through many First Nations stories: the sun, the giver of life (yellow), the creation of land (green), and the sea (blue). Red and black concentric diamond and semi-circle shapes symbolise men and women respectively, connecting them to Ancestors who gave birth to them. The artwork is also a representation of RMIT and the experience within our community, culture and pathways.](https://www.rmit.edu.au/content/dam/rmit/images/sentient-hollie-johnson.jpg)\n![](https://rmitlibrary.github.io/cdn/image/svg/rmit-logo.svg)\n![](https://rmitlibrary.github.io/cdn/image/svg/social/facebook.svg)\n![](https://rmitlibrary.github.io/cdn/image/svg/social/twitter.svg)\n![](https://rmitlibrary.github.io/cdn/image/svg/social/instagram.svg)\n![](https://rmitlibrary.github.io/cdn/image/svg/social/linkedin.svg)\n![](https://rmitlibrary.github.io/cdn/image/svg/social/youtube.svg)\n![](https://rmitlibrary.github.io/cdn/image/svg/social/weibo.svg)\n\nTitle: Reflective Journal: Innovation Learnings & DIEP Model - Desklib\nURL: https://desklib.com/study-documents/innovation-diep-reflection/\nContent: Explore a reflective journal on Managing Innovation (MNGT2004) using the DIEP model. Gain key insights and practical applications.\nRaw Content: ![Home](/asset/sidebar/home.svg)\n![Study Documents](/asset/sidebar/study_docs_white.svg)\n![AI Paraphraser](/asset/sidebar/ai_paraphraser_white.svg)\n![Plagiarism Checker](/asset/sidebar/plag_check_white.svg)\n![AI Researcher](/_next/image/?url=%2Fasset%2Fsidebar%2Fai_researcher_white.png&w=48&q=75)\n![AI Answer](/asset/sidebar/ai_ans_white_.svg)\n![AI Detector](/asset/sidebar/ai_detector_white.svg)\n![AI Quiz](/asset/sidebar/ai_quiz_white.svg)\n![AI Learner](/asset/sidebar/ai_learner_white.svg)\n![AI Grader](/asset/sidebar/ai_grader_white.svg)\n![AI Code Checker](/asset/sidebar/ai_code_checker.svg)\n![Home](/asset/sidebar/home.svg)\n![Study Documents](/asset/sidebar/study_docs_white.svg)\n![AI Paraphraser](/asset/sidebar/ai_paraphraser_white.svg)\n![Plagiarism Checker](/asset/sidebar/plag_check_white.svg)\n![AI Researcher](/_next/image/?url=%2Fasset%2Fsidebar%2Fai_researcher_white.png&w=48&q=75)\n![AI Answer](/asset/sidebar/ai_ans_white_.svg)\n![AI Detector](/asset/sidebar/ai_detector_white.svg)\n![AI Quiz](/asset/sidebar/ai_quiz_white.svg)\n![AI Learner](/asset/sidebar/ai_learner_white.svg)\n![AI Grader](/asset/sidebar/ai_grader_white.svg)\n![AI Code Checker](/asset/sidebar/ai_code_checker.svg)\n![Study Documents Icon](/asset/study/study_doc_icon.svg)\n\n# MNGT2004: Reflective Journal on Innovation using DIEP Model\n\nAdded on  2023/06/17\n\n![Document Page](https://desklib.com/media/document/docfile/pages/diep-strategy-managing-innovation/2024/09/06/20de71a9-f61a-453e-8c3e-5a3e2778dcb1-page-1.webp)\n![tabler-icon-diamond-filled.svg](/asset/ai-ans/tabler-icon-diamond-filled.svg)\n\n## Paraphrase This Document\n\n![Document Page](https://desklib.com/media/document/docfile/pages/diep-strategy-managing-innovation/2024/09/06/851dfed3-a415-4a49-a82d-1ceed79b603b-page-2.webp)\n![Document Page](https://desklib.com/media/document/docfile/pages/diep-strategy-managing-innovation/2024/09/06/181003b3-66cc-4bd1-82fb-fece9cfa9717-page-3.webp)\n\n### ⊘ This is a preview!⊘\n\nDo you want full access?\n\n**Subscribe today** to unlock all pages.\n\n![icon](/asset/popup/lock-icon.svg)\n![icon](/asset/home/images/logo.png)\n\nTrusted by 1+ million students worldwide\n\n![Document Page](https://desklib.com/media/document/docfile/pages/diep-strategy-managing-innovation/2024/09/06/99847ddd-5930-428c-a235-5f0b299849a0-page-4.webp)\n![tabler-icon-diamond-filled.svg](/asset/ai-ans/tabler-icon-diamond-filled.svg)\n\n## Paraphrase This Document\n\n![Document Page](https://desklib.com/media/document/docfile/pages/diep-strategy-managing-innovation/2024/09/06/cfe3b908-8242-4f09-9b1e-6c64861628ae-page-5.webp)\n![Document Page](https://desklib.com/media/document/docfile/pages/diep-strategy-managing-innovation/2024/09/06/a537d076-77c1-4547-8fa9-a3014f3ab1d7-page-6.webp)\n\n### ⊘ This is a preview!⊘\n\nDo you want full access?\n\n**Subscribe today** to unlock all pages.\n\n![icon](/asset/popup/lock-icon.svg)\n![icon](/asset/home/images/logo.png)\n\nTrusted by 1+ million students worldwide\n\n![chevron_up_icon](/asset/study/chevron_up_icon.svg)\n![circle_padding](/asset/study/chevron_down_icon.svg)\n![hide_on_mobile](/asset/study/zoom_in_icon.svg)\n![zoom_out_icon](/asset/study/zoom_out_icon.svg)\n\n### Related Documents\n\n![Share Market Assignment: Reflecting on Process and Benefits](/_next/image/?url=https%3A%2F%2Fdesklib.com%2Fmedia%2Fwriting-assignment-techniques-share-market_page_1.jpg&w=256&q=75)\n\n##### Share Market Assignment: Reflecting on Process and Benefits\n\n![University Engineering Ethics Reflective Essay: Innovation and Ethics](/_next/image/?url=https%3A%2F%2Fdesklib.com%2Fmedia%2Fimages%2Fns%2F0a3d3be47dea454185d56b71bf553228.jpg&w=256&q=75)\n\n##### University Engineering Ethics Reflective Essay: Innovation and Ethics\n\n##### University Professional Practice Module: Week 1 Portfolio Tasks\n\n![Reflective Report on Personal and Career Development Plan (PPDI)](/_next/image/?url=https%3A%2F%2Fdesklib.com%2Fmedia%2Fimages%2Fek%2Fa8bba2e6492745438f1df383734f71c7.jpg&w=256&q=75)\n\n##### Reflective Report on Personal and Career Development Plan (PPDI)\n\n![Reflective Assignment: DIEP Framework and Effective Management Skills](/_next/image/?url=https%3A%2F%2Fdesklib.com%2Fmedia%2Fimages%2Ftp%2F5811258bf75148d6920a51060c44e1e0.jpg&w=256&q=75)\n\n##### Reflective Assignment: DIEP Framework and Effective Management Skills\n\n![Hadi Abdulla's Self-Reflection Essay: Academic Writing at AUE](/_next/image/?url=https%3A%2F%2Fdesklib.com%2Fmedia%2Fimages%2Fhs%2F285326054a93483db43a4bc73065bd2d.jpg&w=256&q=75)\n\n##### Hadi Abdulla's Self-Reflection Essay: Academic Writing at AUE\n\n![logo.png](/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Flogo.6d15ce61.png&w=640&q=75)\n\nYour All-in-One AI-Powered Toolkit for Academic Success.\n\n##### +13062052269\n\n##### info@desklib.com\n\nAvailable 24\\*7 on WhatsApp / Email\n\nCompany\n\nTools\n\nSupport\n\n![[object Object]](/_next/static/media/star-bottom.7253800d.svg)\n\nCopyright © 2020–2025 A2Z Services. All Rights Reserved. Developed and managed by ZUCOL.\n\nTitle: 1.18: Reflective Writing - Humanities LibreTexts\nURL: https://human.libretexts.org/Courses/Lumen_Learning/English_Composition_I_(Lumen)/01%3A_Success_Skills/1.18%3A_Reflective_Writing\nContent: The DIEP model for reflective thinking and writing has you first describe the situation, interpret it, evaluate it, then plan what to do with\nRaw Content: ![Library homepage](https://cdn.libretexts.net/Logos/human_full.png)\n\n## Search\n\nx\n\n#### Text Color\n\n#### Text Size\n\n#### Margin Size\n\n#### Font Type\n\n## \n\nselected template will load here\n\n## Error\n\nThis action is not available.\n\n![Library homepage](https://cdn.libretexts.net/Logos/human_full.png)\n![Humanities LibreTexts](https://a.mtstatic.com/@public/production/site_9956/1481233284-logo.png)\n\n# 1.18: Reflective Writing\n\n![ ](https://biz.libretexts.org/@api/deki/files/37961/lumen.gif \"Lumen Learning\")\n\n\\( \\newcommand{\\vecs}[1]{\\overset { \\scriptstyle \\rightharpoonup} {\\mathbf{#1}} } \\)\n\n\\( \\newcommand{\\vecd}[1]{\\overset{-\\!-\\!\\rightharpoonup}{\\vphantom{a}\\smash {#1}}} \\)\n\n\\( \\newcommand{\\dsum}{\\displaystyle\\sum\\limits} \\)\n\n\\( \\newcommand{\\dint}{\\displaystyle\\int\\limits} \\)\n\n\\( \\newcommand{\\dlim}{\\displaystyle\\lim\\limits} \\)\n\n\\( \\newcommand{\\id}{\\mathrm{id}}\\) \\( \\newcommand{\\Span}{\\mathrm{span}}\\)\n\n( \\newcommand{\\kernel}{\\mathrm{null}\\,}\\) \\( \\newcommand{\\range}{\\mathrm{range}\\,}\\)\n\n\\( \\newcommand{\\RealPart}{\\mathrm{Re}}\\) \\( \\newcommand{\\ImaginaryPart}{\\mathrm{Im}}\\)\n\n\\( \\newcommand{\\Argument}{\\mathrm{Arg}}\\) \\( \\newcommand{\\norm}[1]{\\| #1 \\|}\\)\n\n\\( \\newcommand{\\inner}[2]{\\langle #1, #2 \\rangle}\\)\n\n\\( \\newcommand{\\Span}{\\mathrm{span}}\\)\n\n\\( \\newcommand{\\id}{\\mathrm{id}}\\)\n\n\\( \\newcommand{\\Span}{\\mathrm{span}}\\)\n\n\\( \\newcommand{\\kernel}{\\mathrm{null}\\,}\\)\n\n\\( \\newcommand{\\range}{\\mathrm{range}\\,}\\)\n\n\\( \\newcommand{\\RealPart}{\\mathrm{Re}}\\)\n\n\\( \\newcommand{\\ImaginaryPart}{\\mathrm{Im}}\\)\n\n\\( \\newcommand{\\Argument}{\\mathrm{Arg}}\\)\n\n\\( \\newcommand{\\norm}[1]{\\| #1 \\|}\\)\n\n\\( \\newcommand{\\inner}[2]{\\langle #1, #2 \\rangle}\\)\n\n\\( \\newcommand{\\Span}{\\mathrm{span}}\\) \\( \\newcommand{\\AA}{\\unicode[.8,0]{x212B}}\\)\n\n\\( \\newcommand{\\vectorA}[1]{\\vec{#1}}      % arrow\\)\n\n\\( \\newcommand{\\vectorAt}[1]{\\vec{\\text{#1}}}      % arrow\\)\n\n\\( \\newcommand{\\vectorB}[1]{\\overset { \\scriptstyle \\rightharpoonup} {\\mathbf{#1}} } \\)\n\n\\( \\newcommand{\\vectorC}[1]{\\textbf{#1}} \\)\n\n\\( \\newcommand{\\vectorD}[1]{\\overrightarrow{#1}} \\)\n\n\\( \\newcommand{\\vectorDt}[1]{\\overrightarrow{\\text{#1}}} \\)\n\n\\( \\newcommand{\\vectE}[1]{\\overset{-\\!-\\!\\rightharpoonup}{\\vphantom{a}\\smash{\\mathbf {#1}}}} \\)\n\n\\( \\newcommand{\\vecs}[1]{\\overset { \\scriptstyle \\rightharpoonup} {\\mathbf{#1}} } \\)\n\n\\( \\newcommand{\\vecd}[1]{\\overset{-\\!-\\!\\rightharpoonup}{\\vphantom{a}\\smash {#1}}} \\)\n\n##### Learning Objectives\n\n## Reflective Writing\n\nReflective writing includes several different components: description, analysis, interpretation, evaluation, and future application. Reflective writers must weave their personal perspectives with evidence of deep, critical thought as they make connections between theory, practice, and learning. The steps below should help you find the appropriate balance among all these factors.\n\n### 1st Step: Review the assignment\n\nAs with any writing situation, the first step in writing a reflective piece is to clarify the task. Reflective assignments can take many forms, so you need to understand exactly what your instructor is asking you to do. Some reflective assignments are short, just a paragraph or two of unpolished writing. Usually the purpose of these reflective pieces is to capture your immediate impressions or perceptions. For example, your instructor might ask you at the end of a class to write quickly about a concept from that day’s lesson. That type of reflection helps you and your instructor gauge your understanding of the concept.\n\nOther reflections are academic essays that can range in length from several paragraphs to several pages. The purpose of these essays is to critically reflect on and support an original claim(s) about a larger experience, such as an event you attended, a project you worked on, or your writing development. These essays require polished writing that conforms to academic conventions, such as articulation of a claim and substantive revision. They might address a larger audience than you and your instructor, including, for example, your classmates, your family, a scholarship committee, etc. It’s important before you begin writing, that you can identify the assignment’s purpose, audience, intended message or content, and requirements.\n\n### 2nd Step: Generate ideas for content\n\nAs you generate ideas for your reflection, you might consider things like:\n\n### 3rd Step: Organize content\n\nResearchers have developed several different frameworks or models for how reflective writing can be structured. For example, one method has you consider the “What?” “So what?” and “Now what?” of a situation in order to become more reflective. First, you assess what happened and describe the event, then you explain why it was significant, and then you use that information to inform your future practice.[[1]](#footnote-110-1 \"Driscoll J (1994) Reflective practice for practise - a framework of structured reflection for clinical areas. Senior Nurse 14 (1):47–50\")[[2]](#footnote-110-2 \"Ash, S.L, Clayton, P.H., & Moses, M.G. (2009). Learning through critical reflection: A tutorial for service-learning students (instructor version). Raleigh, NC.\") Similarly, the DIEP framework can help you consider how to organize your content when writing a reflective piece. Using this method, you *describe* what happened or what you did, *interpret* what it means, *evaluate* its value or impact, and *plan* steps for improving or changing for the future.\n\n##### The DIEP Model of reflective writing\n\nThe DIEP model (Boud, Keogh & Walker,1985) organizes the reflection into four different components:\n\n![Describe what happened, what did you do; Interpret: what does the experience mean to you as a learner; Evaluate: how valuable was the experience?; Plan: what will you do with your learning?](https://human.libretexts.org/@api/deki/files/34277/diep.png?revision=1)\n\nRemember, your goal is to make an interpretive or evaluative claim, or series of claims, that moves beyond obvious statements (such as, “I really enjoyed this project”) and demonstrates you have come to a deeper understanding of what you have learned and how you will use that learning.\n\nIn the example below, notice how the writer reflects on her initial ambitions and planning, the a-ha! moment, and then her decision to limit the scope of a project. She was assigned a multimodal (more than just writing) project, in which she made a video, and then reflected on the experience:\n\n##### Student Example\n\nKeeping a central focus in mind applies to multimodal compositions as well as written essays. A prime example of this was in my remix. When storyboarding for the video, I wanted to appeal to all college students in general. Within my compressed time limit of three minutes, I had planned to showcase numerous large points. It was too much. I decided to limit the scope of the topic to emphasize how digitally “addicted” college students are, and that really changed the project in significant ways.\n\n### 4th Step: Draft, Revise, Edit, Repeat\n\nA single, unpolished draft may suffice for short, in-the-moment reflections, but you may be asked to produce a longer academic reflection essay, which will require significant drafting, revising, and editing. Whatever the length of the assignment, keep this reflective cycle in mind:\n\n##### Watch IT\n\nThe following video, produced by the Hull University Skills Team, provides a great overview of reflective writing. Even if you aren’t assigned a specific reflection writing task in your classes, it’s a good idea to reflect anyway, as reflection results in better learning.\n\nYou can view the [transcript for “Reflective Writing” here (opens in new window)](https://course-building.s3-us-west-2.amazonaws.com/English+Comp/Transcripts/ReflectiveWriting_transcript.txt).\n\n##### Try It\n\nCheck your understanding of reflective writing and the things you learned in the video with these quick practice questions:\n\n<https://h5p.cwr.olemiss.edu/h5p/embed/60>\n\n## Contributors and Attributions\n\nThis page titled [1.18: Reflective Writing](https://human.libretexts.org/Courses/Lumen_Learning/English_Composition_I_(Lumen)/01%3A_Success_Skills/1.18%3A_Reflective_Writing) is shared under a [CC BY 4.0](https://creativecommons.org/licenses/by/4.0) license and was authored, remixed, and/or curated by Lumen Learning via [source content](https://courses.lumenlearning.com/englishcomp1) that was edited to the style and standards of the LibreTexts platform.\n\n## Recommended articles\n\nThe LibreTexts libraries are [Powered by NICE CXone Expert](https://www.nice.com/resources/cxone-expert-knowledge-management)and are supported by the Department of Education Open Textbook Pilot Project, the UC Davis Office of the Provost, the UC Davis Library, the California State University Affordable Learning Solutions Program, and Merlot. We also acknowledge previous National Science Foundation support under grant numbers 1246120, 1525057, and 1413739. [Privacy Policy](https://libretexts.org/privacy \"https://libretexts.org/privacy\"). [Terms & Conditions](https://libretexts.org/terms-conditions \"https://libretexts.org/terms-conditions\"). [Accessibility Statement](https://commons.libretexts.org/accessibility). For more information contact us at[info@libretexts.org](mailto:info@libretexts.org).\n\nTitle: DIEP - Academic Reflection Writing Strategy Guide - Studocu\nURL: https://www.studocu.com/row/document/the-university-of-the-west-indies-mona/critical-reading-and-writing-in-science-and-technology/diep-writing-academic-reflection/78430425\nContent: A guide in how to write a reflection. writing an academic reflection reflective writing aims to help you focus on significant new insights you have gained.\n\nTitle: Reflective Practice Toolkit: Models of reflection - Cambridge LibGuides\nURL: https://libguides.cam.ac.uk/reflectivepracticetoolkit/models\nContent: * Models of reflection The ERA cycle (Jasper, 2013) is one of the most simple models of reflection and contains only three stages: * Reflection We should then reflect on the experience by asking 'so what?' - what did we learn as a result of the experience? As with other models, Gibb's begins with an outline of the experience being reflected on. ## Pros and Cons of Reflective Practice Models Although they can be a great way to start thinking about reflection, remember that all models have their downsides. These are just some of the reflective models that are available. These models provide a useful guide or place to start but reflection is a very personal process and everyone will work towards it in a different way.\nRaw Content: [Skip to Main Content](#s-lg-guide-main)\n\n* [LibGuides](https://libguides.cam.ac.uk/home)\n* [Cambridge Libraries](https://www.libraries.cam.ac.uk/)\n\n# Study Skills\n\n# Reflective Practice Toolkit\n\n* [Introduction](https://libguides.cam.ac.uk/reflectivepracticetoolkit/introduction)\n* [What is reflective practice?](https://libguides.cam.ac.uk/reflectivepracticetoolkit/whatisreflectivepractice)\n* [Everyday reflection](https://libguides.cam.ac.uk/reflectivepracticetoolkit/everydayreflection)\n* [Models of reflection](https://libguides.cam.ac.uk/reflectivepracticetoolkit/models)\n* [Barriers to reflection](https://libguides.cam.ac.uk/reflectivepracticetoolkit/barriers)\n* [Reflective writing](https://libguides.cam.ac.uk/reflectivepracticetoolkit/reflectivewriting) \n  + [Free writing](https://libguides.cam.ac.uk/reflectivepracticetoolkit/freewriting)\n  + [Reflective writing exercise](https://libguides.cam.ac.uk/reflectivepracticetoolkit/writingexercise)\n* [Summary](https://libguides.cam.ac.uk/reflectivepracticetoolkit/summary)\n* [Bibliography](https://libguides.cam.ac.uk/reflectivepracticetoolkit/bibliography)\n\nUnless otherwise stated, this work is licenced under a [CC-BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) licence by Cambridge University Libraries.\n\n## Introduction\n\nIf you are not used to being reflective it can be hard to know where to start the process. Luckily there are many models which you can use to guide your reflection. Below are brief outlines of four of the most popular models arranged from easy to more advanced (tip: you can select any of the images to make them larger and easier to read).\n\nYou will notice many common themes in these models and any others that you come across. Each model takes a slightly different approach but they all cover similar stages. The main difference is the number of steps included and how in-depth their creators have chosen to be. Different people will be drawn to different models depending on their own preferences.\n\n## ERA Cycle\n\nThe ERA cycle (Jasper, 2013) is one of the most simple models of reflection and contains only three stages:\n\n* Experience\n* Reflection\n* Action\n\nThe cycle shows that we will start with an experience, either something we have been through before or something completely new to us. This experience can be positive or negative and may be related to our work or something else. Once something has been experienced we will start to reflect on what happened. This will allow us to think through the experience, examine our feelings about what happened and decide on the next steps. This leads to the final element of the cycle - taking an action. What we do as a result of an experience will be different depending on the individual. This action will result in another experience and the cycle will continue.\n\nJasper, M. (2013). Beginning Reflective Practice. Andover: Cengage Learning.\n\n## Driscoll's What Model\n\nAnother simple model was developed by Driscoll in the mid-1990s. Driscoll based his model of the 3 What's on the key questions asked by Terry Borton in the 1970s:\n\n* What?\n* So what?\n* Now what?\n\nBy asking ourselves these three simple questions we can begin to analyse and learn from our experiences. Firstly we should describe what the situation or experience was to set it in context. This gives us a clear idea of what we are dealing with. We should then reflect on the experience by asking 'so what?' - what did we learn as a result of the experience? The final stage asks us to think about the action we will take as a result of this reflection. Will we change a behavior, try something new or carry on as we are? It is important to remember that there may be no changes as the result of reflection and that we feel that we are doing everything as we should. This is equally valid as an outcome and you should not worry if you can't think of something to change.\n\nBorton, T. (1970) Reach, Touch and Teach. London: Hutchinson.\n\nDriscoll, J. (ed.) (2007) Practicing Clinical Supervision: A Reflective Approach for Healthcare Professionals. Edinburgh: Elsevier.\n\n## Kolb's Experiential Learning Cycle\n\nKolb's model (1984) takes things a step further. Based on theories about how people learn, this model centres on the concept of developing understanding through actual experiences and contains four key stages:\n\n* Concrete experience\n* Reflective observation\n* Abstract conceptualization\n* Active experimentation\n\nThe model argues that we start with an experience - either a repeat of something that has happened before or something completely new to us. The next stage involves us reflecting on the experience and noting anything about it which we haven't come across before. We then start to develop new ideas as a result, for example when something unexpected has happened we try to work out why this might be. The final stage involves us applying our new ideas to different situations. This demonstrates learning as a direct result of our experiences and reflections. This model is similar to one used by small children when learning basic concepts such as hot and cold. They may touch something hot, be burned and be more cautious about touching something which could potentially hurt them in the future.\n\nKolb, D. (1984) Experiential Learning: Experience as the Source of Learning and Development. Upper Saddle River: Prentice Hall.\n\n## Gibb's Reflective Cycle\n\nThe final model builds on the other three and adds more stages. It is one of the more complex models of reflection but it may be that you find having multiple stages of the process to guide you reassuring. Gibb's cycle contains six stages:\n\n* Description\n* Feelings\n* Evaluation\n* Analysis\n* Conclusion\n* Action plan\n\nAs with other models, Gibb's begins with an outline of the experience being reflected on. It then encourages us to focus on our feelings about the experience, both during it an after. The next step involves evaluating the experience - what was good or bad about it from our point of view? We can then use this evaluation to analyse the situation and try to make sense of it. This analysis will result in a conclusion about what other actions (if any) we could have taken to reach a different outcome. The final stage involves building an action plan of steps which we can take the next time we find ourselves in a similar situation.\n\nGibbs, G. (1998) Learning by Doing: A Guide to Teaching and Learning Methods. Oxford: Further Education Unit, Oxford Polytechic.\n\n## Think about ... Which model?\n\nThink about the models outlined above. Do any of them appeal to you or have you found another model which works for you? Do you find models in general helpful or are they too restrictive?\n\n## Pros and Cons of Reflective Practice Models\n\nA word of caution about models of reflective practice (or any other model). Although they can be a great way to start thinking about reflection, remember that all models have their downsides. A summary of the pros and cons can be found below:\n\n#### Pros\n\n* Offer a structure to be followed\n* Provide a useful starting point for those unsure where to begin\n* Allow you to assess all levels of a situation\n* You will know when the process is complete\n\n#### Cons\n\n* Imply that steps must be followed in a defined way\n* In the real world you may not start 'at the beginning'\n* Models may not apply in every situation\n* Reflective practice is a continuous process\n\n## Conclusion\n\nThese are just some of the reflective models that are available. You may find one that works for you or you may decide that none of them really suit. These models provide a useful guide or place to start but reflection is a very personal process and everyone will work towards it in a different way. Take some time to try different approaches until you find the one that works for you. You may find that as time goes on and you develop as a reflective practitioner that you try different methods which suit your current circumstances. The important part is that it works - if it doesn't then you may need to move on and try something else.\n\n* [<< **Previous:** Everyday reflection](https://libguides.cam.ac.uk/reflectivepracticetoolkit/everydayreflection)\n* [**Next:** Barriers to reflection >>](https://libguides.cam.ac.uk/reflectivepracticetoolkit/barriers)\n\n* Last Updated: Sep 4, 2025 3:09 PM\n* URL: https://libguides.cam.ac.uk/reflectivepracticetoolkit\n* [Print Page](javascript: window.print();)\n\n[Login to LibApps](https://uniofcam.libapps.com/libapps/login.php?site_id=5032&target64=L2xpYmd1aWRlcy9hZG1pbl9jLnBocD9nPTY3MTIyMCZwPTQ3NjYyNDQ=)\n\n[Report a problem](mailto:answers@subjects-cam.libanswers.com)\n\n© Cambridge University Libraries | [Accessibility](https://www.lib.cam.ac.uk/web-accessibility-statement)  | [Privacy and cookies policy](https://www.lib.cam.ac.uk/privacy-policy) | [Log into LibApps](https://uniofcam.libapps.com/libguides/)\n\nTitle: Reflective writing - Assessments - Expert help guides at La Trobe ...\nURL: https://latrobe.libguides.com/assessments/reflective-writing\nContent: # Reflective writing ## Reflective writing Reflective writing involves describing your experiences and critically analysing what you’ve learnt from those experiences. * Second, writing your critical reflections to gain insight and knowledge to help you in the future. * Reflecting on events: this may include experiences, tasks or observations during placements, internships or other work. ## Models of reflective writing There are many models to help you reflect on an event or new information. These models can also help you to structure your writing in a reflection. Learn more about Gibbs' reflective writing model in this short video. ## Tips for reflective writing * Reflective writing: Find out what reflective writing is and how to use it in your assignments Bartlett, C., & Derrington, K.\nRaw Content: [Skip to Main Content](#s-lg-guide-main)\n\n\n# Reflective writing\n\n## Reflective writing\n\nReflective writing involves describing your experiences and critically analysing what you’ve learnt from those experiences. There are two steps:\n\n* First, thinking about and analysing your feelings and actions around an experience.\n* Second, writing your critical reflections to gain insight and knowledge to help you in the future.\n\n### Important points on language\n\n* **Pronouns**: In writing reflectively, you can use personal pronouns such as ‘I’ and ‘we’.\n* **Tense**: You should describe events that have already happened in the past tense, but use the present tense for your current evaluation, analysis and conclusion. Use the future tense for any plan of action.\n* **Expression**: Write using the conventions of [academic language](https://latrobe.libguides.com/writing/academic-language)\n\nMake sure you check with teaching staff or your assignment for specific requirements in your subject or discipline.\n\n## Types of reflection\n\n* Reflecting on events: this may include experiences, tasks or observations during placements, internships or other work.\n* Reflecting on new information: this may include new theory or concepts learnt during lectures, assessments, discussions or reading.\n\n## Models of reflective writing\n\nThere are many models to help you reflect on an event or new information. They all follow a common pattern of moving from describing to interpreting and planning the next steps. These models can also help you to structure your writing in a reflection.\n\nIf you haven’t been given specific instructions, use either the What? So what? Now what? or Gibbs model to structure your writing.\n\n## What? So what? Now what?\n\nThe What? So what? Now what? (Rolfe et al., 2001) model is often applied in the Health and Physical Sciences.\n\n### What?\n\nDescription:\n\n* What was the experience or new information?\n* What is your understanding of it? Why did it happen? Who was involved?\n* What was your role and what actions did you (and others) take?\n\n### So what?\n\nInterpretation:\n\n* Why does this matter? What was the impact on you and why?\n* How do you feel about it? How does it connect to you and your learning?\n* Can theory or evidence from literature support your thinking?\n\n### Now what?\n\nOutcome:\n\n* What did you learn from it? What will you do because of this experience?\n* How will you apply what you have learnt in the future?\n* Is there anything more to be understood? What are your next steps?\n\nAdapted from Bartlett and Derrington (2021).\n\n## Gibbs reflective cycle\n\nThe Gibbs Reflective Cycle (Gibbs, 1988) is a 6-step reflective model. It is often applied in Education, Nursing, Engineering and Applied Sciences.\n\n### 1. Description\n\nWhat happened? Where, when and with whom?\n\n**Example:**\n\nDuring my acute placement in palliative care, I was asked by my clinical preceptor to conduct a comprehensive pain assessment on a patient that I had been delegated. The patient had been diagnosed with stage four cancer and was scheduled to undergo Voluntary Assisted Dying (VAD) in the coming days…\n\n### 2. Feelings\n\nWhat were you thinking or feeling when it happened?\n\n**Example:**\n\nI sympathised with the patient and their family about how their initial wishes to undergo the VAD process may no longer be applicable. Although I was aware of this potential outcome, I instigated the matter promptly as I felt concerned that my patient…\n\n### 3. Evaluation\n\nWhat was good and bad about the experience?\n\n**Example:**\n\nWhile this experience offered me opportunities for my own professional development, my patient’s family members may have perceived it as negative, as the changing circumstances made it much more difficult for them to grieve and accept loss…\n\n### 4. Analysis\n\nThis is one of the most important sections of your reflection.\n\n* What can you make of the experience?\n* Why was this experience important to you?\n* Does your analysis incorporate theory or evidence from literature?\n\n**Example:**\n\nTo be eligible for VAD, one must meet the legal criteria, which includes maintaining the mental capacity to make and communicate appropriate decisions for oneself (White et al., 2020). Although my patient was originally given the go-ahead to be considered for VAD, they had started to lose their cognition prior to undergoing the VAD process, therefore, the initial proposal needed to be re-reviewed. This experience was important to me because…\n\n### 5. Conclusion\n\nWhat did you learn? What else could you have done?\n\n**Example:**\n\nThis experience provided me with a practical understanding of how fast a patient can rapidly deteriorate. I also accumulated insights into the legislations affecting one’s ability to make decisions and pursue treatment options and scheduled processes...\n\n### 6. Action Plan\n\nIf it were to happen again, what would you do? How will you apply what you have learnt?\n\n**Example:**\n\nIf I ever encounter similar situations, I will follow the same methods and communication techniques that I demonstrated through this experience. Depending on the organisation or environment, I may now also search for appropriate…\n\nThe above examples have been adapted and used with student permission. For the full sample of a Gibbs reflection with annotations, see the Word and PDF files at the bottom of the page.\n\nLearn more about Gibbs' reflective writing model in this short video.\n\n## Tips for reflective writing\n\n### Do:\n\n* write your reflections as soon as possible after the event\n* discuss with friends or family to get more insight and/or other perspectives\n* focus on both positives and negatives.\n\n### Do not:\n\n* include your own or another person’s personal information\n* include location or any other identifiable information\n* judge or criticize others or yourself too harshly.\n\n**For a full sample of reflective writing with annotations, see the Word and PDF documents below.**\n\n* [Sample Reflective Writing [Word 65kb]](https://latrobe.libguides.com/ld.php?content_id=50238756)\n* [Sample Reflective Writing [PDF 224kb]](https://latrobe.libguides.com/ld.php?content_id=50238762)\n\n## Further resources\n\n* [Reflection Toolkit and examples](https://www.ed.ac.uk/reflection/reflectors-toolkit/reflecting-on-experience)\n\n  Includes other models of reflection such as the 5R framework\n* [Reflective writing: Find out what reflective writing is and how to use it in your assignments](https://www.port.ac.uk/student-life/help-and-advice/study-skills/written-assignments/reflective-writing-introduction)\n\n## Study and research support\n\n**Still have questions? Do you want to talk to an expert? [Peer Learning Advisors or Academic Skills Advisors](https://www.latrobe.edu.au/library/study-and-research-support) are available.**\n\nBartlett, C., & Derrington, K. (2021). Types of assignments. In C. Bartlett, T. Cawthray, L. Clark, S. Conway, K. Derrington, A. Devi, A. Frederiks, L. Gunton, W. Hargreaves, D. Howarth, S. Irvine, M. Jeffers, K. Lovric, R. McGregor, E. Peters, L. Pickstone, B. Retallick, Y. Rose, A. Sahay, ... R. Tweedale (Eds.), *Academic success* (Australian ed., pp. 332-339). University of Southern Queensland. <https://usq.pressbooks.pub/academicsuccess/> Used under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license.\n\nGibbs, G. (1988). *Learning by doing: A guide to teaching and learning methods*. Further Education Unit. Oxford.\n\nRolfe, G., Freshwater, D., & Jasper, M. (2001). *Critical reflection in nursing and the helping professions: a user’s guide*. Palgrave Macmillan.\n\n* [<< **Previous:** Case studies](https://latrobe.libguides.com/assessments/case-studies)\n* [**Next:** Annotated bibliographies >>](https://latrobe.libguides.com/assessments/annotated-bibliographies)\n\nTitle: Reflective writing - students.unimelb.edu...\nURL: https://students.unimelb.edu.au/academic-skills/resources/reading,-writing-and-referencing/reflective-writing/reflective-writing\nContent: Reflective writing gives you an opportunity to think deeply about something you've learned or an experience you've had. Reflective writing may ask you to consider the link between theory (what you study, discuss and read about at university) and practice (what you do, the application of the theory in the workplace). Action verbs are usually expressing feelings and thoughts in reflective writing, e.g. felt, thought, considered, experienced, wondered, remembered, discovered, learned. ***Reflective writing needs to go beyond simply summarising what happened.*** Your reader needs to gain an insight into what the experience meant to you, how you *feel* about it, how it *connects* to other things you’ve experienced or studied and what you plan to *do* in response.\nRaw Content: 1. [Students](https://students.unimelb.edu.au)\n2. [Academic Skills](https://students.unimelb.edu.au/academic-skills)\n3. [Resources](https://students.unimelb.edu.au/academic-skills/resources)\n4. [Reading, writing and referencing](https://students.unimelb.edu.au/academic-skills/resources/reading,-writing-and-referencing)\n5. [Reflective writing](https://students.unimelb.edu.au/academic-skills/resources/reading,-writing-and-referencing/reflective-writing)\n6. [Reflective writing](https://students.unimelb.edu.au/academic-skills/resources/reading,-writing-and-referencing/reflective-writing/reflective-writing)\n\n# Reflective writing\n\nAdvice on how to write reflectively.\n\nReflective writing gives you an opportunity to think deeply about something you've learned or an experience you've had.\n\nWatch the video below for a quick introduction to reflective writing. The video includes an example of reflecting on practice, but the approach is equally useful when reflecting on theory.\n\n## Video tutorial\n\n## Reflecting on practice\n\nReflective writing may ask you to consider the link between theory (what you study, discuss and read about at university) and practice (what you do, the application of the theory in the workplace). Reflection on practical contexts enables you to explore the relationship between theory and practice in an authentic and concrete way.\n\n### Examples\n\n* ### \n\n  *\"Yesterday’s class brought Vygotsky’s concepts of scaffolding and the ‘significant other’ into sharp focus for me. Without instruction, ‘Emily’ was able to scaffold ‘Emma’s’ solving of the Keystone Puzzle without directing her or supplying her with the answer – she acted as the ‘significant other’. **It really highlighted for me** the fact that I do not always have to directly be involved in students’ learning, and that students have learning and knowledge they bring to the classroom context.\"*\n\n  #### What this example does well:\n\n  + Links theory to practice.\n  + Clearly states where learning occurred.\n\n  #### Tip\n\n  De-identify actual people you have observed or dealt with on placement or work experience using pseudonyms (other names, job titles, initials or even numbers so that real identities are protected). E.g.:\n\n  + \"It was great to observe ‘Lee’ try to...\"\n  + \"Our team leader’s response was positive…\"\n  + \"I observed G’s reaction to this...\"\n  + \"Student Four felt that this was…\"\n* ### \n\n  *\"The lectures and tutes this semester **have broadened my views** of what sustainability is and the different scales by which we can view it**. I learned that** sustainability is not only something that differs at an individual level in terms of how we approach it ourselves, but also how it differs in scale. We might look at what we do individually to act sustainably, such as in what and how we recycle, but when we think about how a city or state does this, we need to consider pollution, rubbish collection and a range of other systems that point to sustainability on a much larger scale.\"*\n\n  #### What this example does well:\n\n  + Clearly states where learning occurred\n  + Elaborates on key issues\n  + Gives examples.\n* ### \n\n  *\"On the ward rounds yesterday, I **felt** Mr G’s mobility had noticeably improved from last week. This may be due to the altered physio program we have implemented and it allowed me to **experience** a real **feeling** of satisfaction that I had made a real difference.\"*\n\n  #### Tip\n\n  Action verbs are usually expressing feelings and thoughts in reflective writing, e.g. felt, thought, considered, experienced, wondered, remembered, discovered, learned.\n\n## Reflecting on theory\n\nSome reflection tasks are purely theoretical, where you are asked to consider texts you have read, or ideas you may have discussed in tutorials, and reflect on them.\n\n### Example\n\n* ### \n\n  *\"Comparing the approaches of **Mayr and Ulich (2009)** and **Laevers (2005)** to what 'wellbeing' means for the early childhood setting was **very illustrative in that I discovered** they seek to do similar things but within different frameworks. Analysing the two constructs highlighted that the detail in Mayr and Ulich’s framework provided a much richer framework in defining and measuring wellbeing than Laevers’ does.\"*\n\n  #### What this example does well:\n\n  + Clearly states where learning occurred.\n  + References correctly.\n  + Considers what the theory has shown.\n\n## Using the DIEP model\n\nWhen writing reflectively for the first time, it’s not uncommon to produce a summary or description of the event or experience without deeply reflecting on it.\n\n***Reflective writing needs to go beyond simply summarising what happened.*** Your reader needs to gain an insight into what the experience meant to you, how you *feel* about it, how it *connects* to other things you’ve experienced or studied and what you plan to *do* in response.\n\nTo be sure you don’t leave out any of these critical elements of reflection, consider writing using the describe, interpret, evaluate, plan (DIEP) model to help.\n\nDIEP approach adapted from: [RMIT Study and Learning Centre. (2010). Reflective writing: DIEP](https://learninglab.rmit.edu.au/assessments/reflective-writing/how-use-diep/).\n\n### Tip\n\nYou can and should refer to yourself in your reflection using personal pronouns, e.g. I, we...\n\n### DIEP:\n\n* ### \n\n  **Begin by describing the situation.** What did you see, hear, do, read or see? Be as brief and objective as possible.\n\n  **Starting phrases:**\n\n  + *The most interesting insight from my lecture this week is ...*\n  + *A significant issue I had not realised until now is ...*\n  + *I now realise (understand ...) that ...*\n* ### \n\n  **Interpret what happened.** What new insights have you gained? How does this experience connect with other things you’ve learned or experienced before? How did the experience make you feel?\n\n  **Starting phrases:**\n\n  + *This experience idea is relevant to me because…*\n  + *This reminded me of the idea that…*\n  + *A possible implication could be…*\n* ### \n\n  **Make a judgement.** How useful was this experience for you? What is your opinion? Why do you think this might be?\n\n  **Starting phrases:**\n\n  + *Having realised the importance of ..., I can now understand…*\n  + *This experience will change the way I view ...*\n  + *Being able to see… in this way is extremely valuable for me because…*\n* ### \n\n  **Comment on how this experience might inform your future thoughts or actions.** How could you apply what you’ve learned from the experience in the future? How might the experience relate to your degree or future professional life?\n\n  **Starting phrases:**\n\n  + *This is beneficial to me as my future career requires…*\n  + *In order to further develop this skill…I will…*\n  + *Next time…I will…by…*\n\n### Example\n\n* ### \n\n  *[TS] The most surprising insight I have gained so far is how important recording and distributing succinct and accurate information is to the success of the project. [D] In the first week of my internship, I was asked to record some meeting minutes and distribute them to the project team and the client. [I] I initially felt offended as the task appeared trivial to me; it was something we rarely did during team meetings at university. [E] However, after speaking with my industry supervisor, I began to understand how important it is to keep a clear record of the meaningful points raised during meetings. [I] Making accurate notes of the key outcomes was harder than I expected as the rest of my team was relying on my minutes to know what they needed to do. [D]After reviewing my minutes, my supervisor agreed that they were sufficiently clear and accurate. [I] I’ve realised that poorly recorded minutes could have resulted in missed deadlines, miscommunication and costly implications for our contract. [P] To improve my ability to take notes I plan on reviewing the minutes made by my colleagues for other meetings and to investigate note taking techniques such as mind mapping (Trevelyan, 2014). Mind mapping uses links and annotations to record relationships between words and indicate significance. [I] This will help me to continue to develop my skills in this area and develop my ability to “prepare high quality engineering documents” as part of attaining the Stage 1 competency of written communication (Engineers Australia, 2018).*\n\n  Trevelyan, J. P. (2014). *The making of an expert engineer: How to have a wonderful career creating a better world and spending lots of money belonging to other people*. Leiden, The Netherlands: CRC Press/Balkema.\n\n## Editing\n\nAsk yourself:\n\n1. Have I based my reflection on a specific incident, activity, idea or example?\n2. Have I sufficiently critically analysed the situation?\n3. Have I integrated theory in a meaningful way? Can I elaborate further to demonstrate the relevance of the idea and my understanding of it?\n4. Are my plans specific enough? Can I be more concrete?\n\n### Tip\n\nWhen editing your draft, try colour coding each element of DIEP to be sure you have a balance of elements.\n\n## Looking for one-on-one advice?\n\nGet tailored advice from an Academic Skills Adviser by booking an Individual appointment, or get quick feedback from one of our Academic Writing Mentors via email through our Writing advice service.\n\n[Go to Student appointments](https://students.unimelb.edu.au/academic-skills/student-appointments)\n\n \n\nTitle: How to Write Reflectively | OISE Academic Skills Hub\nURL: https://www.oise.utoronto.ca/skillshub/resources/how-write-reflectively\nContent: Aside from following the rubric provided by your professor/course instructor, reflective writing requires you to achieve thoughtful inquiry that demonstrates your understanding by unpacking your assumptions and knowledge to deepen your analysis of the course material or your practical experiences. To help you understand what it means to engage critically, dig deeper into your assumptions about experiences/materials that you have encountered in class, and reflect on why you may have these assumptions, its important to understand the difference between explicit and tacit knowledge. However, **accessing tacit knowledge is key to writing reflectively** as it opens the door to understanding our underlying assumptions and provides a way for us to begin engaging in deep thinking and engagement with course materials or experiences.\nRaw Content: # How to Write Reflectively\n\nHow to Write Reflectively\n\n## Table of Contents\n\n* [Introduction](#intro)\n* [What is Explicit and Tacit Knowledge in Reflective Writing?](#whatis)\n* [How Can I Access Tacit Knowledge?](#how)\n* [How to Write Reflectively](#strategies)\n* [Our Tips](#tips)\n* [Help & Additional Resources](#help)\n\nBreadcrumb\n\n1. [Home](/skillshub/)\n2. Resources\n\nSkills Categories:\n\n[Academic writing](/skillshub/taxonomy/term/39)\n\nSkills Keywords:\n\n[Reflective writing](/skillshub/taxonomy/term/53)\n\n## This Resource Page will help you:\n\n* Identify and understand how to use various tools and strategies to engage in multiple forms of reflective writing (e.g., weekly reflections, experiential reflections, critical reflections).¯\n* Understand how reflective writing can be used within various class assignments.\n\n## Introduction\n\nAside from following the rubric provided by your professor/course instructor, reflective writing requires you to achieve thoughtful inquiry that demonstrates your understanding by unpacking your assumptions and knowledge to deepen your analysis of the course material or your practical experiences. In short, the key to reflective writing is to **go beyond description and move into analysis**.\n\nTo learn more about what reflective writing is, check our Resource Page on [What is Reflective Writing](https://www.oise.utoronto.ca/skillshub/node/41).\n\n## What is Explicit and Tacit Knowledge in Reflective Writing?\n\nTo help you understand what it means to engage critically, dig deeper into your assumptions about experiences/materials that you have encountered in class, and reflect on why you may have these assumptions, its important to understand the difference between explicit and tacit knowledge.\n\n***Explicit knowledge*** is what we understand or see on the surface.\n\nWhen we do not actively engage with our explicit knowledge through critical reflection, we reach a shallow understanding of the concepts, ideas, or materials that we are engaging with.\n\nFor example, by observation, we can see that the sky is blue  but we cant explain *why* the sky is blue.\n\n***Tacit knowledge*** can be difficult to explain because it is influenced by our experiences and level of engagement with literature. In general, understanding what tacit knowledge is comes down to the question of why *(e.g., why do I think x; why I reacted this way; why do I disagree with this author; why do I think these readings align or do not align with my experiences).* Going back to the blue sky example, tacit knowledge goes beyond our observation that the sky is blue and allows us to explain why the sky is blue.\n\nWhile the question of why seems simple, it can become difficult to unpack. However, **accessing tacit knowledge is key to writing reflectively** as it opens the door to understanding our underlying assumptions and provides a way for us to begin engaging in deep thinking and engagement with course materials or experiences.\n\n## How Can I Access Tacit Knowledge?\n\nWhen writing reflectively, the first step is accessing our tacit knowledge. One strategy that helps us do this is ***freewriting.***\n\n### What is freewriting?\n\nFreewriting is a pre-writing technique to uncover and identify thoughts surrounding a topic without the pressure of following academic writing conventions. It involves writing continuously, without outlining, in sentence or paragraph form within a set period of time.\n\n### Why Should I Freewrite?\n\nBy removing the pressure and expectations of academic writing conventions, we can focus those 10-15 minutes on the topic or experience we are being asked to reflect on. When engaging in reflective writing, normally, the first few minutes of writing is about explicit knowledge. However, as we are asked to engage in continuous writing, we may begin to uncover underlying connections and assumptions we werent aware of that we can now identify and decide if we want to further engage with through reflective writing.\n\n### How Can I freewrite?\n\nWhile you can tailor freewriting to your needs, here is a general freewriting structure:\n\n1. Open a fresh document or notebook page.\n2. Set a timer. A common amount of time to freewrite is 10-15 minutes.\n3. Write continuously, as much as possible. Dont let your pen leave the page.\n4. Step away for 15 to 30 minutes.\n5. Review your freewriting and identify any standout ideas or assumptions you want to explore further through critical reflection.\n\n**Tip**: if you are an auditory thinker, it may be helpful to record yourself talking about the idea or topic you are engaging with, rather than writing about it.\n\n## How to Write Reflectively\n\nOnce you have completed freewriting and have identified any standout ideas or assumptions you would like to focus on, you can begin to use the following strategies/tools to help you deepen your reflection.\n\n## Strategy 1: Guiding Questions\n\nThe following are guiding questions for experiential and reading reflections. These questions can be used to help you further develop and unpack the ideas, connections, and/or assumptions you uncovered when freewriting.\n\nAssessing the text(s):\n\n1. What is the main point? How was it developed?\n2. Identify the purpose, impact, and/or theoretical framework of the text.\n3. What do I know about this topic? Where does my existing knowledge come from? What observations or experiences I have had that shape my understanding of this text?\n\n Develop your ideas:\n\n1. What do I know about this topic? Where does my existing knowledge come from? What observations or experiences that I have had shape my understanding of this text?\n2. How does this text help me better understand this topic or explore this field of study/discipline?\n\nIn general, when engaging in experiential reflection writing assignments, it is important to connect concepts from class to your personal or experiential learning opportunity.\n\n1. What were your learning goals before starting your practicum, placement, internship, or experiential learning opportunity?\n2. What is the name of the host organization? What is their mission? What are the objectives of the organization? Who do they serve? What was your role? What did you do?\n3. What did you learn from this experience? About yourself? About working in the field? About society? Try to link your learning from your experience to concepts that you encountered in your course.\n4. Did your experience fit with the goals or concepts of the course? Why or why not? What are the lessons learned that you would carry forward in the future? What was successful, and why? What would you do differently, and why?\n\n## Strategy 2: Outlining\n\nThe following section illustrate two outlining methods: DIEP Model and Gibbs Reflective Model. These methods are great for those who are new to reflective writing. If you have more experience in reflective writing, these approaches can be helpful in prompting your thinking or ensuring that you have hit common components of reflective writing assignments.\n\nDIEP stands for **Describe/Summarize, Interpret, Evaluate, and Plan**. This model can be used for a variety of reflective writing assignments you may encounter in your studies such as reading reflections; weekly journals; and self-assessments.\n\nWhile each question in the DIEP model can help you determine what pieces of your writing goes where, they can also be used to help prompt your thinking.\n\n1. Describe: What did you read? Be as brief and as objective as possible. It may help to use the following phrases:\n\n* What I found interesting from the lecture this week is¦\n* A significant issue I had not realized until¦\n* I now understand¦that¦\n\n2. Interpret: What new insights have you gained? How does this reading connect with other experiences or concepts you have learned before? It may help to use the following phrases:\n\n* This experience is relevant to me because¦\n* This concept relates to another concept that I learned about in¦\n\n3. Evaluate: How useful was this reading for you? What is your opinion, did it change from before? Why do you think this might be? It may help to use the following phrases:\n\n* Having realized the importance of¦ I now understand¦\n* This reading will change the way I view¦\n* Being able to see¦ in this way is valuable for me because¦\n\n4. Plan: How can you apply what you have learned in the future? How does this reading relate to the rest of the course or studies?\n\n* This is beneficial to my future research because¦\n* I need to develop my understanding of¦\n\n> **[Topic sentence]** The most surprising insight I have gained so far is how important recording and distributing succinct and accurate information is to the success of the project.¯**[Description]** In the first week of my internship, I was asked to record some meeting minutes and distribute them to the project team and the client.¯[I] I initially felt offended as the task appeared trivial to me; it was something we rarely did during team meetings at university.¯**[Evaluate]** However, after speaking with my industry supervisor, I began to understand how important it is to keep a clear record of the meaningful points raised during meetings.¯[Interpret] Making accurate notes of the key outcomes was harder than I expected as the rest of my team was relying on my minutes to know what they needed to do.¯**[Description]** After reviewing my minutes, my supervisor agreed that they were sufficiently clear and accurate.¯[Interpret] Ive realised that poorly recorded minutes could have resulted in missed deadlines, miscommunication and costly implications for our contract.¯[Plan] To improve my ability to take notes I plan on reviewing the minutes made by my colleagues for other meetings and to investigate note taking techniques such as mind mapping (Trevelyan, 2014). Mind mapping uses links and annotations to record relationships between words and indicate significance.¯[Interpret] This will help me to continue to develop my skills in this area and develop my ability to prepare high quality engineering documents as part of attaining the Stage 1 competency of written communication (Engineers Australia, 2018).\n\nTrevelyan, J. P. (2014).¯*The making of an expert engineer: How to have a wonderful career creating a better world and spending lots of money belonging to other people*. Leiden, The Netherlands: CRC Press/Balkema.\n\nGibbs reflective model (1988) is best used to help outline experiential reflections. This model helps you break down your experience into manageable chunks that allow you to structure your assignment:\n\n1. Introduction or description of experience\n\n* What happened?\n\n2. Feelings\n\n* What were you thinking?\n\n3. Evaluation\n\n* What was good and bad about the experience?\n\n4. Analysis\n\n* What can you make of the situation? How does it relate to the concepts you learned in class?\n\n5. Conclusion\n\n* What else could you have done within your placement?\n\n6. Action Plan\n\n* If the situation you are reflecting on arose again, what would you do differently?\n\n**Tip:** While it is tempting to describe our experiences in detail, when engaging in reflective writing, avoid being too descriptive. Remember, reflective writing invites you to **practice critical reflection by going beyond explicit knowledge**. Therefore, your analysis of your experience needs to be the substance of your assignment.\n\n**[Description]** Currently, I am on a teaching placement and have just started planning and delivering sections of each lesson. My first session did not go as well as I hoped. My task was to assist students in understanding fractions  because it was my first time, I felt nervous, so I fumbled around. While the students were understanding, the supervising teacher took over because we were running out of time.\n\n**[Feelings]** I felt miserable, and at the time, considered pausing my teacher placement. I was embarrassed by how I managed my nerves and frustrated at how the supervising teacher managed the situation.\n\n**[Evaluation & Analysis]** Now, I did not feel that the situation had been managed well or resolved.  In class, we read Greene (2014), who explains that nine out of ten new trainee teachers found their first session incredibly daunting(p.43). It appears that most trainee teachers have moments of being tongue-tied and losing their way with the lesson (Parbold, 2009, p.223). This validated my experiences. In addition, I remember reading from Cooper (2011), that it is best to acknowledge and address these situations as soon as they happen.\n\n**[Conclusion]** In retrospect, I would do several things differently. I should have spoken to the class teacher immediately after the session and voiced my concerns. That way we could have found a way that we both could support my learning as well as the classroom environment.\n\n**[Action Plan]** In future, I will make sure to build up more of a relationship with colleagues. I am working alongside several different teachers during my placement, and I will speak to each of them about my nerves and find a way to create an environment that is conductive for everyone in the space. I think this can look like making sure I have enough time to prep ahead of time as well as ensuring that when my portion of the lesson comes, we are in less of a time crunch.\n\nTo see more examples of reflective writing, see our Resource Page on [What is Reflective Writing](https://www.oise.utoronto.ca/skillshub/node/41).\n\n## Strategy 3: Reflective Language\n\nThe following phrases can help you generate sentences to enhance the flow of your reflective writing. Choose an element from each column and complete your sentence.\n\nFor me, the (most)...\n\n|  |  |  |\n| --- | --- | --- |\n| meaningful | aspects(s) | was/were¦ |\n| significant | elements(s) | arose from.... |\n| important | issues(s) | happened when¦ |\n| relevant | idea(s) | resulted from¦ |\n| useful | lesson(s) | were... |\n\n**Example:** For me, the most relevant ideas resulted from the students' feedback.\n\n|  |  |  |\n| --- | --- | --- |\n| **Previously,** | I | thought (did not think) |\n| **At the time,** | felt (did not feel) |\n| **At first,** | know (did not know) |\n| **Initially,** | noticed (did not notice) |\n| **Subsequently,** | question (did not question) |\n|  | realized (did not realize) |\n\n**Example:** Initially, I did not realize how I could apply Critical Race Theory within my practicum experience. However, after assisting my supervising teacher with curriculum planning, I am beginning to understand the connection between theory and practice  especially in relation to selecting childrens literature.\n\n|  |  |  |  |\n| --- | --- | --- | --- |\n| **Having** | read¦ | **I now** | feel¦ |\n| experienced¦ | think¦ |\n| applied¦ | realize¦ |\n| analysed¦ | wonder¦ |\n| learned¦ | question¦ |\n|  | know¦ |\n\n**Example:** Having read Bell Hooks (1991) Theory as a Liberatory Practice I now know how critical theory is related to resistance as it evolves from the continuous work of resisting social construction that is bounded by whiteness.\n\n## Our Tips\n\n* **Be selective**. Regardless of the kind of reflective writing assignment, it is important to be **selective** in your writing. This means that you do not need to discuss every detail of your experience or reading. Instead, pick a few stand-out experiences or ideas that are relevant for your learning or research needs.\n* **Read effectively**. When engaging in reflective writing, it is key that you identify the main arguments or important elements of the text to strengthen your analysis. For more info on how to find main points in your readings, check our Resource Page on [How to Read Academic Articles](https://www.oise.utoronto.ca/skillshub/node/49).\n* **Use the appropriate tone**. While you should use a formal tone in your writing, it is acceptable to write in the first person and use personal pronouns. If you are not sure about what level of formality you should use, check with your instructor.\n\n## Help & Additional Resources\n\n### Related Resource Pages on ASH\n\n* [What is Reflective Writing](https://www.oise.utoronto.ca/skillshub/node/41)\n* [What are Stance & Voice and How to Apply them in Academic Writing](https://www.oise.utoronto.ca/skillshub/node/48)\n* [How to Read Academic Articles](https://www.oise.utoronto.ca/skillshub/node/49)\n* [How to Write Paragraphs](https://www.oise.utoronto.ca/skillshub/node/40)\n* [How to Summarize](https://www.oise.utoronto.ca/skillshub/node/36)\n* [How to Paraphrase](https://www.oise.utoronto.ca/skillshub/node/25)\n* [How to Talk to your Readers: Signposting](https://www.oise.utoronto.ca/skillshub/node/50)\n* [How to Write Cohesively](https://www.oise.utoronto.ca/skillshub/node/51)\n\n### On Campus Services\n\n* [Book a writing consultation (OSSC)](https://www.oise.utoronto.ca/current-students/ossc)\n\n "
      }
    ]
  }
]

---

### User
> 11/30/2025, 3:48:40 PM

[
  {
    "tool_use_id": "toolu_01Mow8EbFLv4wVnpz72Ru1Q8",
    "type": "tool_result",
    "content": [
      {
        "type": "text",
        "text": "Detailed Results:\n\nTitle: [PDF] HERRMANN EXAMPLE\nURL: https://www.thinkherrmann.com/hubfs/CP_Site/Individual%20Sample%20Report.pdf\nContent: HBDI ® HERRMANN BRAIN DOMINANCE INSTRUMENT® HERRMANN EXAMPLE ©2019 Herrmann Global https://www.thinkherrmann.com/ HBDI ® High Preference (Preference Code = 1) Intermediate Preference (Preference Code = 2) Low Preference (Preference Code = 3) HERRMANN EXAMPLE Very High Preference (Preference Code = 1) Preference Code 1 2 2 1 Profile Scores 90 55 48 71 Under Pressure 77 66 55 66 A B C D 10 20 30 40 50 60 70 80 90 100 110 120 130 61% 55% 39% 45% ©2019 Herrmann Global https://www.thinkherrmann.com/ HBDI ® ADOLESCENT EDUCATION INTROVERSION / EXTROVERSION analytical ♦ critical factual logical mathematical quantitative rational analytical 5 financial 4 problem solving 5 technical 1 A QUADRANT UPPER LEFT 90 1 77 conservative controlled detailed dominant reader sequential speaker administrative 3 implementation 4 organization 3 planning 5 B QUADRANT LOWER LEFT 55 2 66 emotional intuitive musical reader spiritual symbolic talker expressing 2 interpersonal 2 teaching/training 4 writing 3 C QUADRANT LOWER RIGHT 48 2 55 artistic holistic imaginative intuitive simultaneous spatial synthesizer conceptual 5 creative 4 innovating 3 integration 2 D QUADRANT UPPER RIGHT 71 1 66 introvert ambivert extrovert ♦ day both night ♦ EDUCATIONAL FOCUS OCCUPATION HOBBIES Date BUSINESS MANAGER ENERGY LEVEL DATA SUMMARY Name Occupation HERRMANN EXAMPLE 03/22/2019 PROFILE SCORES PREFERENCE CODE UNDER PRESSURE KEY DESCRIPTORS ♦ = MOST DESCRIPTIVE WORK ELEMENTS 5 = WORK YOU DO BEST 1 = WORK YOU DO LEAST WELL ©2019 Herrmann Global https://www.thinkherrmann.com/ HERRMANN EXAMPLE March 22,\nRaw Content: HBDI ® HERRMANN BRAIN DOMINANCE INSTRUMENT® HERRMANN EXAMPLE ©2019 Herrmann Global https://www.thinkherrmann.com/ HBDI ® High Preference (Preference Code = 1) Intermediate Preference (Preference Code = 2) Low Preference (Preference Code = 3) HERRMANN EXAMPLE Very High Preference (Preference Code = 1) Preference Code 1 2 2 1 Profile Scores 90 55 48 71 Under Pressure 77 66 55 66 A B C D 10 20 30 40 50 60 70 80 90 100 110 120 130 61% 55% 39% 45% ©2019 Herrmann Global https://www.thinkherrmann.com/ HBDI ® ADOLESCENT EDUCATION INTROVERSION / EXTROVERSION analytical ♦ critical factual logical mathematical quantitative rational analytical 5 financial 4 problem solving 5 technical 1 A QUADRANT UPPER LEFT 90 1 77 conservative controlled detailed dominant reader sequential speaker administrative 3 implementation 4 organization 3 planning 5 B QUADRANT LOWER LEFT 55 2 66 emotional intuitive musical reader spiritual symbolic talker expressing 2 interpersonal 2 teaching/training 4 writing 3 C QUADRANT LOWER RIGHT 48 2 55 artistic holistic imaginative intuitive simultaneous spatial synthesizer conceptual 5 creative 4 innovating 3 integration 2 D QUADRANT UPPER RIGHT 71 1 66 introvert ambivert extrovert ♦ day both night ♦ EDUCATIONAL FOCUS OCCUPATION HOBBIES Date BUSINESS MANAGER ENERGY LEVEL DATA SUMMARY Name Occupation HERRMANN EXAMPLE 03/22/2019 PROFILE SCORES PREFERENCE CODE UNDER PRESSURE KEY DESCRIPTORS ♦ = MOST DESCRIPTIVE WORK ELEMENTS 5 = WORK YOU DO BEST 1 = WORK YOU DO LEAST WELL ©2019 Herrmann Global https://www.thinkherrmann.com/ HERRMANN EXAMPLE March 22, 2019 This explanation page will describe each of the four quadrants in the descending order of your preferences and will point out your choices of Key Descriptors which represent a general overview of your mental preferences in day-to-day life, and the Work Elements you strongly relate to. The Work Elements reflect your mental preferences at work. Work preferences may align completely with general preferences, or they may stem from situations unique to one's working environment. This report will also review your forced choices from the Adjective Pairs section of the HBDI®. Your forced choices in this section will often represent how your thinking is impacted in \"Under Pressure\" situations.\nMost Preferred: A The A Quadrant with a score of 90.\nIn this quadrant the Key Descriptors you selected were: logical, critical, rational, and analytical.\nAnd you indicated that analytical is the one most descriptive of you.\nWork Elements you strongly relate to in this quadrant were: analytical, problem solving, and financial aspects.\n29% of your \"Under Pressure\" responses registered in the A Quadrant, compared to 34% of your overall Profile.\nNext Preferred: D The D Quadrant with a score of 71.\nIn this quadrant the Key Descriptors you selected were: holistic and synthesizer.\nWork Elements you strongly relate to in this quadrant were: conceptualizing and creative aspects.\n25% of your \"Under Pressure\" responses registered in the D Quadrant, compared to 27% of your overall Profile.\nNext Preferred: B The B Quadrant with a score of 55.\nIn this quadrant the one Key Descriptor you chose was: detailed.\nWork Elements you strongly relate to in this quadrant were: planning and implementation.\n25% of your \"Under Pressure\" responses registered in the B Quadrant, compared to 21% of your overall Profile.\nAnd Finally: C The C Quadrant with a score of 48.\nIn this quadrant the one Key Descriptor you chose was: emotional.\nThe one Work Element you strongly relate to in this quadrant is: teaching/training.\n21% of your \"Under Pressure\" responses registered in the C Quadrant, compared to 18% of your overall Profile.\nYour preferred \"flow\" of thinking, from highest preference to lowest preference from your overall choice is: A > D > B > C.\nAnd your preferred \"flow\" of thinking when \"under pressure\" is somewhat different: A > B > D > C.\nThis suggests that there may be some shifts in your thinking style when \"under pressure\", perhaps with a less-preferred quadrant becoming more dominant or a generally preferred one receding into the background.\n©2019 Herrmann Global https://www.thinkherrmann.com/ HERRMANN EXAMPLE HERRMANN EXAMPLE HERRMANN EXAMPLE 61% 55% 39% 45% Problem Solver Mathematical Technical Analyzer Logical Talker Musical Spiritual Emotional Interpersonal Planner Controlled Conservative Organizational Administrative Conceptualizer Imaginative Synthesizer Artistic Holistic Does it acknowledge emotional issues?\nDoes it use experiences that relate to the audience?\nExamples to illustrate point?\nIs it helpful and user friendly?\nIs it visual and colorful?\nDoes it use metaphors?\nDoes it look at the future?\nIs it conceptually sound or clear?\nDoes it look at the big picture or overview?\nDoes it provide details?\nIs it in sequential order?\nIs it in an 'appropriate' format?\nIs it neat?\nDoes it use facts?\nIs it quantified?\nDoes it show clear analysis?\nIs it logical and to the point?\nC B HBDI® Profile D HERRMANN EXAMPLE C D B A 1 2 2 1 Use Whole Brain® Communication COMMUNICATION WALK-AROUND Logical, analytical, technical, financial Organizer, planned, detailed, business Integrative, imagination, insightful, visionary Interpersonal, emotional, people oriented, helpful FACTS FUTURES TYPICAL STRENGTHS AT WORK BY QUADRANT • Forming theories • Gathering facts, analyzing issues • Measuring precisely • Problem solving logically • Financial and critical analysis • Understanding technical elements • Working with numbers, statistics, data and precision • Seeing 'the big picture' • Recognizing new possibilities • Integrating ideas & concepts • Challenging established policies • Synthesizing unlike elements into a new whole • Inventing solutions to problems • Problem solving in intuitive ways • Finding overlooked flaws • Approaching problems practically • Maintain a standard of consistency • Reading fine print in documents • Organizing and keeping track of data • Developing detailed plans/procedures • Keeping financial records straight • Recognizing interpersonal difficulties • Anticipating how others will feel • Picking up the non-verbal cues • Engendering enthusiasm • Persuading, conciliating • Understanding emotional elements • Sharing FORM FEELINGS A ©2019 Herrmann Global https://www.thinkherrmann.com/\n\nTitle: HBDI | Leadership Assessment & Whole Brain Thinking\nURL: https://theleadershipsphere.com.au/programs-and-services/leadership-assessment-and-profiling-toolkit/hbdi/\nContent: The HBDI® assesses the thinking styles of individuals and teams. By learning to recognise and understand thinking styles and preferences, they’ll experience an immediate improvement in their ability to communicate, to collaborate, to generate ideas, to solve problems and make decisions. * Understand the Whole Brain® Model and the concept of thinking preferences. Download a real sample of the Herrmann Brain Dominance Instrument® (HBDI®) report and see exactly how thinking preferences are mapped across the Whole Brain® Model. If you’re exploring the Start Thinking™ program or considering HBDI® for leadership, communication, or team performance initiatives, this report shows exactly what you can expect. Over 14+ years we have delivered leadership workshop, courses and programs for individuals and executive leadership teams in 200+ organisations.\nRaw Content: # Herrmann Brain Dominance Instrument® (HBDI®)\n\nThe HBDI® assesses the thinking styles of individuals and teams. The Whole Brain® Thinking approach assists organisations, teams and individuals to measure and harness cognitive diversity.\n\nCONTACT US\n\n[BOOK A CONSULTATION](https://theleadershipsphere.pipedrive.com/scheduler/X9MYYktG/the-leadership-sphere-discovery-call)\n\n## What is Whole Brain® Thinking?\n\nAs the basis of Whole Brain® Thinking, HBDI teaches you how to communicate both with those who think the same as you and those who think differently.\n\nOnce someone understands their thinking style preferences, the door is open to improved:\n\n* teamwork\n* leadership\n* customer relationships\n* creativity\n* problem-solving\n* other dimensions of personal and interpersonal development\n\nThe 116-question HBDI assessment evaluates and describes the degree of preference individuals have for thinking in each of the four quadrants, as depicted by the Herrmann Whole Brain® Model.\n\nMore than thirty years of research and innovation stand behind the HBDI, which was developed in the 1970s by Ned Herrmann (then a manager at General Electric).\n\n## Who is the HBDI® for?\n\nResearch has shown that we can all learn to diagnose and adapt to the thinking preferences of others. Presenting information in a way that recognises, respects and is compatible with different preferences is crucial to meeting colleague and client needs.\n\nThe Start Thinking™ program is recommended for:\n\n* Executives;\n* Senior leaders;\n* Managers;\n* Teams of all levels\n\nOver 3 million people around the world have taken the HBDI. Leading academic institutions and organisations of all sizes and industries, including 97% of Fortune 100 companies, are using the HBDI and Whole Brain® Thinking techniques to get better results in their mission-critical areas.\n\nDOWNLOAD SAMPLE\n\n## HBDI® program options\n\n#### Start Thinking™\n\nResearch has shown that we can all learn to diagnose and adapt to the thinking preferences of others. Presenting information in a way that recognises, respects and is compatible with different preferences is crucial to meeting colleague and client needs.\n\nThe Start Thinking™ program is recommended for:\n\n* Executives;\n* Senior leaders;\n* Managers;\n* Teams of all levels\n\nOver 3 million people around the world have taken the HBDI®. Leading academic institutions and organisations of all sizes and industries, including 97% of Fortune 100 companies, are using the HBDI® and Whole Brain® Thinking techniques to get better results in their mission-critical areas.\n\n[BOOK A 15MIN CONSULTATION](#contact-us)\n\n#### The TLS Sales System\n\nThe power of this program is not just in the process – it is in the underlying principle: that making sales is all about communication and relationships.\n\nAt the end of this program your team will:\n\n* understand themselves better, especially how they think and communicate\n* know how to use this model and approach clients in new ways\n* quickly build trust and demonstrate value, the way the client needs to hear and see it presented\n\nUnderpinning a sales process with the HBDI® and a Whole Brain® approach will give your team the ability to connect, respond, influence and relate to existing and potential clients with ease. This results in higher levels of trust, a better ability to ‘flex’ in response to the audience and increased conversion rates.\n\n[BOOK A 15MIN CONSULTATION](#contact-us)\n\n## 3 Simple Steps to HBDI®\n\n#### Step 1\n\nBook a consultation with one of our senior learning specialists.\n\n#### Step 2\n\nWork with us to create a custom plan based on what you need.\n\n#### Step 3\n\nDeliver the program, along with evidence it creates real change.\n\n## Connect with us\n\nTalk to us about the results you need. We’ll show you some options for getting there. And then together we’ll deliver a program your people will love.\n\n[CALL US](tel:1300100857)\n\n[BOOK A 15MIN CONSULTATION](https://theleadershipsphere.pipedrive.com/scheduler/X9MYYktG/the-leadership-sphere-discovery-call)\n\n## What is the Start Thinking™ program?\n\n### Start Thinking™\n\nQuite simply, how we think determines how we act, and how we act determines how well we perform. This is the premise of the Start Thinking™ workshop. In this half-day, face to face session we will introduce your team to the concepts of Herrmann Whole Brain® Thinking and explain how they can be applied to the varied challenges of business life.\n\nBy learning to recognise and understand thinking styles and preferences, they’ll experience an immediate improvement in their ability to communicate, to collaborate, to generate ideas, to solve problems and make decisions.\n\nIt’s the start of a process that will not only transform them as individuals, but create the groundwork for organisational change that will lead to better outcomes and results across  your business.\n\nStart Thinking™ is the first step in transforming your business by transforming your people.\n\n## Start Thinking™ Program Overview\n\n### Topics Covered\n\nThis workshop explains the theory, through activity and experience.\n\nParticipants will:\n\n* Be debriefed on their HBDI profile and learn to interpret the data.\n* Explore quadrant clusters, strengths and frustrations and personal work preferences.\n* Learn to recognise other people’s thinking preferences and what they mean.\n* Apply an understanding of thinking preferences to business challenges.\n\n### Learning Outcomes\n\nParticipants in Start Thinking™ will:\n\n* Understand the Whole Brain® Model and the concept of thinking preferences.\n* Understand their HBDI profile and preferences and the impact it has on their role and the team.\n* Understand how to spot and understand other people’s thinking preferences.\n* Understand how to use this knowledge to work more effectively as a team.\n* Apply insights from their thinking style to specific business opportunities.\n* Understand how thinking preferences impact your leadership style.\n\n[BOOK A CONSULTATION](https://theleadershipsphere.pipedrive.com/scheduler/X9MYYktG/the-leadership-sphere-discovery-call)\n\n## Program Additions\n\nWe can tailor follow up sessions for your specific organisational context as required. As an example, many clients choose to follow the Start Thinking™ program with Communication and Teamwork sessions.\n\n### ThinkAbout™ Communication\n\nMany of our day-to-day business problems can be solved by simply improving our communication.\n\nWhether we are having conversations internally or talking to customers, it’s critically important that we can ‘get through’ to people who have different thinking styles to our own.\n\nMany organisations are now using Whole Brain® Thinking to create a ‘common language’ that makes it easier to reach a shared understanding.\n\nDuring this half-day workshop, participants examine the way their thinking preferences affect the way they communicate. They’ll then learn to communicate more effectively by employing the Whole Brain® Communicator to align their messages with all four quadrants of the brain.\n\n**During the workshop, participants will:**\n\n* Explore the impact that thinking preferences have on the way in which people communicate.\n* Learn how to communicate more effectively by aligning how they both speak and listen to their audience’s thinking style.\n* Practice having a Whole Brain® conversation when there is no time to prepare.\n\n**At the end of this workshop, participants will:**\n\n* Use the Whole Brain® Model to understand how other people communicate.\n* Recognise their own communication style and appreciate the impact it has on their audience.\n* Recognise and understand the ‘language’ that someone else is using.\n* Use the four quadrants of the Whole Brain® Model to communicate more effectively.\n* Use the Whole Brain® Model to avoid misunderstandings and miscommunications.\n* Reach a wider audience by communicating in a Whole Brain® style.\n\n### ThinkAbout™ Teamwork\n\nWhen workload exceeds the capacity of an individual, we usually form a team to get the job done. But getting a group of people to act effectively together is not easy.\n\nPeople think differently, with different priorities and a desire for different outcomes. Managing these differences is critical to success and this is where the Whole Brain® Thinking Model proves to be an invaluable tool.\n\nOur aim is not to create teams of like-minded individuals. Far from it. One study revealed that teams with a full range of thinking preferences are 66% more effective! Our aim is to help you take full advantage of different thinking styles by aligning them in such a way that the team enjoys the synergistic effect of becoming greater than the sum of its parts.\n\n**During the workshop, participants will:**\n\n* Explore the advantages of Whole Brain® Thinking within teamwork.\n* Use the HBDI® Team Profile data to understand how interactions within the team create both strengths and challenges in terms of performance.\n* Identify the necessary measures the team must take to employ a Whole Brain® Thinking approach to its interactions and work.\n* Use the Team Planning ThinkAbout™ tool to identify tasks by quadrant so that they can be assigned more effectively.\n\n**At the end of this workshop, participants will:**\n\n* Understand what they individually bring to a team and know their specific contribution.\n* Understand what others are bringing to the team and value their specific contributions.\n* Know how to analyse a team profile, understand the implications for collaborative working and plan team activities.\n* Recognise and understand the effects that specific tasks will have on the team and be prepared to deal with them.\n\n## Testimonial\n\n“Understanding my way of approaching challenging situations has helped us to come up with strategies that play to the strengths of different members of the team. We know who the right people are to go to for any specific concern. It has helped us become a more collaborative, communicative, and successful organisation.”\n\n## Our promise to you\n\n* The best solution for delivering your desired learning outcomes.\n* Highly experienced and accredited consultants, facilitators and coaches.\n* Proprietary methodologies based on the latest research and experience from world-leading consultants.\n* Evidence-driven program design. You always know what results you’re getting.\n\n* Dedicated support team. We love to help you succeed.\n* Open and honest communication. Our mantra is “clear is kind”.\n* You define what ‘value’ means. We deliver.\n\nPhillip Ralph\n\n## Want to See the HBDI® Profile in Action?\n\nDownload a real sample of the Herrmann Brain Dominance Instrument® (HBDI®) report and see exactly how thinking preferences are mapped across the Whole Brain® Model. \n\nThis example outlines quadrant scores, preference codes, pressure responses, and work elements to give you a clear picture of how the HBDI® drives individual and team insight. \n\nIf you’re exploring the Start Thinking™ program or considering HBDI® for leadership, communication, or team performance initiatives, this report shows exactly what you can expect.\n\nDownload the HBDI® Sample Report\n\n## Some of our Clients\n\nThe Leadership Sphere delivers up to date and relevant leadership development programs that will enable you to build high performing teams.\n\nOver 14+ years we have delivered leadership workshop, courses and programs for individuals and executive leadership teams in 200+ organisations. Many of our clients choose to work with us for years.\n\n## Unlocking Leadership Potential\n\nTalk to us about the results you need. We’ll show you some options for getting there. And then together we’ll deliver a program your people will love.\n\n[BOOK A CONSULTATION](https://theleadershipsphere.pipedrive.com/scheduler/X9MYYktG/the-leadership-sphere-discovery-call)\n\nThe Leadership Sphere 2024  \n All rights reserved\n\n### Services\n\n* [Dare to Lead™](https://theleadershipsphere.com.au/programs-and-services/dare-to-lead/)\n* [High Performance Teams](https://theleadershipsphere.com.au/programs-and-services/high-performance-teams/)\n* [Leadership Development](https://theleadershipsphere.com.au/programs-and-services/executive-leadership-excellence/)\n* [Executive Coaching](https://theleadershipsphere.com.au/programs-and-services/executive-coaching/)\n* [Self-Paced Learning](https://theleadershipsphere.com.au/programs-and-services/online-leadership-development/)\n* [Assessment & Profiling](https://theleadershipsphere.com.au/programs-and-services/leadership-assessment-and-profiling-toolkit/)\n\n### Learn More\n\n* [About Us](https://theleadershipsphere.com.au/about-us/)\n* [FAQs](https://theleadershipsphere.com.au/about-us/faq/)\n* [Privacy Policy](https://theleadershipsphere.com.au/privacy-policy/)\n\n### Insights\n\n* [Blog](https://theleadershipsphere.com.au/insights/)\n* [Our Book](https://theleadershipsphere.com.au/about-us/leadership-without-silver-bullets-book/)\n\n### Contact\n\n+61 [1300 100 857](tel:1300100857)\n\nHeadquartered in Australia, Servicing Global\n\nPO Box 273  \n Doreen, Victoria  \n Australia 3754\n\n### Bookmarks\n\n[Scroll to top](#top \"Scroll to top\")\n\nDownload the RocheMartin Mastering EQ Programme Brochure\n\nDownload the RocheMartin ECR Sample Report\n\n[Call Now](tel:1300100857) \n\nTitle: B B HBDI Questionaire E | PDF - Scribd\nURL: https://www.scribd.com/doc/266410414/b-b-HBDI-Questionaire-E\nContent: The document describes a 120-question survey called the Herrmann Brain Dominance Instrument that measures a person's preferred thinking styles.\nRaw Content: ![Scribd](data:image/svg+xml;base64,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)\n\n# B B HBDI Questionaire E\n\nB B HBDI Questionaire E\n\n## Uploaded by\n\nAI-enhanced title and description\n\n# B B HBDI Questionaire E\n\nThe document describes a 120-question survey called the Herrmann Brain Dominance Instrument that measures a person's preferred thinking styles. The survey assesses preferences in four domains: analytic, emotional, imaginative, and fact-based thinking. Upon completion, the survey provides a profile of a person's thinking style preferences to help them understand how they learn, make decisions, and communicate.\n\n# B B HBDI Questionaire E\n\nB B HBDI Questionaire E\n\n## Uploaded by\n\nAI-enhanced title and description\n\n## Share this document\n\n![]()\n\n## Footer menu\n\nAbout\n\nSupport\n\nLegal\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nAbout\n\nLegal\n\nSupport\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nTitle: [PDF] Making Business Matter - The Ultimate Guide to HBDI\nURL: https://www.makingbusinessmatter.co.uk/wp-content/uploads/2021/12/The_Ultimate_Guide_to_HBDI_.pdf\nContent: The HBDI is a psychometric assessment, or test, that shows how you prefer to think. Often referred to as the 'Whole Brain Model', it shows us which areas we\nRaw Content: www.makingbusinessmatter.co.uk The HBDI is a psychometric assessment, or test, that shows how you prefer to think. Often referred to as the ‘Whole Brain Model’, it shows us which areas we prefer to think, and which areas we prefer not to think. It highlights the fact that each of us is diferent and, therefore, thinks in diferent ways. It does this by dividing the brain into four quadrants, analytical, practical, relational, and experimental. Each represented by a diferent colour. The premise being each of us prefers to think in one, or a combination of the quadrants. A conceptual representation of the model is below. By better under-standing how we, and others, prefer to think we can make better decisions. This will help improve working relationships and empathy for others.\n‘By understanding yourself you can learn to understand and value others.’ – Ned Herrmann There are many psychometric tests, like, for instance, Myers-Briggs, Belbin, or Firo-B. Each helps us to understand our abilities, motivations, personality, and much more.\nWhat is HBDI Assessment?\nThe HBDI Whole Brain Model was developed by Ned Herrmann. This metaphorical model is used to understand that each person has four quadrants when it comes to the process of thinking, communi-cating, and decision making. The model measures preferences to thinking & processing styles and doesn’t measure competence, personality & intelligence.\nIn this Ultimate Guide to the HBDI psychometric tool, we will deliver answers and understanding to the following (you can jump to sections with these links below): • What is HBDI Assessment?\n• Who Founded The HBDI Psychometric Test?\n• Is the HBDI Test Popular?\n• What Can Y ou Expect from Using the HBDI Assessment?\n• Example of a Completed HBDI Proﬁle • Explaining the HBDI Proﬁle • Beneﬁts of Knowing Y our HBDI Proﬁle • Can Y ou Increase Y our Thinking In Less Preferred Quadrants?\n• Can Whole Brain Thinking Support Leadership Development?\n• Other Psychometric Tools • HBDI vs Other Psychometric Testing Tools • Further Reading and Resources What is the HBDI Whole Brain Model?\nThe Ultimate Guide to HBDI ® – Herrmann Brain Dominance Instrument: www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 2 Return to the top Return to the top The creator William ‘Ned’ Herrmann was a physicist by training. He worked for General Electric for over 35 years as a manager. Fascinated by the creative aspects of the brain, he was searching for a way to inspire creativity in the GE employees. From the late 1970s, Ned researched, developed, and validated this dominance model. Ned is considered by many to be the ‘father of brain dominance technology’ (brain research).\n‘Creativity in its fullest sense includes both generating an idea and manifesting it – making something happen as a result.’ – Ned Herrmann Sadly Ned died on 24th December 1999. His daughter Ann Herrmann-Nehdi is now the current CEO. You can click on the video below to see our exclusive interview with Ann: Who Founded The HBDI Psychometric Test?\nHBDI stands for the Herrmann Brain Dominance Instrument.\nWhat is HBDI and how does it afect my personality?\nWhat does HBDI Stand for?\nwww.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 3 Return to the top The 120-question HBDI survey results in a proﬁle of your preferred thinking preferences. By under-standing your preferences, you can consequently, achieve a greater appreciation for how you learn. This, in turn, will help you make better decisions, solve problems, improve communication, and make a lasting impression. The survey measures preferences and not skills. It should be noted. however, that it is not a test and there are no right or wrong answers.\nWhat Can Y ou Expect from Using the HBDI Assessment?\nOver 2 million people have completed their HBDI proﬁles across 45 countries. It has been the subject of 250 dissertations, more than 30 books, and over 100 articles. Furthermore, it is used by world-class companies. For example, IBM, Coca-Cola, Kraft, Goldman Sachs, and Target.\nThe HBDI Whole Brain Business Book by Ann Herrmann-Nehdi Herrmann International do not ‘sell-on’ their product, like many other psychometric tools. Con-sequently, this means that the team have full access to all proﬁles ever made. They can, therefore, derive many more insights for practitioners to use. The HBDI test is also CPD accredited and accredited by the Association for Talent Development. Furthermore, Peter Drucker, the business guru, also recommends it in the Harvard Business Press on Knowledge Management.\nIs the HBDI Test Popular?\nwww.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 4 • A – Blue quadrant: Logical, technical, and ﬁnancial. In a single word ‘Fact’, or as a profession – Engineer.\n• B – Green quadrant: Organised, detailed, and structured. In a single word ‘Form’, or as a profession – Project Manager.\n• C – Red quadrant: Emotional, sensory, and people. In a single word ‘Feeling’, or as a profession – Teacher/Nurse.\n• D – Yellow quadrant: Risk taker, intuitive, and the big picture. In a single word ‘Future’, or as a profession – Entrepreneur.\nA word of caution: We need to be careful not to ‘pigeon hole’ a person to a single colour. Everyone uses all the colours. This is about our preferences.\nWhat Are the 4 Quadrants of the Brain?\n• Blue and green quadrants represent the left side of the brain.\n• Yellow and red quadrants represent the right side of the brain.\n• Blue and yellow quadrants represent the top half of the brain.\n• Green and red quadrants represent the bottom half of the brain.\nWhich Area of the Brain Do the Coloured Quadrants Represent?\nTo illustrate, below is an example of MBM Director and qualiﬁed practitioner Andy Palmer’s HBDI assessment results: Sample HBDI results Undoubtedly, Andy is a Blue, which means that he is keen on facts and the details. Under pressure (the dotted line), Andy thinks more in the next steps and planning quadrant (Green). He struggles with creative thinking (Yellow) and is not particularly a feelings person (Red). His proﬁle is explained in more detail below: Example of a Completed HBDI Proﬁle www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 5 Return to the top On every HBDI proﬁle, there are 3 sets of numbers; Preference Code, Adjective Pairs, and Proﬁle Scores.\nWhat Do the Numbers Mean?\nQuadrant A is about facts and ‘computing’, and so ‘Cerulean Blue’ was chosen. The following quad-rant, Quadrant B is about organisation and structure, and so green was chosen to represent ‘ground-edness’. Quadrant C is about feeling and emotion, so red was chosen. Finally, Quadrant D is about imagination so yellow was chosen for its vibrancy.\nOur own personal take is that the relationship of the colours to the quadrant characteristics is a little tenuous. This is because blue will not be seen by everyone as a ‘computing’ colour. The very useful part is that the colours enable our clients and Learners to talk to each other in the third person. For example, by saying, ‘Oh, I now understand why you ask those questions, because you are a blue, and you need to know the detail’.\nWhat Do the Colours Represent?\nExplaining the HBDI Proﬁle: We are the soft skills training provider to the UK Grocery Industry, helping Suppliers to win more business. They choose us because of our money-back guarantee, our relevant experience, and because we make their learning stick.\nOur unique training method, Sticky Learning ®, ensures that your Learners are still using their new skill 5 months later, and a money-back guarantee supports this.\nExcuse the Interruption, but Here’s a Little Bit About Us… www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 6 The dotted line shows how Andy prefers to think under pressure, or when he is stressed. In his case, he becomes more organised because the dotted line extends from reaching just the ﬁrst circle to almost reaching the outer circle. This manifests itself, for instance, as needing to list all the tasks that he needs to do and organise them into a plan.\nUnderstanding the dotted lines in the B quadrant What’s the Function of the Dotted Line?\nThe scores range from 8 to 189. They show how much you prefer to think in that quadrant when not under pressure.\nThe numbers simply show how far your proﬁle ‘reaches’. The further your outline reaches the outer circles, the more you prefer to think in that way. Remember, however. you can think in all 4 quadrants. You just prefer to retain your thoughts in some, rather than others. Andy prefers to think in facts (Blue 108), which means that he can be known to want 3 decimal places!\nProﬁle Scores In the HBDI questionnaire, you are asked to choose between 12 pairs of adjectives designed to see how you prefer to think under pressure. There are a total of 24 points distributed across the 4 quad-rants. This gives the dotted line preference showing our proﬁle under pressure, also known as your ‘backup style’.\nFor Andy, this means that when he is under pressure he chooses to think more in the Green quad-rant, which is about planning. For example, consider someone who when the ‘chips are down’ they might respond with: ‘Firstly, let’s get a meeting, secondly, let’s decide on ABC, and thirdly, we’ll organise the XYZ’.\nAdjective Pairs This consists of four numbers placed in order of the quadrants: ABCD. The terms ‘Strong Preference’, ‘General Preference’, and ‘Avoidance’ are used to label the 1, 2, 3 zones of the proﬁle grid and corre-spond to the Proﬁle Scores; 1 corresponds to a strong preference (above 66), 2 corresponds to gener-al preference (33 – 66), and 3 is a negative preference – that is, an avoidance (0-33).\nFor instance, Andy has an ‘1122’ proﬁle which means that he has a strong preference for thinking in Blue and Green, and a general preference for thinking in Red and Yellow. He does not have any 3 scores which would be quadrants that he wishes to avoid thinking and learning in.\nPreference Code www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 7 Return to the top As a rule of thumb the diametrically opposed HBDI quadrants, e.g. blue & red, and yellow & green, will ﬁnd it most challenging to get along. It can, unfortunately, be human nature to dismiss what we don’t understand.\nFor instance, hearing a fellow colleague that ‘needs a plan’ (as a yellow), can be dismissed as someone who is ‘anal about detail’. Or, likewise, the green that sees a friend talking about crazy ideas and thinks that ‘he just has his head in the clouds’.\nThe challenge is to appreciate the strengths of others and work together as a team. In other words, yellows have an idea, the blues conﬁrm the numbers, the greens create the plan, and the reds buy people into the journey.\nHow Do the Diferent HBDI Quadrants Interact with Each Other?\nThe short answer is no. The long answer is that whilst you could think that being dominant in all four quadrants would be an advantage. The disadvantage, however, might be that the person takes a long time to come to a decision.\nIs there an Ideal HBDI Proﬁle?\nThe percentages show how much Andy thinks in the top versus bottom half of his brain, and how much he prefers to think in the left versus the right-hand side of his brain.\nWhat Do the Percentages Mean?\nNot everyone’s proﬁle changes under pressure. The Herrmann team suggest that, as a result of the demands on the average knowledge worker, our stress proﬁle (dotted line) is probably how we prefer to think at work all the time.\nwww.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 8 By having a better understanding of the diferences in the ways that people process and make sense of the world, organisations can harness the beneﬁts. Take a look at the image below to learn more: What Is Cognitive Diversity? Why Is it Important?\nBy understanding yourself better you could ‘play to your strengths’, thus using your time to do more of the activities that are in your quadrant. Additionally, ‘use’ the people around you for the quadrants where you are not as dominant to build ‘cognitively diverse’ teams. As a result of better understanding others, you can communicate in ‘their language’, give feedback how they need to hear it, and under-stand the weaknesses in your team, to name only a few of the applications.\nTo measure how well you use your understanding of HBDI you can use our competency frame-work. This will help you to understand how a person uses this psychometric test on a basic and on more advanced levels.\nBeneﬁts of Knowing Y our HBDI Proﬁle www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 9 During Herrmann ® training, a learner asked one of our trainers, ‘How can I use the test to help me present better?’ To illustrate, the trainer drew this ﬂip-chart: Learner’s Work Example The ﬂip-chart shows the 4 quadrants of the HBDI model. Each square on the ﬂip-chart shows how a slide could be presented to communicate more efectively to all 4 quadrants. Furthermore, it also addressed the 4 main questions asked by each quadrant; the Blues ask ‘What?’, the Yellows ask ‘Why?’, the Greens ask ‘When?’, and the Reds ask ‘Who?’.\nPresent More Efectively by Appealing to All 4 Quadrants • Consider, for example, that a husband and wife are buying a house. The woman is dominant in the red quadrant and the man is dominant in the blue quadrant. He likes a particular house because it is only 4.7 miles from the train station. She prefers a particular (other) house because it ‘feels right’. Both quadrant thoughts are ‘right’. The challenge is to appreciate each other’s perspective and celebrate that they are diferent. The trick is to then ﬁnd a common ground, e.g. they both think in yellow and therefore they buy more on their yellow thinking.\n• When learning Time Management, a Blue Learner may be more interested in the technique of putting a time on each task on their daily list because they can analyse how they spent their time.\n• When learning Negotiation Skills, a Green Learner may be more interested in the 7 stages of a negotiation because they can see how the negotiation will progress through the stages.\nCan Y ou Give Speciﬁc Examples to Help Me Understand Further?\nwww.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 10 Problem-solving by brainstorming underpinned with the HBDI proﬁle is undoubtedly more powerful. Brainstorming is a creative technique by which eforts are made to ﬁnd a conclusion for a speciﬁc problem. It is usually done as a group with ideas and solutions spontaneously created. To illustrate, here are 4 diferent ways to brainstorm, each using a diferent quadrant of the brain.\n• Maths-storming – the blue quadrant.\n• Similar-storming – the green quadrant.\n• People-storming – the red quadrant.\n• Super-storming – the yellow quadrant.\nImprove Y our Problem Solving Ability With The HBDI We all make hundreds of decisions each day. Many of the decisions we make have an impact on other people, and more often than not without having the time to really think about them fully. Using the Whole Brain theory of decision-making, we can help leverage our own preferences, and our not so preferred preferences, to make faster and better choices.\nWe use the above matrix and these sample questions, working around the quadrants to develop a better understanding of perspectives and considerations.\nImprove Y our Decision-Making Approach If you are unsure of the proﬁle of your audience we suggest appealing to all 4 quadrants. This can be tested by ensuring that there is a speciﬁc slide that will appeal to each colour. You can then see how your audience reacts. Lastly, if the audience proves to be dominant in one colour, then your presentation should lean towards this style of communication. This will allow your presentation to have the maximum inﬂuence and impact.\nwww.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 11 Return to the top It is important not to exclusively select the technique from your highest degree of preference. For example, as a Blue, I may ﬁnd the blue technique most comfortable. Yet, the yellow could yield better ideas and diferent results.\nclick image to view full size & download www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 12 Return to the top • Invent a ‘gourmet’ dish and actually prepare it.\n• Allow yourself to daydream.\n• Imagine yourself in the year 2025.\nFor the Y ellow Quadrant • Play with your children the way they want to play.\n• ‘Dance’ without moving your feet.\n• Take a 10-minute ‘feeling break’ every morning, afternoon, and evening.\nFor the Red Quadrant • Assemble a model kit with the instructions.\n• Develop a personal budget.\n• Organise your picture ﬁles.\nFor the Green Quadrant • Take a current problem situation and analyse it into its main parts.\n• Convert your retirement dreams into a quantitative map from now to then.\n• Write a critical review of your favourite movie.\nFor the Blue Quadrant You can stimulate the other quadrants of your proﬁle and apply a transformative thinking approach by doing activities in that quadrant. To illustrate, here are some examples of activities that can help you develop your thinking ability and thrive: Can Y ou Increase Y our Thinking In Less Preferred Quadrants?\nCan HBDI Whole Brain Thinking Support Leadership Development?\nBy understanding your people better you can communicate more ‘in their language’. You can understand that a leader can be dominant in any quadrant. However, the challenge is working on those less dominant quadrants, and using the strengths of the people in your team to be ‘a whole brain’.\n‘..whole brained teams are 66% more efective than homogeneous teams’ – Inclusive Leadership Play-book.\nHerrmann International has written an excellent whitepaper called ‘Inclusive Leadership Play-book‘. This explains how leaders should embrace diversity and found that ‘whole brained teams’ are substantially more efective.\nwww.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 13 Return to the top DiSC is a behaviour assessment tool based on the theory of psychologist William Moulton Marston. It explores four diferent behavioural traits: dominance, inducement, submission, and compliance. It helps aid discussion of people’s behavioural diferences.\nWhat is DiSC Behavioral Assessment Analyses an individual’s personality traits, classifying them according to Carl Jung’s theory of psy-chological types: extraversion/introversion, sensing/intuition, thinking/feeling, (and adding a fourth) judging/perceiving. To ﬁnd out more see our Ultimate Guide to Myers Briggs.\nWhat is the Myers-Briggs Type Indicator Thinking and powerful assessment tools, such as psychometrics, can help to ﬁnd a person’s ‘ﬁt’ within a business by evaluating their skills, knowledge and personality. They are often heavily used for recruit-ment, but can also provide useful data as a management tool for team building, development and leadership success. Furthermore, they can help the person develop an awareness of their own strengths and weaknesses.\nThere are a variety of psychometric tests available. Some focus on measuring a particular skill or aptitude, whilst others look to create a proﬁle of speciﬁc traits.\nHere is an overview of some of the most widely used psychometric tests: Other Psychometric Tools Typically three-day workshops are required to become accredited, you’ll learn to use, apply, and inter-pret the HBDI® and utilize Whole Brain® Thinking approaches. For more information click here.\nHow Much Does HBDI Certiﬁcation Cost?\nwww.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 14 A personality-based test used primarily for managerial and executive-level candidates to show person-ality traits and behaviour competencies.\nWhat is CTPI-100 (The Central Test Personality Inventory) This is a self-scored tool that evaluates the efect on co-worker potential of an individual’s style of management. It explores the manager’s assumptions and priorities about the relationship between concerns for performance and concerns for people.\nWhat is Management Styles Inventory (MSI) Originally designed by Dr Max Kostick, PAPI is a personality measure designed to elicit behaviours and preferences which are relevant to the workplace.\nWhat is Personality and Preference Inventory (PAPI) Also known as the ﬁve-factor model (FFM), the test consists of a series of statements, to which the subject answers how much they agree or disagree with. The test measures: openness, conscientious-ness, extroversion, agreeableness, and neuroticism. These allow personal insight into how they will likely react in diferent situations.\nWhat is the Big Five Personality Traits Developed by Saville & Holdsowrth Ltd, the OPQ is a personality test commonly used for recruit-ment. It measures 32 diferent personality traits as indicators of job-relevant behaviours.\nWhat is Occupational Personality Questionnaire (SHL’s OPQ) The HDS measures a person’s tendencies when under stress. It can help show the ‘dark-side’ personal-ity characteristics that can damage relationships and impinge upon long-term success.\nWhat is Hogan Development Survey (HDS) Introduced by William Schutz in 1958, this tool explains the interpersonal interactions of a group of people, based on how much interaction a person wants in the areas of, inclusion, control and afec-tion.\nWhat is FIRO-B (Fundamental Interpersonal Relations Orientation) This proﬁling tool focuses on an individual’s preferred contribution style to a role or company. It uses the following categories: implementer, polisher, playmaker, strategist and game changer.\nWhat is The GC Index Also called the Belbin Self-Perception Inventory, Belbin Team Role Inventory, BSPI or BTRI. It is a behavioural test devised by Meredith Belbin to measure preference for nine diferent team roles: plant, resource investigator, coordinator, shaper, monitor evaluator, teamworker, implementer, completer ﬁnisher and specialist.\nWhat is The Belbin Team Inventory www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 15 Return to the top As noted above, there are many psychometric proﬁling tools. From understanding the part you play in a team (Belbin), to how you react in conﬂict (TKI), to Myers-Briggs (MBTI), which helps us understand how we perceive the world and make decisions. Our preference is HBDI because it is easy to grasp, whilst being able to ofer useful insights to learners so they can become more comfortable with how they prefer to think.\nThe following White Paper looks at HBDI and other assessments and how they can work together.\nHow an HBDI sample proﬁle looks like This post from HR Toolbox provides a much deeper insight into Herrmann Brain Dominance Test ® vs MBTI (Myers-Briggs). In our experience, learners rarely remember their Myers-Briggs 4 letters, however, nearly everyone remembers which HBDI colour they are!\nHBDI vs Other Psychometric Testing Tools Helps measure how a person behaves when presented with a conﬂict situation. It analyses the dimen-sions, assertiveness and cooperativeness. We use this tool for Executive Coaching to help the coachee ﬁnd and assess their conﬂict resolution skills.\nWhat is Thomas Kilmann Conﬂict Mode Instrument (TKI) Used to show an individual’s dominant personality traits. It explores 16 factors: warmth, reasoning, emotional stability, dominance, liveliness, rule-consciousness, social boldness, sensitivity, vigilance, abstractedness, privateness, apprehensiveness, openness to change, self-reliance, perfectionism, and tension.\nWhat is 16pf (Sixteen Personality Factor Questionnaire) www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 16 1. Why they prefer to understand facts that support the learnings (blue quadrant), or 2. Learn better by understanding metaphors (yellow quadrant), or 3. See why they need to create an action plan to carry out learnings (green quadrant), or 4. Why they learn better through physical activities where they can touch and feel the learnings (red quadrant).\n‘Whole Brain Learning’ enables the Learner to understand: We use HBDI for Executive Coaching, Team Building, and for some clients, to help every learner as they progress through their training.\nWe ﬁnd that it helps us to coach more efectively because we understand the person better and, in turn, helps the coachee understand themselves better. Consequently, understanding the model pro-vides a platform to give better feedback, in turn, improving communication and leadership skills.\nFor Team Building we ﬁnd that HBDI helps employee engagement and supports the learner and the team to meet 3 of the 7 essential qualities of the Teamwork competency framework. For instance, (E) Trustworthy relationships, (F) Excellent communication, and (G) Feeding back to each other.\nHow Do We at MBM Use the HBDI proﬁles for Our Clients?\nA number of validation studies have been carried out on HBDI over the last 10 years. Of these, including Berkeley, California, and the University of Texas, all have proven positive. Experts in the ﬁeld consider this to be rare.\nModel Validation In our opinion, after working with these proﬁles for over the past 14 years the answer we have come to is, ‘Tolerance and Appreciation’. In essence, by understanding that people think diferently you can start to ‘tolerate’ why they ask the questions they do. After tolerance comes appreciation because you then start to want to use their thinking diversity to enhance your own.\n‘Most of us assume we are seeing the world the way it really is.’ – Ned Herrmann For example, it is easy for the yellow quadrant to see the green quadrant, logical, robot-like, and reserved, as ‘detailed monkeys’. The appreciation comes when the yellows struggle to plan and a green can easily answer the how.\nWhat are the Beneﬁts of Using this Brain Preference Model?\nwww.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 17 Return to the top Our Herrmann Brain Dominance Instrument ® training helps each person to understand themselves, their colleagues, and everyone else better. Furthermore, you will be able to sell to the ‘whole buyer’ and inﬂuence better. This is because you will learn how to be ‘talk in the other per-son’s language’, and appreciate their unique strengths.\nContact Us can to ﬁnd out how we can help you to achieve more, alternatively please or ﬁll out the form below. Our qualiﬁed Herrmann Brain Dominance Instrument practitioners are from your industry and can provide training on any one of our products, from Category Management and GSCOP to Time Management and Inﬂuencing Skills, using our unique Sticky Learning methods.\nHerrmann Brain Dominance Instrument Training www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 18 Click below to see our YouTube channel and playlist with more tips on how to use the Herrmann Brain Dominance Instrument in the workplace: Watch Our Videos Take a look at our award-winning blog and it’s content on tips and beneﬁts of using the Herrmann Brain Dominance Instrument.\nRead our Blog Read our HBDI glossary for a complete deﬁnition and A-Z of key terms. Additionally, feel free to take a look at all of our soft skills glossaries.\nGlossaries Read some case studies to discover other organisations who have found success with transformative thinking, and explore a sample team proﬁle.\nCase Studies TEDx Talk Tryon – Ann asks the question, “Do you manage your brain or does it manage you?” To reach your potential and use your brain to the full, you need to understand how it works. And, thus, what you can do to better use it.\nAnn Herrmann at TEDx video, ‘‘Think like your future depends on it‘.\nAnn Herrmann at TEDx video, ‘‘One thing to know about your future that will change your life‘.\nIn this 4 minute video Ned Herrmann talks about his model: Further HBDI Reading and Resources www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 19 www.makingbusinessmatter.co.uk We are the soft skills training provider to the UK Grocery Industry, helping Suppli-ers to win more business. They choose us because of our money back guarantee, our relevant experience, and because we make their learning stick.\nAbout Andy Palmer Andy started at the coal face with eight years in food retailing. Prior to joining MBM he then spent ﬁve years in the supply base in positions of category analysis, Category Management and account management. He works as part of the team enabling suppliers to UK supermarkets to secure more proﬁtable wins through people development. He specialises in Category Training and is a qualiﬁed HBDI practitioner.\nFeel free to get in touch to ﬁnd out about how one of our qualiﬁed Herrmann Brain Dominance Instrument practitioners can help you. Simply visit here to contact us or email us at helpme@makingbusinessmatter.co.uk, and we will be happy to get back to you.\nContact Us www.makingbusinessmatter.co.uk Making Business Matter - The Ultimate Guide to HBDI ® 20\n\nTitle: Herrmann Brain Dominance Instrument Thinking Styles Assessment\nURL: https://www.scribd.com/document/92687750/hbdi\nContent: HBDI. Herrmann Brain Dominance Instrument Thinking Styles Assessment. This 120-question survey form results in a profile of your preferred thinking styles.\nRaw Content: ![Scribd](data:image/svg+xml;base64,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)\n\n# Herrmann Brain Dominance Instrument Thinking Styles Assessment\n\nHerrmann Brain Dominance Instrument Thinking Styles Assessment\n\n## Uploaded by\n\nAI-enhanced title and description\n\n# Herrmann Brain Dominance Instrument Thinking Styles Assessment\n\nThis 120-question survey results in a profile of your preferred thinking styles. The survey measures preferences rather than skills. It is not a test; there are no wrong answers.\n\n# Herrmann Brain Dominance Instrument Thinking Styles Assessment\n\nHerrmann Brain Dominance Instrument Thinking Styles Assessment\n\n## Uploaded by\n\nAI-enhanced title and description\n\n## Share this document\n\n![]()\n\n## Footer menu\n\nAbout\n\nSupport\n\nLegal\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nAbout\n\nLegal\n\nSupport\n\nSocial\n\nGet our free apps\n\n![Scribd - Download on the App Store]()\n![Scribd - Get it on Google Play]()\n\nTitle: [PDF] Herrmann Brain Dominance Instrument Workshop - Building EQ\nURL: https://www.protechtraining.com/pdf/PT10457~.pdf\nContent: The facilitated discussion follows an initial report debrief, is where participants explore how they collectively use their thinking style preferences as a team, how differences in thinking style can help or hinder a team’s effectiveness at solving problems and making decisions, and identify how they might better approach solving problems and making decisions by leveraging identified strengths and incorporating new thinking approaches and strategies. Throughout the day of the workshop, larger groups will be divided into smaller working groups, that can be mixed as desired to increase the opportunity to build trust through better understanding each other, and improve interpersonal relationships Topics • Learning Approach • Introduction to the workshop and workshop objectives • Introduction to Hermann Brain Dominance thinking style • HBDI Assessment Report Debrief • Self reflection • Group Work • Team results review and debrief.\nRaw Content: ProTech Professional Technical Services, Inc. Due to the nature of this material, this document refers to numerous hardware and software products by their trade names. References to other companies and their products are for informational purposes only, and all trademarks are the properties of their respective companies. It is not the intent of ProTech Professional Technical Services, Inc. to use any of these names generically Course Outline Herrmann Brain Dominance Instrument Workshop – Building EQ Course Summary Description The Herrmann Brain Dominance Instrument (HBDI) model identifies broad thinking preferences e.g. left brain versus right brain, Intellectual versus Instinctive brain, and then further breaks down thinking preferences into four distinct quadrants: Rational Self, Experimental Self, Feeling Self, and Safekeeping Self. As such, the HBDI is a type of emotional intelligence model/assessment that can be used for understanding similarities and differences between team members. The 1-Day HBDI Workshop is focused on helping participants identify their thinking style preferences (i.e. how individuals use thinking style) instead of personality style (e.g. DiSC, etc.), and differs from other Emotional Intelligence (EQ) assessments in that the HBDI focuses on thinking style preference(s) not personality. HBDI then helps participants build an understanding of how they can use their whole brain to make decisions and solve problems either individually or as a group/team. The facilitated in-class workshop helps participants link thinking style to behavioural preferences, and to understand how thinking preferences are expressed in individual and group settings, using thinking style as the driver. The facilitated discussion follows an initial report debrief, is where participants explore how they collectively use their thinking style preferences as a team, how differences in thinking style can help or hinder a team’s effectiveness at solving problems and making decisions, and identify how they might better approach solving problems and making decisions by leveraging identified strengths and incorporating new thinking approaches and strategies. This larger group discussion helps to build additional self-awareness and importantly to build trust and improve relationships with members of larger team. A key outcome at the individual level of this discussion is that individuals learn they can change their thinking style preferences to become more effective at solving problems and making decisions. At the group level, participants learn how to leverage the strengths of different thinking styles, build a better understanding of each other, and set measureable goals for using new thinking style approaches for solving future problems and making decisions. Throughout the day of the workshop, larger groups will be divided into smaller working groups, that can be mixed as desired to increase the opportunity to build trust through better understanding each other, and improve interpersonal relationships Topics • Learning Approach • Introduction to the workshop and workshop objectives • Introduction to Hermann Brain Dominance thinking style • HBDI Assessment Report Debrief • Self reflection • Group Work • Team results review and debrief. • Implications and strategies to use when forming and reforming project teams • Commitment to Self and Team Prerequisites Prior to the class, individuals complete the confidential HBDI Self Assessment on line Completion of the confidential on-line self-assessment takes approximately 15 to 20 minutes. Participants receive a confidential comprehensive full colour detailed printed report the morning of the workshop. Duration One day ProTech Professional Technical Services, Inc. Due to the nature of this material, this document refers to numerous hardware and software products by their trade names. References to other companies and their products are for informational purposes only, and all trademarks are the properties of their respective companies. It is not the intent of ProTech Professional Technical Services, Inc. to use any of these names generically Course Outline Herrmann Brain Dominance Instrument Workshop – Building EQ Course Outline I. Learning Approach A variety of interactive facilitated discussions together with group work assignments is used throughout the day – adhering to the accepted principles of adult learning. II. Introduction to the workshop and workshop objectives III. Introduction to Hermann Brain Dominance thinking style This is done as a large fun group exercise/group game where participants use specialized HBDI playing cards to try to identify their primary thinking style, as well as give feedback to colleagues about what they feel is their colleague’s primary thinking style. IV. HBDI Assessment Report Debrief Report debriefs, together with what is HBDI, the difference between personality and thinking style and how the two are connected V. Self reflection What does my thinking style say about me, and how I interact with others? VI. Group Work How HBDI plays out in group problem-solving and decision-making – a variety of fun case-studies, scenarios and group exercise(s) with facilitated debrief. Note: Individuals are typically grouped together by functional role and then by thinking style similarities or differences. o An example of one of several potential fun group exercises typically used is that teams use their various thinking styles and compete to build the tallest freestanding structure using unconventional materials – the thinking styles and problems solving approach used is discussed in the debrief. VII. Team results review and debrief. As an exercise, participants may be asked to create an Infographic that graphically depicts their team’s thinking style and problems solving approach, and they share this with the larger group. VIII. Implications and strategies to use when forming and reforming project teams Participants explore, discuss and agree strategies that they can use to help them form and reform project teams using HBDI as a framework. IX. Commitment to Self and Team Individual’s identify one commitment they will make to improve teamwork as part of what they have learned. Team members then identify two or three commitments they can and will make that will improve overall team effectiveness. The commitments are recorded by the facilitator. These commitments will be measured at an agreed later date, typically six or nine months later.\n\nTitle: [PDF] Introduction to the HBDI® and the Whole Brain® Model\nURL: https://www.thinkherrmann.com/hubfs/Whole_Brain_Thinking_and_the_HBDI-Technical_Overview-Validity_Evidence-_Jan_2016.pdf\nContent: Introduction to the HBDI® and the Whole Brain® Model Technical Overview & Validity Evidence UPDATED 2016 Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 2 OVERVIEW The theory on which the Whole Brain® Model and the Herrmann Brain Dominance Instrument® (HBDI®) were built has been supported with reliability and validity evidence from over 30 years of research on a global database comprised of over a million individuals. 0 10,000 20,000 30,000 40,000 50,000 60,000 0 12 24 36 48 60 72 84 96 108 120 132 144 156 168 180 192 204 216 FREQUENCY PROFILE SCORES FREQUENCY OF QUADRANT SCORES N = 449,537 A Quadrant B Quadrant C Quadrant D Quadrant Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 10 Reliability Evidence Test-Retest Reliability.\nRaw Content: Introduction to the HBDI® and the Whole Brain® Model Technical Overview & Validity Evidence UPDATED 2016 Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 2 OVERVIEW The theory on which the Whole Brain® Model and the Herrmann Brain Dominance Instrument® (HBDI®) were built has been supported with reliability and validity evidence from over 30 years of research on a global database comprised of over a million individuals. Ned Herrmann, the originator of the Whole Brain® Model, sought to apply brain-based research to the field of business and developed the Whole Brain® Model accordingly (e.g., Herrmann, 1981, 1982, 1991, 1996). The model is based on the neuroscientific premise that the brain works in systems, and it elucidates four integrated systems that, based on theoretical rationale and empirical evidence (e.g., Bunderson, Newby, Olsen, & Wendt, n.d.; Bunderson, Olsen, & Herrmann, 1982; Ho, 1988), help explain personal and professional success. Everyone has access to all four systems, but over time we develop individualized preferences. The Whole Brain® Model helps people better understand the four integrated systems, better understand their preferences for each of the systems, and ultimately gives individuals, teams, and organizations the capacity to increase thinking agility to maximize performance. Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 3 Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 4 WHAT IS THE HBDI®? The HBDI® was developed to measure human mental preferences described by the Whole Brain® Model. Specifically, the instrument was developed to measure the four integrated systems that effectively describe clusters of individualized preferences. The HBDI® is grounded in theory and has support for its validity through both rational and empirical evidence. Past research has shown the HBDI® measures validly the four integrated systems of mental preferences (e.g., Ho, 1988; Bunderson et al., 1982). Further, past research has demonstrated that scores from the HBDI® can be used validly to predict and inform thinking preferences, performance, and results. WHAT DOES THE HBDI® MEASURE? The HBDI® measures four integrated systems of thinking preferences that help explain personal and professional success. Each system is a cluster of interrelated mental activities and thinking preferences. These four systems can be mapped metaphorically on the human brain as the Upper Left (A Quadrant), Lower Left (B Quadrant), Lower Right (C Quadrant), and Upper Right (D Quadrant). The A Quadrant is typified by preferences that are logical, analytical, technical, and quantitative. The B Quadrant is typified by preferences that are controlled, planned, administrative, and sequential. The C Quadrant is typified by preferences that are emotional, interpersonal, feeling oriented, and spiritual. The D Quadrant is typified by preferences that are imaginative, holistic, innovative, and synthesizing. These quadrants are the four key interrelated constructs measured by the HBDI®. It is important to note that the HBDI® does not claim to measure ability, aptitude, or capabilities. Further, the HBDI® does not claim to measure activity in specific localized areas of the human brain. The brain model is simply a metaphor that helps users poignantly understand the Whole Brain® Model while appreciating the rigorous neuroscientific principles upon which it was founded. Quadrant Scores. The HBDI® measures reliably and validly the four quadrants. According to the Whole Brain® Model, describing an individual can only be done comprehensively by examining all four interrelated quadrant scores. Thus, each individual receives a 4-quadrant preference profile with a ranking of 1 (primary), 2 (secondary), or 3 (tertiary) for each quadrant based on the degree of preference for the respective quadrant attributes. For example, an individual with a profile of 1232 would have primary preferences for A-Quadrant thinking, secondary preferences for B- and D-Quadrant thinking, and tertiary preferences for C-Quadrant thinking. Individuals also receive raw scores for each quadrant, which provide more detail concerning the degree to which preferences exist for each quadrant. Using the above example (i.e., 1232), the A-Quadrant primary score could hypothetically be 70 or it could be 130—both are considered primary but one is clearly of a greater magnitude. Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 5 Left-Brain Cluster versus Right-Brain Cluster Preferences. In addition to quadrant scores, the HBDI® also provides scores associated with preferences for the metaphorical left brain (A and B Quadrants) versus right brain (C and D Quadrants). Individuals with scores denoting strong preference in the left hemisphere tend to be partial to logical, organized, and fact-based mental activities. Conversely, individuals with scores denoting strong preference on the right quadrants tend to have preferences for emotional, intuitive, and innovative mental activities. Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 6 Upper Mode versus Lower Mode Dominance. In addition to left brain versus right brain, the HBDI® also provides scores associated with preferences for the metaphorical upper mode (A and D Quadrants) versus lower mode (B and C Quadrants) mental activities. Higher scores in the upper quadrants are indicative of preferences toward logical, technical, innovative, and synthesizing mental activities, whereas higher scores in the lower quadrants are typically indicative of preferences toward emotional, interpersonal, organized, and safekeeping mental activities. Stress Profile. In addition to preference profiles and raw scores, the HBDI® also provides individuals with stress profiles. The stress profile is an extension of the preference profile, and its scores are used to inform individuals about their typical preference styles when dealing with significant stress. For example, the proclivity to have logical and rational thinking preferences during stressful situations manifests as a higher score on the stress profile for the A Quadrant. USES OF THE HBDI® AND THE WHOLE BRAIN® THEORY The Whole Brain® Model has been applied in numerous work and organizational contexts. Its intended use is to help individuals, teams, and organizations recognize and understand thinking preferences and boost thinking agility in order to enable better thinking, better performance, and better results. It helps individuals understand their own thinking preferences and leverage them to facilitate learning and development, problem solving, decision making, communication, productivity, and subjective wellbeing. It helps teams better understand each team member and leverage this information to facilitate communication, team effectiveness, and morale. Finally, it helps organizations leverage information on thinking preferences to increase organizational effectiveness, develop and retain top talent, boost revenue, and facilitate various management and leadership processes. (See Table 1 for a nonexhaustive list of instrument uses that are deemed appropriate based on theoretical and empirical rationale.) Table 1 Appropriate Uses of the HBDI® and Whole Brain® Model 1. Better understanding of self and others. 2. Enhanced communication and interpersonal effectiveness. 3. Enhanced productivity at the individual, team, and organizational levels. 4. Building a work climate and designing jobs that facilitates creativity and productivity. 5. Developing authenticity and trust. 6. Enhanced teaching effectiveness. 7. Enhanced learning and development. 8. Better management and leadership. 9. Educational and occupational counseling. At present, validity evidence for the HBDI® has not been collected to approve its use in clinical testing, Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 7 diagnostic testing, or medical or psychological classification. There is also an absence of validity evidence for its use in admissions or placement testing prior to educational programs or training events. Lastly, in its current state, the HBDI® is not recommended for personnel selection decisions, professional and occupational licensure, or certification. EVIDENCE OF RELIABILITY AND VALIDITY Database Characteristics and Descriptive Statistics Since inception, Herrmann International has supported an ongoing effort to establish a program of research that supports the validity of the HBDI®. Between the years of 1980 and 2014, Herrmann International’s database amassed over 1.4 million records of individuals who had completed the HBDI® around the globe. The HBDI® database records include a diverse array of demographic characteristics. In terms of gender, 603,253 (42.71%) self-identified as female and 809,337 (57.29%) self-identified as male. Participants span all age ranges and come from a diverse array of occupations and job titles (including over 200,000 managers and over 10,000 CEOs). The database includes substantial participation from numerous nationalities (e.g., Australian, French, and Chinese), languages (e.g., English, Spanish, and Italian), and countries (e.g., Canada, Czech Republic, and Finland). In fact, the HBDI® has been translated successfully into over 20 languages. This rich database enables Herrmann International to carry out an extensive and rigorous program of research to contribute to the validity argument and ascertain the psychometric soundness of the HBDI®. Several descriptive statistics are interesting and worth noting. Displayed in Table 2 are descriptive statistics for each quadrant from a representative sample of the HBDI® global database, including the arithmetic mean (M), standard deviation (SD), minimum, and maximum. Skewness and kurtosis are also included to demonstrate that the data demonstrate multivariate normality, which is a statistical assumption about data that is often elusive and overlooked. Displayed in Table 3 are the most frequently occurring HBDI® preference profiles. Finally, displayed in Figure 1 is the frequency of quadrant scores for a representative sample of the global database. Table 2 Descriptive Statistics from a Representative Sample of the HBDI® Database All (N = 70,621) M SD Min Max Skewness Kurtosis A Quadrant 79.38 24.47 12 153 -0.044 -0.597 B Quadrant 77.46 19.06 12 158 0.091 -0.209 C Quadrant 65.75 21.55 11 147 0.299 -0.311 D Quadrant 70.52 22.84 14 182 0.457 -0.127 Males (n = 35,268) M SD Min Max Skewness Kurtosis A Quadrant 88.24 22.49 18 153 -0.216 -0.419 Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 8 B Quadrant 75.47 18.76 12 152 0.118 -0.173 C Quadrant 58.00 19.26 11 138 0.439 -0.059 D Quadrant 69.87 22.24 15 182 0.507 -0.006 Females (n = 35,353) M SD Min Max Skewness Kurtosis A Quadrant 70.53 23.13 12 153 0.156 -0.497 B Quadrant 79.45 19.14 17 158 0.056 -0.230 C Quadrant 73.49 20.93 11 147 0.141 -0.319 D Quadrant 71.16 23.40 14 173 0.405 -0.236 Table 3 Top 10 Ranked Preference Profiles from HBDI® Global Database All (N = 1,374,792) Males (n = 790,183) Females (n = 584,609) 1 1122 18.95% 1122 23.26% 2111 16.04% 2 2111 10.29% 1221 13.59% 1122 13.12% 3 1221 9.85% 1121 12.14% 2211 12.23% 4 1121 9.19% 2211 6.19% 2112 11.66% 5 2211 8.76% 2111 6.04% 1112 9.78% 6 1112 7.61% 1112 6.00% 1121 5.20% 7 2112 6.63% 1132 4.87% 1221 4.77% 8 1211 4.75% 1211 4.77% 1211 4.73% 9 1132 3.09% 1222 3.31% 1111 3.13% 10 1111 2.98% 2112 2.91% 3111 3.08% Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 9 Figure 1. Frequency of quadrant scores. 0 10,000 20,000 30,000 40,000 50,000 60,000 0 12 24 36 48 60 72 84 96 108 120 132 144 156 168 180 192 204 216 FREQUENCY PROFILE SCORES FREQUENCY OF QUADRANT SCORES N = 449,537 A Quadrant B Quadrant C Quadrant D Quadrant Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 10 Reliability Evidence Test-Retest Reliability. Test-retest reliability is a stability measure that refers to the extent to which a measurement instrument produces consistent scores when the same measurement procedure is used with the same participant using the same instrument on repeated measures over a given period of time. An instrument is said to be unreliable when it is unable to produce consistent scores under these repeated conditions. Using 78 cases in which individuals took the HBDI® on at least two occasions, Ho (1988) found test-retest reliabilities of .96 for left-brain preferences, .96 for right-brain preferences, .86 for A-Quadrant preferences, .98 for B-Quadrant preferences, .94 for C-Quadrant preferences ,.97 for D-Quadrant preferences, .98 for Cerebral preferences, and .91 for Limbic Preferences. Internal Consistency Reliability. Coefficient alpha (α) is a measure of internal consistency reliability (Cronbach, 1951). Because each of the four quadrants are considered unidimensional constructs, they should demonstrate internal consistency by demonstrating a coefficient α > .70 (Nunnally, 1978). Based on a sample size of 181,139, Bunderson and colleagues (n.d.) found sufficient internal consistency reliabilities for the A Quadrant (α = .84), B Quadrant (α = .77), C Quadrant (α = .80), and D Quadrant (α = .81). This suggests that items within each construct are internally consistent and manifestations of a single latent dimension. Validity Evidence Validity is best thought of as an accumulation of theoretical and empirical evidence. Validity is not an inherent characteristic of a measurement instrument; rather, according to the Standards for Educational and Psychological Testing (American Educational Research Association, American Psychological Association, & National Council on Measurement in Education, 1999), “Validity refers to the degree to which evidence and theory support the interpretations of test scores entailed by proposed uses of tests.” Validity is of paramount concern for any measuring instrument, and therefore Herrmann International has been relentless in their pursuit of building a sound scientific basis to support the HBDI® and the theoretical model on which it is built. Face Validity. Face validity refers to the extent to which the instrument and its scores appear to the test taker or respondent to measure what it purports to measure. Evidence of face validity is particularly important for self-report preference instruments like the HBDI® because they are dependent on honesty and forthrightness from the respondents. Further, for respondents to trust the results and accept the information as pertinent and practical, participants have to believe in the integrity of the measurement instrument. Research has not been done to formally collect evidence of face validity, but anecdotal accounts suggest that HBDI® respondents are overwhelmingly positive about their experience with the HBDI® and attest to the perceived accuracy of the reported results. Content Validity. Evidence of content validity is provided by demonstrating that the content involved in the measurement instrument is representative—and neither contaminated nor deficient—of the constructs that it purports to measure. This evidence is often established by subject matter experts (SMEs) who verify that Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 11 items and scales sufficiently tap relevant content domain. The HBDI® and its constituent constructs are well grounded in scientific theory and ongoing rational reviews by multiple SMEs continue to support the representativeness of items within each content domain. Internal Construct Validity. Internal construct validity (or structural validity) is supported when empirical evidence suggests the number of distinct constructs measured by an instrument align with theory-based predictions and a priori conceptualizations (Cronbach & Meehl, 1955; Messick, 1989). Further, items and manifest indicators of constructs must map onto the construct they are purported to measure. The HBDI® measures four main constructs (i.e., the four quadrants), and each construct has an array of indicators that contribute to the scoring of each construct. Research to date has provided sound support for the structural validity of the HBDI® (e.g., Bunderson et al., n.d., 1982; Ho, 1988; see also Herrmann, 1988, 1991). Factor analytic results have consistently supported the theoretical dimensionality of the four quadrants. Further, items and manifest indicators have consistently loaded reliably onto their respective quadrants, demonstrating clean factor structures. Finally, results support the interpretation of two bipolar second-order factors (A vs. C and B vs. D) and a single bipolar third-order factor (Left vs. Right Dominance). The former indicates that preference toward one end of the bipolar factor (e.g., A-Quadrant preference or B-Quadrant preference) often coincides with avoidance toward the other end of the bipolar factor (e.g., C-Quadrant avoidance or D-Quadrant avoidance). The latter indicates that dominance toward left-brain preferences often coincides with avoidance toward right-brain preferences. These findings align with Whole Brain® Model predictions and with research in psychological and neuroscientific disciplines. External Construct Validity. Collecting evidence of external construct validity consists of comparing instrument measures to other external instrument measures in order to examine its network of relations with other measures that should theoretically be similar to (convergent validity) or dissimilar to (discriminant validity) the referent measure (Cronbach & Meehl, 1955; Messick, 1989). The Whole Brain® Model provides theoretical rationale for why the HBDI® should relate with other psychological constructs of interest. The HBDI® is purported to measure thinking preferences that are important determinant of mental activities, behaviors, and experiences, in important life contexts such as home, leisure, and work. Thus, these thinking preferences constructs should relate to an array of actions and decisions that can be observed, measured, and then linked to the HBDI®. Several factor-analytic investigations into the external validity of the HBDI® have been conducted. The HBDI® and its constructs have been included in large scale factor analyses with external measures of personality, cognitive ability, cognitive styles, and learning strategies such as the Myers Briggs Type Indicator, the Educational Testing Services Kit of Factor Reference Tests (e.g., Necessary Arithmetic Operations, Gestalt Completion, and Hidden Figures), Ravens Progressive Matrices, various individual differences questionnaires (e.g., Hill Individual Difference Questionnaire and Paivio Individual Difference Questionnaire), and various measures of learning strategies. Findings indicate that the four quadrants (as well as the left vs. right score) are linked in a consistent and predictable way with mental processes involved in the construct measures (Bunderson, 1989). These findings provide evidence for the practicality of using HBDI® scores in conjunction with other measures and support the utility of using the HBDI® to account for and predict variability in a wide Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 12 array of important real-world measures of mental activities, personality, behaviors, and performance. CONCLUSION The Whole Brain® Model and the associated measurement instrument (i.e., the HBDI®) have benefited from a solid theoretical foundation and empirical research conducted using Herrmann International’s expansive global database. The construct model and the instrument were both developed on solid theory and research, have demonstrated evidence of test-retest reliability and internal consistency reliability, and have consistently demonstrated evidence of internal and external construct validity. The utility of the Whole Brain® Model and the HBDI® has been supported in numerous work contexts, and the ongoing program of research will continue to ensure that it meets rigorous standards of educational and psychological measurement. Introduction to the HBDI® and the Whole Brain® Model Confidential – Intended for licensed professional and academic use only Copyright © 2014-2017 Herrmann Global LLC • herrmannsolutions.com 13 REFERENCES American Educational Research Association, American Psychological Association, & National Council on Measurement in Education (1999). Standards for educational and psychological testing. Washington, DC: Author. Bunderson, C. V. (1989). The validity of the Herrmann Brain Dominance Instrument®. Creative Brain. Lake Lure, NC: Brain Books. Bunderson, C. V., Newby, V. A., Olsen, J. B., & Wendt, D. C. (n.d.). Validity of the HBDI four-quadrant and left-right structure: A structural validation study using new millennium database. Unpublished manuscript. Bunderson, C. V., Olsen, J. B., & Herrmann, W. E. (1982). A fourfold model of multiple brain dominance and its validation through correlational research. (Scientific and Technical Report #10: prepared for General Electric). Orem, Utah: Wicat Incorporated Learning Design Laboratories. Cronbach, L. J. (1951). Coefficient alpha and the internal structure of tests. Psychometrika, 16, 297-334. Cronbach, L. J., & Meehl, P. E. (1955). Construct validity in psychological test. Psychological Bulletin. 52, 281-302. Herrmann, N. (1981). The creative brain. Training and Development Journal, 35, 10-16. Herrmann, N. (1982). The creative brain II. Training and Development Journal, 6, 74-86. Herrmann, N. (1988). The creative brain. Lake Lure, NC: Brain Books. Herrmann, N. (1991). The creative brain*. The Journal of Creative Behavior,25, 275-295. Herrmann, N. (1996). The whole brain business book (Vol. 334). New York: McGraw-Hill. Ho, K. T. (1988, December). The dimensionality and occupational discriminating power of the Herrmann Brian Dominance Instrument. Dissertation Abstracts International, 49, 2409. Messick, S. (1989). Validity. In R. Linn (Ed.), Educational Measurement, Vol. III. Nunnally, J. C. (1978) Psychometric theory. New York: McGraw-Hill.\n\nTitle: [PDF] HBDI® Pair Profile - Herrmann International\nURL: https://www.thinkherrmann.com/hubfs/CP_Site/Pair%20Sample%20Report%201%20Different.pdf\nContent: Our Thinking Under Pressure A B C D A B C D Yama Display Herrmann Example Yama Display -34 -4 +25 +11 Herrmann Example -13 +11 +7 -5 General Score Change from General Profile 12/19 ©2019 Herrmann Global https://www.thinkherrmann.com/ A B C D General Score Under Pressure introvert extrovert A B C D Yama Display -34 -4 +25 +11 Herrmann Example -13 +11 +7 -5 mathematical quantitative analytical rational factual critical logical reader speaker detailed dominant controlled sequential conservative talker reader musical spiritual intuitive symbolic emotional simultaneous imaginative synthesizer intuitive artistic holistic spatial How Our Thinking Changes Under Pressure 13/19 ©2019 Herrmann Global https://www.thinkherrmann.com/ strongly agree agree neutral disagree strongly disagree I feel that a step by step method is best for solving problems.\nRaw Content: HBDI® Pair Profile Thinker comparison for: Certified Practitioner Pat Practitioner Herrmann Example Yama Display ©2019 Herrmann Global https://www.thinkherrmann.com/ Yama Display Herrmann Example Notes: 1/19 ©2019 Herrmann Global https://www.thinkherrmann.com/ A B C D reader speaker detailed dominant controlled sequential conservative talker reader musical spiritual intuitive symbolic emotional simultaneous imaginative synthesizer intuitive artistic holistic spatial General Comparison of Our Thinking Strong Preference (1) Intermediate Preference (2) Low Preference (3) Preference Code A B C D Yama Display 2 1 1 2 Herrmann Example 1 2 2 1 Profile Scores Yama Display 45 87 94 60 Herrmann Example 90 55 48 71 mathematical quantitative analytical rational factual critical logical 2/19 ©2019 Herrmann Global https://www.thinkherrmann.com/ A B C D reader speaker detailed dominant controlled sequential conservative talker reader musical spiritual intuitive symbolic emotional simultaneous imaginative synthesizer intuitive artistic holistic spatial Our Cumulative Mental Resources Strong Preference (1) Intermediate Preference (2) Low Preference (3) A B C D General Score 90 87 94 71 Under Pressure Score 77 83 119 71 mathematical quantitative analytical rational factual critical logical 3/19 ©2019 Herrmann Global https://www.thinkherrmann.com/ A B C D 2 1 1 2 A B C D 1 2 2 1 Yama Display Herrmann Example 2112 - This profile represents 6.84% of the Herrmann® database. This profile is a double dominant profile with the two primaries falling in the Lower Left B and Lower Right C quadrants.It is, therefore, a double primary in the lower mode. The profile is characterized by very strong preferences in conservative thinking and controlled behavior with a desire for organization and structure as well as detail and accuracy (B quadrant). The primary in the C quadrant would equally show itself by interpersonal skills and sensitivity to feelings.\nIt may indicate emotion, and perhaps interest in music and a sense of spirituality. It would also be likely to demonstrate sensory intuition or 'gut feelings'. The two lower primaries could represent an important duality for the person to resolve within themselves. The opposing qualities of control and structure, contrasting with the emotional and interpersonal 'feelings' can cause internal conflict. The clear secondary preferences of the upper modes, both Upper Left A and Upper Right D, are also characteristic of this profile, with logical and analytical processing in the Upper Left A quadrant and holistic and creative thinking in the Upper Right D quadrant.\n1221 - This profile represents 9.64% of the Herrmann® database. This profile is double dominant with the two primaries in the Upper quadrants, A and D. Individuals with this profile would exhibit strong preferences for logical, analytical and quantitative modes of thinking in the Upper Left A quadrant; in contrast they would also have a preference for the integrative, synthesizing, creative and holistic aspects of Upper Right D. This profile indicates a clear secondary preference for the emotional, interpersonal processing of Lower Right C as well as a clear secondary for the controlled, conservative, organized processing modes of the Lower Left B quadrant. Individuals with this profile frequently exhibit the ability to switch back and forth between the two cerebral quadrants, as the situation demands.\nOur Profiles, Side-by-Side Descriptions and Characteristics 4/19 ©2019 Herrmann Global https://www.thinkherrmann.com/ A B C D 2 1 1 2 A B C D 1 2 2 1 Yama Display Herrmann Example Occupations typical of people with this profile include human resource professionals and those in counselling and 'helping' positions -particularly when there is a heavy administrative load. Executives, nurses, some secretaries and homemakers may also show similar profiles. Work that is considered a 'Turn- On' would include: getting things done on time, working with others, writing expressively, solving customer issues, and building relationships.\nOccupations typical of this profile include design engineers, financial consultants or advisers (those involved with forecasting financial trends), and research and development scientists - particularly physicists. It is also typical of senior executives in operating and strategic positions in technical organizations. Work that is considered a 'Turn- On' would include: working solo,making things work, being challenged, inventing solutions, bringing about change, and integrating ideas.\nOur Profiles, Side-by-Side Common Occupations 5/19 ©2019 Herrmann Global https://www.thinkherrmann.com/ Yama Display Herrmann Example Yama Display Herrmann Example Our Typical Process Flows Compared This graphic presents what a typical process flow would look like for each of our thinking preferences.\nOur Under Pressure Process Flows Compared 15.7% A 30.4% B 32.9% C 21.0% D 34.1% A 20.8% B 18.2% C 26.9% D This graphic presents the alternate flow of preferences under pressure.\nAnd where we may approach things when under pressure.\n3.9% A 29.2% B 41.9% C 25.0% D 29.2% A 25.0% B 20.8% C 25.0% D 6/19 ©2019 Herrmann Global https://www.thinkherrmann.com/ YAMA DISPLAY HERRMANN EXAMPLE A B C D factual logical critical rational analytical mathematical quantitative factual logical critical rational analytical ♦ mathematical quantitative reader verbal detailed dominant controlled sequential conservative reader verbal detailed dominant controlled sequential conservative reader verbal musical symbolic emotional ♦ intuitive spiritual reader verbal musical symbolic emotional intuitive spiritual spatial artistic creative holistic intuitive synthesizer simultaneous spatial artistic creative holistic intuitive synthesizer simultaneous How We See Ourselves ♦ Selected as the most descriptive 7/19 ©2019 Herrmann Global https://www.thinkherrmann.com/ Our Thinking at Work YD HE analytical YD HE technical aspects 0 1 2 3 4 5 YD HE problem solving YD HE financial aspects 0 1 2 3 4 5 YD HE organization YD HE planning 0 1 2 3 4 5 YD HE administrative YD HE implementation 0 1"
      },
      {
        "type": "text",
        "text": "\n\n[OUTPUT TRUNCATED - exceeded 25000 token limit]\n\nThe tool output was truncated. If this MCP server provides pagination or filtering tools, use them to retrieve specific portions of the data. If pagination is not available, inform the user that you are working with truncated output and results may be incomplete."
      }
    ]
  }
]

---

### User
> 11/30/2025, 3:48:46 PM

[
  {
    "tool_use_id": "toolu_01SgXF3fFjNBKjJ4STcpFSDK",
    "type": "tool_result",
    "content": [
      {
        "type": "text",
        "text": "Detailed Results:\n\nTitle: [PDF] The Thinking Environment : Road Test | TimetoThink\nURL: https://www.timetothink.com/wp-content/uploads/2024/06/the-thinking-environment-road-test-coaching-at-work-linda-aspey.pdf\nContent: The Thinking Environment® is a way of being more than a tool, built on a unique framework for generative thinking developed by Nancy Kline of Time to Think.\n\nTitle: Creating a Thinking Culture - IEDP\nURL: https://www.iedp.com/articles/creating-a-thinking-culture/\nContent: Nancy Kline's Thinking Environment®, is a framework and a system ... Attention is the one essential and it is the most powerful tool we have.\n\nTitle: Nancy Klein's - Thinking Environment - Business Results Group\nURL: https://www.brg.co.za/thinkingenvironment/\nContent: Nancy Kline's Thinking Environment is a powerful approach to communication and problem-solving that enables individuals and groups to tap into their full\nRaw Content: ![Business Results Group](//www.brg.co.za/wp-content/uploads/2015/09/NEW-BRG-Logo-300x144.png)\n\n## Nancy Klein’s - Thinking Environment™\n\nStimulate Thinking\n\n![](https://www.brg.co.za/wp-content/uploads/2023/05/4.png \"4\")\n\n### Who Is This For?\n\nExposure to the Thinking Environment is highly beneficial for anyone who wants to become a better thinker, communicator, and collaborator in their personal or professional life.\n\nThinking Environment training is particularly useful for leaders and managers who want to create a culture of collaboration and innovation within their organisations and teams. It is also very effective for individuals who want to improve their personal and professional relationships by enhancing their ability to listen, communicate, and empathize with others.\n\n### Overview\n\nNancy Kline’s Thinking Environment is a powerful approach to communication and problem-solving that enables individuals and groups to tap into their full potential for creative and effective thinking. Based on extensive research and practical experience, this approach has been used successfully by leaders, managers, educators, and professionals in a wide range of settings around the world.\n\nThe Thinking Environment is based on the idea that the quality of our thinking is directly related to the quality of the attention we give to it. By creating a supportive and respectful environment that fosters free thinking, deep listening, and constructive feedback, we can unleash the full power of our minds and achieve breakthrough results.\n\nWith its emphasis on autonomy, diversity, and creativity, training in the Thinking Environment provides a structured framework that helps individuals and teams unleash their full potential and achieve their goals.\n\nIn Partnership With\n\n![](https://www.brg.co.za/wp-content/uploads/2023/05/Time-to-Think-Logo-1-300x120.png \"Time to Think Logo\")\n\n#### Thinking Environment | Nancy Klein\n\nThe Thinking Environment is based on ten core principles that provide a framework for creating a supportive and respectful environment for thinking and communication. These principles include:\n\nBy applying these principles in your interactions with others, you can create a powerful Thinking Environment that fosters free thinking, deep listening, and constructive feedback. Whether you are working with individuals or groups, the Thinking Environment provides a structured and effective approach to communication and problem-solving that can help you achieve breakthrough results.\n\nThinking Environment Training\n\n**Thinking Environment™ Training**\n\nTraining is designed to provide participants with an understanding of the key principles of the Thinking Environment approach, and how to create a supportive and respectful environment for thinking and communication. Participants will learn practical techniques for deep listening, asking incisive questions, generating creative ideas, problem-solving, decision-making, and brainstorming. They will also learn how to apply the Thinking Environment approach in various contexts, including personal and professional relationships, leadership, and complex problem-solving.\n\n**Format**: Training can be conducted in a traditional face-to-face workshop or in an interactive Virtual Instructor Led Training environment.\n\n**Delivery**: Chose from a foundation module of 3hours (half-day face-to-face), a full day, or a two-day option\n\n**Objectives**:\n\nTransforming Meetings™\n\nAccording to a study by Harvard Business Review, executives report that 67% of meetings are unproductive and inefficient. Additionally, the study found that 71% of participants also felt those meetings were unproductive and a waste of time. When it’s estimated that most people in organisations spend more than two-thirds of their time in meetings, this is a frightening statistic and clearly highlights the urgent need for effective meeting strategies.\n\n**The Thinking Environment Transforming Meetings™ session** is an innovative and effective approach to transforming meetings into powerful interactions that generate breakthrough results. It is an essential tool for leaders and professionals who want to improve the quality of their meetings and achieve greater success in their personal and professional lives.\n\n**Overview**\n\nThe session is designed to provide participants with an understanding of the key principles of the Thinking Environment approach, and how to apply them to transform their meetings. Participants will learn practical techniques for creating a supportive and respectful environment, that fosters free thinking, deep listening, asking incisive questions, generating creative ideas, problem-solving, decision-making, and brainstorming. They will also learn how to apply the Thinking Environment approach in various contexts, including team meetings, strategic planning sessions, project reviews, and more. The Application includes practice in a real-time business meeting, achieving concrete business results.\n\n**Objectives**\n\nThis practical step-by-step process for leading meetings engages each person fully, generating ideas, debate, decision-making, and practical results of exceptional quality. Teleconferencing, video conferencing, and face-to-face meetings all take leaps in productivity when led in this way. Sessions can be customised based on the specific needs and objectives of the group.\n\nThinking Environment Keynotes\n\nA 90-minute keynote presentation is an ideal way to test your company’s appetite for the Thinking Environment practices and to determine its suitability for your business. Keynotes are also an ideal way of reaching large audiences in a limited period of time or sharing the Thinking Environment philosophy with the broader organisation.\n\nThinking Environment Coaching\n\nBusiness Results Group’s trained pool of facilitators and coaches is able to provide personal one-on-one development options for busy executives, individuals, and small teams. Coupled with the 360 Assessment, coaching takes leaders on a personal and confidential journey of discovery, resulting in a new approach to leadership that genuinely helps leaders and organisations transform by tapping into the innate intelligence that already exists within the business.\n\nContact us to set up a Thinking Environment coaching session\n\nLeadership can be learned. New evidence from neuroscience clearly points to ways that leaders can engage with and motivate others, allowing them and their organisations to continue discovering their potential.\n\n**Tara Swart, Kitty Chrisholm and Paul Brown**\n\nNeuroscience for Leadership, Harnessing\n\nthe Brain Gain Advantage\n\n### Get In Touch\n\nFirst Name\\*\n\nLast Name\\*\n\nEmail address\\*\n\n### Articles\n\n### LinkedIn\n\n![Business Results Group class=](//www.brg.co.za/wp-content/uploads/2015/01/LogoCLean.png)\n\nTitle: What Is The Thinking Environment? - Aspey Associates\nURL: https://www.aspey.com/blog-posts/2017/11/15/what-is-the-thinking-environment\nContent: It's a unique and powerful framework for generative thinking developed by Nancy Kline of Time to Think. Guided by principles and human behaviours.\nRaw Content: ![Aspey Associates](//images.squarespace-cdn.com/content/v1/5a0998dc2278e7cd4b7de2b6/1539857677075-DFTNNGVI1TH9OCEQZYX0/Revised+logo+181018.png)\n![Aspey Associates](//images.squarespace-cdn.com/content/v1/5a0998dc2278e7cd4b7de2b6/1539857677075-DFTNNGVI1TH9OCEQZYX0/Revised+logo+181018.png)\n\n# What Is The Thinking Environment?\n\n### The quality of everything we do depends on the quality of the thinking we do first.\n\nYet when was the last time you really had time to think when you needed it, or before you acted or made decisions? Time to collect your thoughts, to let them flow, to move them around, to weigh them up, to go as deep or as wide or as focused or as bold or as high as you wanted?\n\nAnd when was the last time you were able to think in the presence of someone else who genuinely wanted to hear what you thought, who invited you to truly think for yourself, who didn’t interrupt, question, advise, direct, analyse, interpret, assess or judge?  Think about a typical meeting - do you really get time to think, and allow others to have the same, or are meetings places of embattlement, frustration or unproductive meandering?\n\nIf you said yes to any of those last points, I’m sure that you’ll find the The Thinking Environment™ can change the situation entirely! It’s a unique and powerful framework for generative thinking developed by Nancy Kline of Time to Think. Guided by principles and human behaviours known as the “Ten Components of the Thinking Environment” it enables people to think for themselves with rigour, imagination, courage and grace.\n\n### How it works\n\nThis simple yet profoundly impactful framework is supported by a growing body of neuropsychological evidence that the quality of one person’s attention determines the quality of the other person’s thinking. People can go much further in their own thinking if we listen to *ignite* their minds, rather than listening to *respond* with a question, a suggestion, or advice.\n\nAttention is an act of creation. Given the right environment, the Thinker can generate a multitude of thoughts, ask their own questions, solve their own dilemmas, and identify their own untrue assumptions that may be stifling or hindering them. And with generative, clean input and precise, visionary questioning from the Thinking Partner, can instead become clear, creative, progressive and decisive.\n\n### What can it be used for?\n\nApplying the principles of the Thinking Environment can have a transformative effect in many contexts – day to day discussions, team meetings, facilitated events, client relationships, even family life all can be approached from a fresh perspective.\n\n### What is the Thinking Partnership?\n\nThe Thinking Partnership is the step-by-step process for liberating the human mind to think for itself with unprecedented clarity, originality and rigour, within the framework of a Thinking Environment. This is a creative partnership unlike any other: a Thinker and a Thinking Partner. It’s regarded by many as an essential coaching skill; the training and application of it is also a unique personal development experience.\n\n### What does Linda Aspey offer?\n\nAs a Faculty member of Time to Think, trained by Nancy Kline, Linda Aspey offers confidential one to one Time to Think Coaching sessions for senior managers, executives and business owners. Time to Think sessions can be complemented with traditional coaching methods and tools, depending on your needs. Time to Think coaching sessions can be one-off, ad hoc or at regular intervals – whatever works best.\n\nShe also facilitates all kinds of events, meetings and offsites, and offers “Transforming Meetings” a training programme that helps you to do just exactly that – transform meetings – in your place of work. Your meetings will never again be boring, one sided or unproductive! Instead they will be places and spaces where people create, share, listen, collaborate, support and feel inspired and energized.\n\nLinda also runs public courses on Time to Think: The Time to Foundation, the qualifying Time to Think Facilitator, the Thinking Partnership and the qualifying Time to Think Coach. See our [course listings](https://www.aspey.com/ttt-courses) for next training dates. Courses can be delivered for groups and teams in house where you have several people for training at the same time.\n\n![](https://images.squarespace-cdn.com/content/v1/5a0998dc2278e7cd4b7de2b6/1847cab7-d1b2-4cf3-952b-3a4ac3f9826c/AA+TTT+Postcard+Side+1+May+2020-SQUARE.jpg)\n\n© Linda Aspey 2021\n\n#### Best Books For New Managers and Leaders\n\n#### Six Principles for Effective Meetings\n\n## The Independent Mind Digest\n\nSign up to join our community of thinkers & get my quarterly digest of thoughtfully curated articles, talks, workshops, courses & more. I also send out very occasional emails with special alerts to events, courses or papers. You can unsubscribe at any time.\n\nWe do not share your details with anyone and will always respect your privacy. See our [Privacy Notice](/privacy-policy) for more info.\n\nThank you! You have been added to my mailing list for occasional newsblogs. You can unsubscribe at any time although the intention is for it to be so interesting and useful you won’t want to!   \n  \nAll best, LInda\n\n### From the blog...\n\n![How the Unbridled Expansion of AI Is Impacting the Whole of Life]()\n![Coaching Supervision - Who is the Expert in the Room? ]()\n![The Independent Mind Digest,  June 2025]()\n![The Independent Mind Digest, May 2025]()\n![And But Therefore framework png.png]()\n![sunthruclouds+%282%29.jpg]()\n![Climate Cafe Listening Circles: Breaking the Silence]()\n![One widespread habit that's getting in the way of good relationships, creativity and trust]()\n![From Eco-Distress to Resilience: How Employers Can Support Staff in a Changing World]()\n![Blog June 2024 -Inspiration, Resources and News]()\n\nCopyright © 2018 Aspey Ltd, trading as Aspey Associates. Registered in England & Wales. Company number 4475717.\n\nTitle: [PDF] Time To Think Nancy Kline\nURL: http://www.dc.narpm.org/browse/mL1391/6001027/Time%20To%20Think%20Nancy%20Kline.pdf\nContent: Kline's model encourages us to prioritize listening and create an environment where every person feels valued and free to express their thoughts without fear of\n\nTitle: [PDF] Time To Think Nancy Kline\nURL: https://ww2.jacksonms.gov/fulldisplay/CYACo1/270006/time_to_think__nancy_kline.pdf\nContent: Create Small Thinking Environments: Set up meetings or coaching sessions that follow the principles of attention, equality, ease, appreciation, and.\n\nTitle: Using the Thinking Environment model in meetings - YouTube\nURL: https://www.youtube.com/watch?v=PRZNfYLAPIk\nContent: ... Nancy Kline's Thinking Environment, a mix of self-generated and sourced public domain. If this is of interest do let me know. See many of\n\nTitle: [PDF] Kline 5th proof.indd - TimetoThink\nURL: https://www.timetothink.com/wp-content/uploads/2020/02/caw-article.pdf\nContent: The creation of a thinking environment allows client and coach to find solutions together. But how can the coach be a catalyst for the client's own ideas\n\nTitle: Is it 'Time to Think' yet? Learning hubs in specialty training - PMC - NIH\nURL: https://pmc.ncbi.nlm.nih.gov/articles/PMC9461484/\nContent: The training director designed the Learning Hub around Kline's (1999) Ten Components of a Thinking Environment [below], where everyone matters and is allowed"
      }
    ]
  }
]

---

### Assistant
> 11/30/2025, 3:48:47 PM

[
  {
    "type": "text",
    "text": "Prompt is too long"
  }
]

