# 2.2 Dialogue Mode Specification

**Purpose:** This document defines Dialogue Mode (ForgeMode)‚Äîthe structured thinking system in IES that guides users through meaning extraction via adaptive, personalized questioning.

**Date:** December 6, 2025
**Status:** Production Ready (Phase 2c Complete)

---

## Mission and Purpose

Dialogue Mode is the **thinking ‚Üí extraction** engine in the IES knowledge lifecycle. It provides:

- **Structured thinking sessions** ‚Äî Template-driven exploration with 5 distinct modes
- **Adaptive questioning** ‚Äî AI asks questions tailored to user's cognitive profile and current state
- **9 Question Classes** ‚Äî Cognitive functions mapped to thinking modes for deeper exploration
- **Session persistence** ‚Äî Auto-saved documents with full transcript and metadata
- **Concept formalization** ‚Äî Extract entities from dialogue and promote to knowledge graph

**Design Principle:** If thinking requires structure, it should follow form. Dialogue Mode scaffolds the thinking process while preserving user agency.

---

## The Five Thinking Modes

From `.worktrees/siyuan/ies/plugin/src/views/ForgeMode.svelte` (lines 136-148):

```typescript
const THINKING_MODES = {
    learning: {
        label: 'Learning',
        emoji: 'üìö',
        description: 'Understand new mechanisms and concepts',
        template_id: 'learning-mechanism-map'
    },
    articulating: {
        label: 'Articulating',
        emoji: 'üí¨',
        description: 'Clarify vague intuitions',
        template_id: 'articulating-clarify-intuition'
    },
    planning: {
        label: 'Planning',
        emoji: 'üìã',
        description: 'Develop action strategies',
        template_id: null  // Future implementation
    },
    ideating: {
        label: 'Ideating',
        emoji: 'üí°',
        description: 'Generate creative options',
        template_id: null  // Future implementation
    },
    reflecting: {
        label: 'Reflecting',
        emoji: 'ü™û',
        description: 'Extract personal insights',
        template_id: null  // Future implementation
    }
};
```

**Mode Selection:**
- User selects mode at session start based on current thinking need
- Mode determines template (if available), question classes, and AI behavior
- Mode-specific folders organize session documents in SiYuan

---

## Nine Question Classes

From `ies/backend/src/ies_backend/schemas/question_engine.py` (lines 6-22):

```python
class QuestionClass(str, Enum):
    """Nine question classes with distinct cognitive functions."""

    SCHEMA_PROBE = "schema_probe"           # Surfaces hidden structure
    BOUNDARY = "boundary"                   # Clarifies edges/limits
    DIMENSIONAL = "dimensional"             # Introduces spectra/coordinates
    CAUSAL = "causal"                       # Pushes for mechanisms/sequences
    COUNTERFACTUAL = "counterfactual"       # What-if deviations
    ANCHOR = "anchor"                       # Grounds abstractions in concrete
    PERSPECTIVE_SHIFT = "perspective_shift" # Forces viewpoint changes
    META_COGNITIVE = "meta_cognitive"       # Checks thinking patterns
    REFLECTIVE_SYNTHESIS = "reflective_synthesis"  # Integration statements
```

**Class Labels and Colors** (ForgeMode.svelte lines 161-173):

| Class | Label | Emoji | Color | Cognitive Function |
|-------|-------|-------|-------|-------------------|
| `schema_probe` | Structure | üèóÔ∏è | #4a90d9 (blue) | "What are the categories?" |
| `boundary` | Edge | üî≤ | #7b68ee (purple) | "What's NOT included?" |
| `dimensional` | Spectrum | üìê | #20b2aa (teal) | "On a scale from X to Y?" |
| `causal` | Mechanism | ‚ö° | #f4a460 (tan) | "What causes this?" |
| `counterfactual` | What-If | üîÆ | #da70d6 (orchid) | "If the opposite were true?" |
| `anchor` | Concrete | ‚öì | #3cb371 (green) | "Give a specific example?" |
| `perspective_shift` | Viewpoint | üëÅÔ∏è | #cd853f (brown) | "How would X see this?" |
| `meta_cognitive` | Thinking | üß† | #778899 (gray) | "Where do you feel stuck?" |
| `reflective_synthesis` | Integration | üîó | #6495ed (blue) | "How do these connect?" |

**Mode-to-Class Mapping** (from backend):

```python
# From question_engine.py CLASS_TO_MODES
LEARNING: [SCHEMA_PROBE, CAUSAL, ANCHOR]
ARTICULATING: [ANCHOR, META_COGNITIVE, REFLECTIVE_SYNTHESIS]
PLANNING: [DIMENSIONAL, CAUSAL]
IDEATING: [COUNTERFACTUAL, PERSPECTIVE_SHIFT]
REFLECTING: [ANCHOR, META_COGNITIVE, REFLECTIVE_SYNTHESIS]
```

---

## Question Class Hints (Cognitive Guidance)

From ForgeMode.svelte (lines 174-239):

```typescript
const QUESTION_CLASS_HINTS: Record<string, { hint: string; prompt: string; responseStarter?: string }> = {
    schema_probe: {
        hint: "Try listing the main categories, components, or buckets.",
        prompt: "What are the main parts of this?",
        responseStarter: "The main parts are..."
    },
    causal: {
        hint: "Think about what leads to what. What are the prerequisites?",
        prompt: "What causes this? What has to happen first?",
        responseStarter: "This happens because..."
    },
    anchor: {
        hint: "Ground abstractions in concrete instances or examples.",
        prompt: "Can you give a specific example? When did you experience this?",
        responseStarter: "For example..."
    },
    // ... (9 classes total with hints)
};
```

**Features:**
- Each question class has cognitive guidance to reduce friction
- `hint`: What to think about when answering
- `prompt`: Sample question for that class
- `responseStarter`: Optional sentence starters to begin responses

**UI Integration:**
- Expandable hint section in question-response card
- Displays when user clicks "Show hint" (ForgeMode lines 1296-1330)
- Reduces cognitive load for users unfamiliar with question types

---

## Interactive Question-Response System

From ForgeMode.svelte (lines 993-1075):

```typescript
async function handleQuestionResponse() {
    if (!currentQuestionResponse.trim()) {
        showMessage('Please enter a response', 3000, 'error');
        return;
    }

    const userMessage = {
        role: 'user' as const,
        content: currentQuestionResponse.trim()
    };

    // Add user response to conversation
    conversation = [...conversation, userMessage];

    // Track question-response exchange
    questionResponseHistory.push({
        question: currentQuestion.question,
        questionClass: currentQuestion.questionClass,
        response: currentQuestionResponse,
        timestamp: new Date().toISOString()
    });

    // Clear pending question and response
    currentQuestion = null;
    currentQuestionResponse = '';

    // Generate next AI response with follow-up question
    await handleSendMessage();
}
```

**Question-Response Flow:**

```
1. AI generates question (with QuestionClass tag)
   ‚Üì
2. User sees question with class badge and hint
   ‚Üì
3. User expands hint for cognitive guidance
   ‚Üì
4. User types response in textarea
   ‚Üì
5. User submits (Cmd/Ctrl+Enter or "Respond" button)
   ‚Üì
6. Response added to conversation history
   ‚Üì
7. Question-response pair tracked for transcript
   ‚Üì
8. AI processes response ‚Üí generates next question
```

**UI Components:**
- `.question-response-card`: Main container with class-colored borders
- `.qrc-question`: Question text display
- `.qrc-hint`: Expandable cognitive guidance section
- `.qrc-input`: Textarea for response (auto-focus)
- `.qrc-respond`: Submit button
- `.qrc-skip`: Skip question if not relevant
- `.qrc-starter`: Optional sentence starters

**CSS Styling** (ForgeMode.svelte lines 1445-1855):

Complete styling system with:
- Class-specific border colors
- Hover states and focus rings
- Loading indicators
- Expandable sections
- Button variants (primary, secondary, ghost)

---

## Template-Driven Sessions

Templates provide structured scaffolding for specific thinking modes.

**Template Structure** (from backend schemas):

```typescript
interface ThinkingTemplate {
    id: string;                        // "learning-mechanism-map"
    name: string;                      // "Mechanism Map"
    mode: ThinkingMode;                // "learning"
    sections: Section[];               // Template sections
    graph_mapping: GraphMappingRules;  // Entity extraction rules
}

interface Section {
    id: string;                        // "understanding_prerequisites"
    prompt: string;                    // "What do you need to understand first?"
    input_type: InputType;             // "freeform" | "concept_search" | "selection"
    ai_behavior: string;               // "Ask clarifying questions about..."
    required: boolean;                 // Is this section required?
}
```

**Available Templates:**

1. **Learning: Mechanism Map** (`learning-mechanism-map`)
   - Sections: Prerequisites, Core Components, Causal Flow, Boundary Conditions
   - Focus: Understand how something works (mechanisms, frameworks, systems)

2. **Articulating: Clarify Intuition** (`articulating-clarify-intuition`)
   - Sections: Fuzzy Sense, Concrete Examples, Contrast Cases, Formalization
   - Focus: Turn vague feelings into precise conceptualizations

**Template Flow:**

```
1. User starts session ‚Üí selects mode with template
   ‚Üì
2. ForgeMode fetches template from backend (GET /templates/{template_id})
   ‚Üì
3. Template sections displayed in progress panel
   ‚Üì
4. User works through sections sequentially
   ‚Üì
5. AI asks mode-appropriate questions for each section
   ‚Üì
6. Responses saved in sectionResponses object
   ‚Üì
7. Session completes ‚Üí full document created with section responses
```

**Progress Tracking:**

ForgeMode tracks which section is current:

```typescript
let currentSectionIndex = 0;
let sectionResponses: Record<string, string> = {};  // section_id ‚Üí response

// Section complete when user provides substantial response
function handleSectionComplete(sectionId: string, response: string) {
    sectionResponses[sectionId] = response;
    currentSectionIndex++;
    // Load next section or complete session if last
}
```

**UI Display:**

```svelte
<!-- Progress panel shows section status -->
<div class="forge-progress">
    <div class="progress-sections">
        {#each template.sections as section, i}
            <div class="progress-section" class:current={i === currentSectionIndex} class:completed={sectionResponses[section.id]}>
                <span class="section-emoji">{i === currentSectionIndex ? '‚ñ∂Ô∏è' : sectionResponses[section.id] ? '‚úÖ' : '‚¨ú'}</span>
                <span class="section-label">{formatSectionName(section.id)}</span>
            </div>
        {/each}
    </div>
</div>
```

---

## Session Document Creation

When session completes, ForgeMode creates structured document in `/Sessions/{mode}/` folder.

**Document Structure:**

From `siyuan-structure.ts` (lines 499-638):

```typescript
function createSessionDocument(options: SessionDocumentOptions) {
    const frontmatter = `---
be_type: "session"
be_id: "${options.sessionId}"
mode: "${options.mode}"
topic: "${options.topic}"
status: "completed"
created: "${new Date().toISOString()}"
${options.templateData ? `template_id: "${options.templateData.template_id}"` : ''}
${options.templateData ? `template_name: "${options.templateData.template_name}"` : ''}
${options.entitiesExtracted !== undefined ? `entities_extracted: ${options.entitiesExtracted}` : ''}
${options.graphMappingExecuted !== undefined ? `graph_mapping_executed: ${options.graphMappingExecuted}` : ''}
${options.questionClassesUsed?.length ? `question_classes_used: [${options.questionClassesUsed.map(c => `"${c}"`).join(', ')}]` : ''}
---`;

    // Document content sections:
    // 1. Topic section with metadata
    // 2. Section responses (if template-based)
    // 3. Full conversation transcript
    // 4. Session results (entities, question classes used)
}
```

**File Location:**

```
/Sessions/{mode}/{YYYY-MM-DD-HHMM-topic}.md
```

Examples:
- `/Sessions/Learning/2025-12-06-1430-executive-function-mechanisms.md`
- `/Sessions/Articulating/2025-12-06-0915-shame-metabolization-intuition.md`

**Document Contents:**

1. **Frontmatter (YAML)** ‚Äî Session metadata
2. **Topic Section** ‚Äî Mode, template, date
3. **Section Responses** (if template-based) ‚Äî Responses organized by section
4. **Conversation Transcript** ‚Äî Full user/AI exchange
5. **Session Results** ‚Äî Entities extracted, question classes used, graph mapping status

---

## Concept Extraction Wizard

After session completes, user can formalize extracted entities into graph concepts.

**Entry Points:**

From ForgeMode completion UI:

```svelte
{#if extractedEntities.length > 0}
    <div class="entity-list">
        {#each extractedEntities as entity}
            <div class="entity-item">
                <span class="entity-name">{entity.name}</span>
                <span class="entity-type">{entity.type}</span>
                <div class="entity-actions">
                    <button on:click={() => openQuickConcept(entity)}>Quick</button>
                    <button on:click={() => openConceptWizard(entity)}>Advanced</button>
                </div>
            </div>
        {/each}
    </div>
{/if}
```

**Quick Concept:**
- Simple name + description dialog
- Fast capture for obvious concepts
- Saves to Neo4j + creates `/Concepts/` SiYuan document

**Advanced Wizard:**

From `.worktrees/siyuan/ies/plugin/src/components/ConceptExtractor.svelte` (600+ lines):

**4-Step Process:**

```
Step 1: Select Entity
  ‚Üí Choose from extracted entities or create new

Step 2: Define Concept
  ‚Üí Concept type (concept, theory, framework, mechanism, pattern, distinction)
  ‚Üí Name, description, aliases

Step 3: Add Relationships
  ‚Üí Select existing concepts from graph
  ‚Üí Define relationship type (supports, contradicts, component_of, operationalizes, develops, enables, contrasts_with)
  ‚Üí Add evidence (quote or reasoning)

Step 4: Review & Save
  ‚Üí Confirm all details
  ‚Üí Dual save: Neo4j graph + SiYuan document
```

**Backend Integration:**

```typescript
// POST /concepts
const createConceptResponse = await apiPost('/concepts', {
    name: conceptName,
    description: conceptDescription,
    concept_type: conceptType,
    aliases: aliases,
    relationships: relationships.map(rel => ({
        target_concept: rel.target,
        relationship_type: rel.type,
        evidence: rel.evidence
    })),
    source_session_id: sessionId,
    source_quotes: selectedQuotes
});
```

**SiYuan Document Creation:**

```typescript
// Create document in /Concepts/ folder
const docId = await createConceptDocument({
    conceptId: createConceptResponse.concept_id,
    conceptName: conceptName,
    conceptType: conceptType,
    description: conceptDescription,
    aliases: aliases,
    relatedConcepts: relationships.map(r => r.target)
});
```

**ConceptBlockMeta Frontmatter:**

```yaml
---
block_type: "concept"
concept_id: "concept_abc123"
concept_type: "mechanism"
related_concepts: ["Executive Function", "Working Memory"]
version: "1.0"
created_at: "2025-12-06T10:30:00Z"
---
```

---

## Backend API Integration

**Dialogue Mode APIs:**

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/thinking/start` | POST | Start thinking session from capture |
| `/thinking/{session_id}` | GET | Get session details |
| `/thinking/{session_id}/step` | POST | Record breadcrumb during thinking |
| `/thinking/{session_id}/complete` | POST | Mark session complete |
| `/templates/{template_id}` | GET | Fetch thinking template |
| `/question-engine/generate-questions` | POST | Generate adaptive questions |
| `/concepts` | POST | Create concept in graph |
| `/concepts` | GET | List/search concepts |
| `/concepts/{concept_name}` | GET | Get concept details |

**Question Generation Flow:**

```typescript
// 1. Detect user state from recent messages
const stateResult = await apiPost('/question-engine/detect-state', {
    messages: conversation.slice(-3)  // Last 3 user messages
});

// 2. Select inquiry approach based on state + mode
const approachResult = await apiPost('/question-engine/select-approach', {
    state: stateResult.state,
    thinking_mode: currentMode
});

// 3. Generate classified question
const questionsResult = await apiPost('/question-engine/generate-questions', {
    approach: approachResult.approach,
    topic: sessionTopic,
    context: {
        section_id: currentSectionId,
        user_messages: conversation.filter(m => m.role === 'user'),
        ai_messages: conversation.filter(m => m.role === 'assistant')
    }
});

// 4. Display question with class badge
currentQuestion = {
    question: questionsResult.questions[0].text,
    questionClass: questionsResult.questions[0].question_class
};
```

---

## Implementation Status

| Component | File | Status | Lines | Notes |
|-----------|------|--------|-------|-------|
| **Frontend (SiYuan)** | | | | |
| ForgeMode UI | `ForgeMode.svelte` | ‚úÖ Complete | 1400+ | 5 modes, interactive Q&A, templates |
| Concept Extractor | `ConceptExtractor.svelte` | ‚úÖ Complete | 600+ | 4-step wizard |
| Session Structure | `siyuan-structure.ts` | ‚úÖ Complete | 769 | Document creation, 10-folder hierarchy |
| **Backend** | | | | |
| Thinking API | `api/thinking.py` | ‚úÖ Complete | 57 | Session lifecycle |
| Thinking Service | `services/thinking_service.py` | ‚úÖ Complete | 349 | Session management |
| Template API | `api/template.py` | ‚úÖ Complete | 24 | Template serving |
| Template Service | `services/template_service.py` | ‚úÖ Complete | 150 | Template loading/execution |
| Question Engine API | `api/question_engine.py` | ‚úÖ Complete | 400 | 9 question classes |
| Concept API | `api/concept.py` | ‚úÖ Complete | 74 | Graph formalization |
| Concept Service | `services/concept_service.py` | ‚úÖ Complete | 200+ | Neo4j integration |
| **Tests** | | | | |
| Backend Tests | `tests/test_*.py` | ‚úÖ Passing | TBD | 94/94 tests passing |

---

## Integration with Other Modes

### Capture ‚Üí Dialogue

```
CaptureItem (status: queued)
  ‚Üí User clicks "Start Thinking"
  ‚Üí POST /thinking/start { capture_id }
  ‚Üí ThinkingSession created
  ‚Üí CaptureItem status: queued ‚Üí in_thinking
  ‚Üí ForgeMode opens with capture content as topic
```

**Data Passed:**
- `capture.raw_text` ‚Üí Session topic/context
- `capture.auto_extracted.entities` ‚Üí Initial entities for dialogue
- `capture.auto_extracted.topics` ‚Üí Suggested themes

---

### Dialogue ‚Üí Flow

```
ThinkingSession (status: completed)
  ‚Üí User clicks entity in session results
  ‚Üí POST /flow/open-from-session { session_id, entity_id }
  ‚Üí FlowSession created
  ‚Üí Flow Mode opens with entity as starting point
```

**Data Passed:**
- `session.entities` ‚Üí Extracted concepts for graph exploration
- `session.breadcrumbs` ‚Üí Journey context from session
- `session.id` ‚Üí Source reference for breadcrumb

---

### Dialogue ‚Üí Concept Graph (Virtuous Cycle)

```
ThinkingSession (completed)
  ‚Üí User extracts concepts via wizard
  ‚Üí POST /concepts { name, description, relationships, source_session_id }
  ‚Üí Concept node created in Neo4j
  ‚Üí SiYuan document created in /Concepts/
  ‚Üí Next session can reference formalized concept
```

**Virtuous Cycle:**
1. Dialogue generates entities
2. User formalizes entities into concepts
3. Concepts saved to Neo4j graph
4. Next dialogue session can search/reference concepts
5. Knowledge graph grows from thinking artifacts

---

## Key Differentiators

| Traditional Dialogue | IES Dialogue Mode |
|---------------------|-------------------|
| Generic chatbot questions | 9 question classes with cognitive functions |
| One-size-fits-all prompts | Adaptive questions based on user state + profile |
| No session structure | Template-driven with progress tracking |
| Lost in chat history | Persistent session documents with full transcript |
| Manual concept extraction | Wizard-guided formalization with graph integration |
| Isolated conversations | Feeds knowledge graph (virtuous cycle) |

---

## References

**Implementation Files:**
- Frontend: `.worktrees/siyuan/ies/plugin/src/views/ForgeMode.svelte`
- Concept Wizard: `.worktrees/siyuan/ies/plugin/src/components/ConceptExtractor.svelte`
- Session Structure: `.worktrees/siyuan/ies/plugin/src/utils/siyuan-structure.ts`
- Backend Thinking API: `ies/backend/src/ies_backend/api/thinking.py`
- Backend Template API: `ies/backend/src/ies_backend/api/template.py`
- Backend Question Engine: `ies/backend/src/ies_backend/api/question_engine.py`
- Backend Concept API: `ies/backend/src/ies_backend/api/concept.py`
- Thinking Service: `ies/backend/src/ies_backend/services/thinking_service.py`
- Concept Service: `ies/backend/src/ies_backend/services/concept_service.py`
- Thinking Schemas: `ies/backend/src/ies_backend/schemas/thinking.py`
- Question Engine Schemas: `ies/backend/src/ies_backend/schemas/question_engine.py`
- Template Schemas: `ies/backend/src/ies_backend/schemas/template.py`

**Related Docs:**
- `docs/ies-master-analysis/0-system/0.1-IES-Overview.md` ‚Äî System overview and knowledge lifecycle
- `docs/ies-master-analysis/2-modes/2.1-Capture-Spec.md` ‚Äî Capture ‚Üí Dialogue transition
- `docs/ies-master-analysis/3-schemas/3.1-Seed-Schema.md` ‚Äî Seed types and status systems
- `docs/ies-master-analysis/2-modes/2.4-Mode-Transition-Engine.md` ‚Äî Mode switching logic
- `IES AST SiYuan structure.md` ‚Äî SiYuan notebook with 20 pages defining AST architecture

---

*This document defines Dialogue Mode‚Äîthe structured thinking system in IES. For ephemeral capture, see 2.1-Capture-Spec.md. For graph exploration from sessions, see 2.3-Flow-Spec.md.*
